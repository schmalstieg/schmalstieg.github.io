

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Publication Details - Dieter Schmalstieg</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Dieter Schmalstieg">
<meta property="og:title" content="Publication Details">


  <link rel="canonical" href="http://localhost:4000/pubdetail.html">
  <meta property="og:url" content="http://localhost:4000/pubdetail.html">



  <meta property="og:description" content="Publication Details">





  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Dieter Schmalstieg",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Dieter Schmalstieg Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Dieter Schmalstieg</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/talklist.html">Talks</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/patents.html">Patents</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/arbook.html">AR Book</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/Schmalstieg.png" class="author__avatar" alt="Links">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Links</h3>
    <p class="author__bio">to external websites</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Stuttgart, Germany</li>
      
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> University of Stuttgart</li>
      
      
      
        <li><a href="mailto:dieter.schmalstieg@visus.uni-stuttgart.de"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/schmalstieg"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
        <li><a href="https://www.youtube.com/user/@dieterschmalstieg7244"><i class="fab fa-fw fa-youtube" aria-hidden="true"></i> YouTube</a></li>
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=xXu8K6IAAAAJ&hl=en"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
      
        <li><a href="https://orcid.org/0000-0003-2813-2235"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="Publication Details">
    <meta itemprop="description" content="Publication Details">
    
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">Publication Details
</h1>
          
        
        
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        
<div id="Schmalstieg_446" style="display:none;">
    <div>
	  Xiangyu Wang, Thomas Koehler, Jun Lin Qiu, Shohei Mori, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>NeuralPVS: Learned Estimation of Potentially Visible Sets</b>
	</div><div>
	  
	    In <i>ACM SIGGRAPH Asia Conference Papers</i>,
	  
      
	  December 2025, to appear.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Real-time visibility determination in expansive or dynamically changing environments has long posed a significant challenge in computer graphics. Existing techniques are computationally expensive and often applied as a precomputation step on a static scene. We present NeuralPVS, the first deep-learning approach for visibility computation that efficiently determines from-region visibility in a large scene, running at approximately 100 Hz processing with less than 1% missing geometry. This approach is possible by using a neural network operating on a froxelized representation of the scene. The network's performance is achieved by combining sparse convolution with a 3D volume-preserving interleaving for data compression. Moreover, we introduce a novel repulsive visibility loss that can effectively guide the network to converge to the correct data distribution. This loss provides enhanced robustness and generalization to unseen scenes. Our results demonstrate that NeuralPVS outperforms existing visibility methods in terms of both accuracy and efficiency.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/9sreKrHNVMs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_447" style="display:none;">
    <div>
	  Sebastian Kuenzel, Sergej Geringer, Quynh Quang Ngo, Philip Voglreiter, Daniel Weiskopf, Dieter Schmalstieg:
	</div><div>
	  <b>Potentially Visible Set Generation with the Disocclusion Buffer</b>
	</div><div>
	  
	    In <i>ACM SIGGRAPH Asia Conference Papers</i>,
	  
      
	  December 2025, to appear.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The computation of a potentially visible set (PVS) can accelerate many computer graphics algorithms, such as framerate upsampling, streaming rendering, global illumination, and multi-fragment effects. Algorithms for from-region PVS have an inherently high complexity. Previous from-region PVS algorithms propagate occlusion through the scene in a front-to-back manner and are order-dependent, which places bounds on parallelism and restricts execution speed. We introduce the disocclusion buffer, which operates on a sparse, layered representation of the scene with quantized depth. In this representation, we invert the traditional PVS problem formulation and explicitly compute disocclusion rather than occlusion. Disocclusion can be computed in parallel in an order-independent manner, overcoming the main bottleneck in traditional PVS computation. Our PVS algorithm is over six times faster than the previous state of the art at the same level of accuracy in a direct comparison. It runs in shaders on the GPU without requiring any hardware extensions. We demonstrate how our work outperforms previous PVS algorithms in the range of supported camera motion without compromising quality.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_448" style="display:none;">
    <div>
	  Lukas Radl, Felix Windisch, Thomas Deixelberger, Jozef Hladky, Michael Steiner, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>SOF: Sorted Opacity Fields for Fast Unbounded Surface Reconstruction</b>
	</div><div>
	  
	    In <i>ACM SIGGRAPH Asia Conference Papers</i>,
	  
      
	  December 2025, to appear.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Recent advances in 3D Gaussian representations have significantly improved the quality and efficiency of image-based scene reconstruction. Their explicit nature facilitates real-time rendering and fast optimization, yet extracting accurate surfaces---particularly in large-scale, unbounded environments---remains a difficult task. Many existing methods rely on approximate depth estimates and global sorting heuristics, which can introduce artifacts and limit the fidelity of the reconstructed mesh. In this paper, we present Sorted Opacity Fields (SOF), a method designed to recover detailed surfaces from 3D Gaussians with both speed and precision. Our approach improves upon prior work by introducing hierarchical resorting and a robust formulation of Gaussian depth, which better aligns with the level-set. To enhance mesh quality, we incorporate a level-set regularizer operating on the opacity field and introduce losses that encourage geometrically-consistent primitive shapes. In addition, we develop a parallelized Marching Tetrahedra algorithm tailored to our opacity formulation, reducing meshing time by up to an order of magnitude. As demonstrated by our quantitative evaluation, SOF achieves higher reconstruction accuracy while cutting total processing time by more than a factor of three. These results mark a step forward in turning efficient Gaussian-based rendering into equally efficient geometry extraction.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/jCn2yAHnKtw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_449" style="display:none;">
    <div>
	  Sebastian Hubenschmid, Johannes Zagermann, Robin Erb, Tiare Feuchtner, Jens Grubert, Markus Tatzgern, Dieter Schmalstieg, Harald Reiterer:
	</div><div>
	  <b>SpatialMouse - A Hybrid Pointing Device for Seamless Interaction Across 2D and 3D Spaces</b>
	</div><div>
	  
	    In <i>Proc. ACM Virtual Reality Software and Technology</i>,
	  
      
	  November 2025, to appear.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We introduce the SpatialMouse, a hybrid pointing device that combines the capabilities of a desktop mouse with the spatial input of a virtual reality (VR) controller, enabling seamless transitions between 2D and 3D interaction spaces in immersive mixed reality environments. Holistic usage scenarios in mixed reality involve tasks suited alternately to 2D or 3D information spaces. Yet, existing input devices excel in either 2D or 3D, but not both, making it necessary to switch between multiple input devices (e.g., mouse and VR controller). Our SpatialMouse addresses this issue, offering the affordances of a desktop mouse for indirect 2D pointing and the spatial capabilities of VR controllers with six degrees of freedom. In a user study with 12 participants, our prototype significantly reduced perceived task load and improved user experience compared to switching between separate devices. We extract design recommendations to further support such hybrid input approaches.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_442" style="display:none;">
    <div>
	  Michael Steiner, Thomas Koehler, Lukas Radl, Felix Windisch, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>AAA-Gaussians: Anti-Aliased and Artifact-Free 3D Gaussian Rendering</b>
	</div><div>
	  
	    In <i>Proc. IEEE/CVF International Conference on Computer Vision (ICCV)</i>,
	  
      
	  October 2025, to appear.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Although 3D Gaussian Splatting (3DGS) has revolutionized 3D reconstruction, it still faces challenges such as aliasing, projection artifacts, and view inconsistencies, primarily due to the simplification of treating splats as 2D entities. We argue that incorporating full 3D evaluation of Gaussians throughout the 3DGS pipeline can effectively address these issues while preserving rasterization efficiency. Specifically, we introduce an adaptive 3D smoothing filter to mitigate aliasing and present a stable view-space bounding method that eliminates popping artifacts when Gaussians extend beyond the view frustum. Furthermore, we promote tile-based culling to 3D with screen-space planes, accelerating rendering and reducing sorting costs for hierarchical rasterization. Our method achieves state-of-the-art quality on in-distribution evaluation sets and significantly outperforms other approaches for out-of-distribution views. Our qualitative evaluations further demonstrate the effective removal of aliasing, distortions, and popping artifacts, ensuring real-time, artifact-free rendering.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=KEwxiN7zj7I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_443" style="display:none;">
    <div>
	  Verena Biener, Florian J. Winston, Dieter Schmalstieg, Alexander Plopski:
	</div><div>
	  <b>Long-Term Experiences From Working with Extended Reality in the Wild</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality</i>,
	  
      
	  October 2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Extended Reality (XR) is increasingly used as a productivity tool and recent commercial XR devices have even been specifically designed as productivity tools, or, at least, are heavily advertised for such purposes, such as the Apple Vision Pro (AVP), which has now been available for more than one year. In spite of what marketing suggests, research still lacks an understanding of the long-term usage of such devices in ecologically valid everyday settings, as most studies are conducted in very controlled environments. Therefore, we conducted interviews with ten AVP users to better understand how experienced users engage with the device, and which limitations persist. Our participants report that XR can increase productivity and that they got used to the device after some time. Yet, a range of limitations persist that might hinder the widespread use of XR as a productivity tool, such as a lack of native applications, difficulties when integrating XR into current workflows, and limited possibilities to adapt and customize the XR experience.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_444" style="display:none;">
    <div>
	  Ayaka Yasunaga, Hideo Saito, Dieter Schmalstieg, Shohei Mori:
	</div><div>
	  <b>IntelliCap: Intelligent Guidance for Consistent View Sampling</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality</i>,
	  
      
	  October 2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Novel view synthesis from images, for example, with 3D Gaussian splatting, has made great progress. Rendering fidelity and speed are now ready even for demanding virtual reality applications. However, the problem of assisting humans in collecting the input images for these rendering algorithms has received much less attention. High-quality view synthesis requires uniform and dense view sampling. Unfortunately, these requirements are not easily addressed by human camera operators, who are in a hurry, impatient, or lack understanding of the scene structure and the photographic process. Existing approaches to guide humans during image acquisition concentrate on single objects or neglect view-dependent material characteristics. We propose a novel situated visualization technique for scanning at multiple scales. During the scanning of a scene, our method identifies important objects that need extended image coverage to properly represent view-dependent appearance. To this end, we leverage semantic segmentation and category identification, ranked by a vision-language model. Spherical proxies are generated around highly ranked objects to guide the user during scanning. Our results show superior performance in real scenes compared to conventional view sampling strategies.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/YNKomf2kuLc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_445" style="display:none;">
    <div>
	  Sebastian Rigling, Steffen Koch, Dieter Schmalstieg, Bruce Thomas, Michael Sedlmair:
	</div><div>
	  <b>Selection at a Distance Through a Large Transparent Touch Screen</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    
	    
	  
      
	  October 2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Large transparent touch screens (LTTS) have recently become commercially available. These displays have the potential for engaging Augmented Reality (AR) applications, especially in public and shared spaces. However, the interaction with objects in the real environment behind the display remains challenging: Users must combine pointing and touch input if they want to select objects at varying distances. There is a lot of work on wearable or mobile AR displays, but little on how users interact with LTTS. Our goal is to contribute to a better understanding of natural user interaction for these AR displays. To this end, we developed a prototype and evaluated different pointing techniques for selecting 12 physical targets behind an LTTS, with distances ranging from 6 to 401~cm. We conducted a user study with 16 participants and measured user preferences, performance, and behavior. We analyzed the change in accuracy depending on the target position and the selection technique used. Our findings include: (a) Users naturally align the touch point with their line of sight for targets farther than 36~cm behind the LTTS. (b) This technique provides the lowest angular deviation compared to other techniques. (c) Some user close one eye to improve their performance. Our results help to improve future AR scenarios using LTTS systems.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/JcnFBgURy4k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_450" style="display:none;">
    <div>
	  Sebastian Hubenschmid, Niklas Elmqvist, Tiare Feuchtner, Jens Grubert, Markus Tatzgern, Dieter Schmalstieg, Harald Reiterer:
	</div><div>
	  <b>Revisiting Hybrid Input Devices for Immersive Analytics</b>
	</div><div>
	  
	    In <i>IEEE VIS Workshops</i>,
	  
      
	  October 2025, to appear.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Hybrid user interfaces offer a promising framework for analysts to leverage the strengths of heterogeneous environments, such as desktops and mixed reality, and transition fluidly between them. Especially for immersive analytics, which often blends 3D interaction spaces with traditional 2D workflows, such hybrid user interfaces can reduce cognitive workload and improve user experience. Prior work has combined desktop-based statistical analysis with an in-situ exploration of spatiotemporal data in mixed reality. However, switching between devices and input modalities in such combinations can disrupt users' flow. We revisit the concept of hybrid input devices that operate seamlessly across 2D and 3D contexts by leveraging the complementary strengths of heterogeneous input devices. We thereby propose a hypothetical hybrid input device that combines input from a mouse and a spatial controller, for which we present potential interaction techniques and discuss potential opportunities and challenges for immersive analytics.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_437" style="display:none;">
    <div>
	  Andreas Fender, Dieter Schmalstieg:
	</div><div>
	  <b>Desired Realities: Concept and Examples</b>
	</div><div>
	  
	    In <i>Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems</i>,
	  
      
	  May 2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_438" style="display:none;">
    <div>
	  Michael Pabst, Linda Rudolph, Nikolas Brasch, Verena Biener, Chloe Eghtebas, Ulrich Eck, Dieter Schmalstieg, Gudrun Klinker:
	</div><div>
	  <b>MRUnion: Asymmetric Task-Aware 3D Mutual Scene Generation of Dissimilar Spaces for Mixed Reality Telepresence</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 31,
	    
	  
      
	  May 2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In mixed reality (MR) telepresence applications, the differences between participants' physical environments can interfere with effective collaboration. For asymmetric tasks, users might need to access different resources (information, objects, tools) distributed throughout their room. Existing intersection methods do not support such interactions, because a large portion of the telepresence participants' rooms become inaccessible, along with the relevant task resources. We propose MRUnion, a Mixed Reality Telepresence pipeline for asymmetric task-aware 3D mutual scene generation. The key concept of our approach is to enable a user in an asymmetric telecollaboration scenario to access the entire room, while still being able to communicate with remote users in a shared space. For this purpose, we introduce a novel mutual room layout called Union. We evaluated 882 space combinations quantitatively involving two, three, and four combined remote spaces and compared it to a conventional Intersect room layout. The results show that our method outperforms existing intersection methods and enables a significant increase in space and accessibility to resources within the shared space. In an exploratory user study (N=24), we investigated the applicability of the synthetic mutual scene in both MR and VR setups, where users collaborated on an asymmetric remote assembly task. The study results showed that our method achieved comparable results to the intersect method but requires further investigation in terms of social presence, safety and support of collaboration. From this study, we derived design implications for synthetic mutual spaces.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_439" style="display:none;">
    <div>
	  Jens Grubert, Dieter Schmalstieg, Kirsten Dickhaut:
	</div><div>
	  <b>Towards Supporting Literary Studies Using Virtual Reality and Generative Artificial Intelligence</b>
	</div><div>
	  
	    In <i>2025 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops</i>,
	  
      
	  March 2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Literary studies critically examine fictional texts, exploring their structures, themes, stylistic features, and cultural-historical contexts. A central challenge in this field lies in bridging textual analysis with the spatial and sensory dimensions of settings described or implied in texts. Traditional methodologies often require scholars to mentally reconstruct these environments, leading to incomplete or inconsistent interpretations. Readers may be biased by their personal context or experiences, or may lack detailed knowledge of the relevant historical facts. This paper argues for the integration of virtual reality and generative artificial intelligence as supporting instruments to enhance literary research. The former enables immersive, spatially accurate reconstructions of historical environments, while the latter provides tools such as text-to-image and text-to-3D generation which let us dynamically render visual elements quoted in literary texts. Together, these technologies have the potential to significantly enhance traditional literature analysis methodologies, enabling novel approaches for contextualizing and analyzing literature in its spatial and cultural milieu.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_440" style="display:none;">
    <div>
	  Philipp Fleck, Michael Hochortler, David Kastl, Georg Gotschier, Johanna Pirker, Dieter Schmalstieg:
	</div><div>
	  <b>CECILIA: A Toolkit for Visual Game Content Exploration and Modification</b>
	</div><div>
	  
	    <i>IEEE Transactions on Games</i>, 
	    
	    
	  
      
	   2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We investigate the idea of a toolkit for visually exploring and modifying game content, addressing questions such as how to identify relevant in-game data, how to make use of the data to create in-game visual representations, and what benefits these representations have. To that aim, we build a toolkit on top of the .NET platform employed by Unity in order to explore and add custom content without access to the game's source code. Our visual modifications use live objects in the game as data sources. The results appear as an integral part of the game world, which is generated with the original Unity rendering engine. This capability enables visual exploration for debugging, playtesting, modding, streaming, and data-driven analysis of games, as we demonstrate with several examples.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_441" style="display:none;">
    <div>
	  Antonio Pepe, Richard Schussnig, Jianning Li, Christina Gsaxner, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Deep Medial Voxels: Learned Medial Axis Approximations for Anatomical Shape Modeling</b>
	</div><div>
	  
	    <i>IEEE Transactions on Medical Imaging</i>, 
	    
	    
	  
      
	   2025.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Shape reconstruction from imaging volumes is a recurring need in medical image analysis. Common workflows start with a segmentation step, followed by careful post-processing and, finally, ad hoc meshing algorithms. As this sequence can be time-consuming, neural networks are trained to reconstruct shapes through template deformation. These networks deliver state-of-the-art results without manual intervention, but, so far, they have primarily been evaluated on anatomical shapes with little topological variety between individuals. In contrast, other works favor learning implicit shape models, which have multiple benefits for meshing and visualization. Our work follows this direction by introducing deep medial voxels, a semi-implicit representation that faithfully approximates the topological skeleton from imaging volumes and eventually leads to shape reconstruction via convolution surfaces. Our reconstruction technique shows potential for both visualization and computer simulations.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_436" style="display:none;">
    <div>
	  Saeed Safikhani, Dorian Lux, Dieter Schmalstieg, Johanna Pirker:
	</div><div>
	  <b>Tutorial Generation For Virtual Reality from Example Playtroughs</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Artificial Reality and Telexistence (EGVE-ICAT)</i>,
	  
      
	  December 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_431" style="display:none;">
    <div>
	  Christoph Ebner, Alexander Plopski, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Gaze-Contingent Layered Optical See-Through Displays with a Confidence-Driven View Volume</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    
	    
	  
      
	  October 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The vergence-accommodation conflict (VAC) presents a major perceptual challenge for head-mounted displays with a fixed image plane. Varifocal and layered display designs can mitigate the VAC. However, the image quality of varifocal displays is affected by imprecise eye tracking, whereas layered displays suffer from reduced image contrast as the distance between layers increases. Combined designs support a larger workspace and tolerate some eye-tracking error. However, any layered design with a fixed layer spacing restricts the amount of error compensation and limits the in-focus contrast. We extend previous hybrid designs by introducing confidence-driven volume control, which adjusts the size of the view volume at runtime. We use the eye tracker's confidence to control the spacing of display layers and optimize the trade-off between the display's view volume and the amount of eye tracking error the display can compensate. In the case of high-quality focus point estimation, our approach provides high in-focus contrast, whereas low-quality eye tracking increases the view volume to tolerate the error. We describe our design, present its implementation as an optical-see head-mounted display using a multiplicative layer combination, and present an evaluation comparing our design with previous approaches.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_432" style="display:none;">
    <div>
	  Shohei Mori, Dieter Schmalstieg:
	</div><div>
	  <b>A Way Out of the Replication Crisis in Diminished Reality Research</b>
	</div><div>
	  
	    In <i>Adjunct Proceedings of IEEE ISMAR</i>,
	  
      
	  October 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_433" style="display:none;">
    <div>
	  Ana Stanescu, Peter Mohr, Franz Thaler, Mateusz Kozinski, Lucchas Ribeiro-Skreinig, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Error Management for Augmented Reality Assembly Instructions</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE ISMAR</i>,
	  
      
	  October 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Augmented reality (AR) lends itself to presenting visual instructions on how to assemble or disassemble an object. Splitting the assembly procedure into shorter steps and presenting the corresponding instructions in AR supports their comprehension. However, one can still misinterpret instructions and make errors while manipulating the object. While previous work supports detecting the occurrence of errors, we investigate handling such errors. This requires knowledge of the error at runtime of the application. Starting from a categorization of the errors, we investigate how to automatically derive common error states to generate training data. We introduce an extension to a state-of-the-art deep-learning-based object detector for supporting the detection of assembly states at real-time update rates, based on contrastive learning. We evaluated the proposed detector, showing that it outperforms the state-of-the-art, and we demonstrate our work with an AR application that alerts the user if errors occur and provides visual help to correct the error.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_434" style="display:none;">
    <div>
	  Lucchas Ribeiro-Skreinig, Peter Mohr, Blanca Berger, Markus Tatzgern, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Immersive Authoring by Demonstration of Industrial Procedures</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE ISMAR</i>,
	  
      
	  October 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This work presents an authoring tool for supporting the creation of immersive instructions for industrial processes. Our system simplifies the creation of instructional content by providing an immersive virtual reality environment that enables expert operators to interact directly with virtual replicas of industrial devices. Hand movements, tool usage, gaze, spoken comments, and machine part movement are recorded using a head-mounted display. Editing of instructions in virtual reality is aided by automatic segmentation of recorded data into individual steps and visualizations of regions with intensive activity. A qualitative evaluation of our system by industrial experts shows that it is a viable alternative to current practices in authoring instructions for assembly and maintenance.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/whY1MZJ7VDs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_430" style="display:none;">
    <div>
	  Christina Schwarz-Gsaxner, Markus Perz, Gijs Luijten, Jens Kleesiek, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>MultiAR: A Collaborative Augmented Reality Platform for Biomedical Education</b>
	</div><div>
	  
	    In <i>Proc. IEEE Engineering in Medicine and Biology</i>,
	  
      
	  July 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_425" style="display:none;">
    <div>
	  Nina Doerr, Benjamin Lee, Katharina Baricova, Dieter Schmalstieg, Michael Sedlmair:
	</div><div>
	  <b>Visual Highlighting for Situated Brushing and Linking</b>
	</div><div>
	  
	    <i>Computer Graphics Forum (Proc. EuroVis)</i>, 
	    vol. 43,
	    
	  
      
	  May 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_423" style="display:none;">
    <div>
	  Christina Gsaxner, Shohei Mori, Dieter Schmalstieg, Jan Egger, Gerhard Paar, Werner Beiler, Denis Kalkofen:
	</div><div>
	  <b>DeepDR: Deep Structure-Aware RGB-D Inpainting for Diminished Reality</b>
	</div><div>
	  
	    In <i>Proc. International Conference on 3D Vision</i>,
	  
      
	  March 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_426" style="display:none;">
    <div>
	  Carlos Quijano-Chavez, Nina Doerr, Benjamin Lee, Dieter Schmalstieg, Michael Sedlmair:
	</div><div>
	  <b>Brushing and Linking for Situated Analytics</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality Workshops</i>,
	  
      
	  March 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_428" style="display:none;">
    <div>
	  David Mandl, Shohei Mori, Peter Mohr, Yifan Peng, Tobias Langlotz, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Neural Bokeh: Learning Lens Blur for Computational Videography and Out-of-Focus Mixed Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_429" style="display:none;">
    <div>
	  Marco Stranner, Philipp Fleck, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Instant Segmentation and Fitting of Excavations in Subsurface Utility Engineering</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. Virtual Reality)</i>, 
	    
	    
	  
      
	  March 2024, Best paper award honorable mention.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_435" style="display:none;">
    <div>
	  Tania Kaimel, Ana Stanescu, Peter Mohr, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Progress Observation in Augmented Reality Assembly Tutorials Using Dynamic Hand Gesture Recognition</b>
	</div><div>
	  
	    In <i>IEEE Virtual Reality and 3D User Interfaces Abstracts and Workshops</i>,
	  
      
	  March 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_422" style="display:none;">
    <div>
	  Neven ElSayed, Dieter Schmalstieg, Eduardo Veas:
	</div><div>
	  <b>Agents of MASK: Mobile Analytics from Situated Knowledge</b>
	</div><div>
	  
	    <i>ACM Interactions</i>, 
	    
	    
	  
      
	  January 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_427" style="display:none;">
    <div>
	  Daniel Mlakar, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>End-to-End Compressed Meshlet Rendering</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    
	    
	  
      
	  January 2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_424" style="display:none;">
    <div>
	  Jianning Li, Christina Gsaxner, Antonio Pepe, Dieter Schmalstieg, Jens Kleesiek, Jan Egger:
	</div><div>
	  <b>Sparse Convolutional Neural Network for High-resolution Skull Shape Completion and Shape Super-resolution</b>
	</div><div>
	  
	    <i>Scientific Reports</i>, 
	    
	    
	  
      
	   2024.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_416" style="display:none;">
    <div>
	  Lucchas Ribeiro-Skreinig, Denis Kalkofen, Ana Stanescu, Peter Mohr, Frank Heyen, Shohei Mori, Michael Sedlmair, Dieter Schmalstieg, Alexander Plopski:
	</div><div>
	  <b>guitARhero: Interactive Augmented Reality Guitar Tutorials</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    
	    
	  
      
	  October 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper presents guitARhero, an Augmented Reality application for interactively teaching guitar playing to beginners through responsive visualizations overlaid on the guitar neck. We support two types of visual guidance, a highlighting of the frets that need to be pressed and a 3D hand overlay, as well as two display scenarios, one using a desktop magic mirror and one using a video see-through head-mounted display. We conducted a user study with 20 participants to evaluate how well users could follow instructions presented with different guidance and display combinations and compare these to a baseline where users had to follow video instructions. Our study highlights the trade-off between the provided information and visual clarity affecting the user's ability to interpret and follow instructions for fine-grained tasks. We show that the perceived usefulness of instruction integration into an HMD view highly depends on the hardware capabilities and instruction details.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/mOndObWHwJY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_417" style="display:none;">
    <div>
	  Fernando Reyes-Aviles, Philipp Fleck, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Bag of World Anchors for Instant Large-Scale Localization</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    
	    
	  
      
	  October 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this work, we present a novel scene description to perform large-scale localization using only geometric constraints. Our work extends compact world anchors with a search data structure to efficiently perform localization and pose estimation of mobile augmented reality devices across multiple platforms (e.g., HoloLens 2, iPad). The algorithm uses a bag-of-words approach to characterize distinct scenes (e.g., rooms). Since the individual scene representations rely on compact geometric (rather than appearance-based) features, the resulting search structure is very lightweight and fast, lending itself to deployment on mobile devices. We present a set of experiments demonstrating the accuracy, performance and scalability of our novel localization method. In addition, we describe several use cases demonstrating how efficient cross-platform localization facilitates sharing of augmented reality experiences.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/K5iybmbYORY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_418" style="display:none;">
    <div>
	  Shohei Mori, Dieter Schmalstieg, and Denis Kalkofen:
	</div><div>
	  <b>Exemplar-Based Inpainting for 6DOF Virtual Reality Photos</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    
	    
	  
      
	  October 2023, ISMAR 2023 best paper honorable mention..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Multi-layer images are currently the most prominent scene representation for viewing natural scenes under full-motion parallax in virtual reality. Layers ordered in diopter space contain color and transparency so that a complete image is formed when the layers are composited in a view-dependent manner. Once baked, the same limitations apply to multi-layer images as to conventional single-layer photography, making it challenging to remove obstructive objects or otherwise edit the content. Object removal before baking can benefit from filling disoccluded layers with pixels from background layers. However, if no such background pixels have been observed, an inpainting algorithm must fill the empty spots with fitting synthetic content. We present and study a multi-layer inpainting approach that addresses this problem in two stages: First, a volumetric area of interest specified by the user is classified with respect to whether the background pixels have been observed or not. Second, the unobserved pixels are filled with multi-layer inpainting. We report on experiments using multiple variants of multi-layer inpainting and compare our solution to conventional inpainting methods that consider each layer individually.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/VOI_CW47CWw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_419" style="display:none;">
    <div>
	  Benjamin Lee, Michael Sedlmair, Dieter Schmalstieg:
	</div><div>
	  <b>Design Patterns for Situated Visualization in Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. VIS)</i>, 
	    
	    
	  
      
	  October 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Situated visualization has become an increasingly popular research area in the visualization community, fueled by advancements in augmented reality (AR) technology and immersive analytics. Visualizing data in spatial proximity to their physical referents affords new design opportunities and considerations not present in traditional visualization, which researchers are now beginning to explore. However, the AR research community has an extensive history of designing graphics that are displayed in highly physical contexts. In this work, we leverage the richness of AR research and apply it to situated visualization. We derive design patterns which summarize common approaches of visualizing data in situ. The design patterns are based on a survey of 293 papers published in the AR and visualization communities, as well as our own expertise. We discuss design dimensions that help to describe both our patterns and previous work in the literature. This discussion is accompanied by several guidelines which explain how to apply the patterns given the constraints imposed by the real world. We conclude by discussing future research directions that will help establish a complete understanding of the design of situated visualization, including the role of interactivity, tasks, and workflows.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_420" style="display:none;">
    <div>
	  Ana Stanescu, Peter Mohr, Mateusz Kozinski, Shohei Mori, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>State-Aware Configuration Detection for Augmented Reality Step-by-Step Tutorials</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    
	    
	  
      
	  October 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Presenting tutorials in augmented reality is a compelling application area, but previous attempts have been limited to objects with only a small numbers of parts. Scaling augmented reality tutorials to complex assemblies of a large number of parts is difficult, because it requires automatically discriminating many similar-looking object configurations, which poses a challenge for current object detection techniques. In this paper, we seek to lift this limitation. Our approach is inspired by the observation that, even though the number of assembly steps may be large, their order is typically highly restricted: Some actions can only be performed after others. To leverage this observation, we enhance a state-of-the-art object detector to predict the current assembly state by conditioning on the previous one, and to learn the constraints on consecutive states. This learned `consecutive state prior' helps the detector disambiguate configurations that are otherwise too similar in terms of visual appearance to be reliably discriminated. Via the state prior, the detector is also able to improve the estimated probabilities that a state detection is correct. We experimentally demonstrate that our technique enhances the detection accuracy for assembly sequences with a large number of steps and on a variety of use cases, including furniture, Lego and origami. Additionally, we demonstrate the use of our algorithm in an interactive augmented reality application.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/ebw0TLXwC9I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_421" style="display:none;">
    <div>
	  Aimee Sousa Calepso, Philipp Fleck, Michael Sedlmair, Dieter Schmalstieg:
	</div><div>
	  <b>Exploring Augmented Reality for Situated Analytics with Many Movable Physical Referents</b>
	</div><div>
	  
	    In <i>Proc. ACM VRST</i>,
	  
      
	  October 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Situated analytics (SitA) uses visualization in the context of physical referents, typically by using augmented reality (AR). We want to pave the way toward studying SitA in more suitable and realistic settings. Toward this goal, we contribute a testbed to evaluate SitA based on a scenario in which participants play the role of a museum curator and need to organize an exhibition of music artifacts. We conducted two experiments: First, we evaluated an AR headset interface and the testbed itself in an exploratory manner. Second, we compared the AR headset to a tablet interface. We summarize the lessons learned as guidance for designing and evaluating SitA.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/bEkVd194lHk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_414" style="display:none;">
    <div>
	  Philip Voglreiter, Bernhard Kerbl, Alexander Weinrauch, Joerg Mueller, Thomas Neff, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Trim Regions for Online Computation of From-Region Potentially Visible Sets</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics (Proc. SIGGRAPH)</i>, 
	    vol. 42,
	    
	  
      
	  August 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Visibility computation is a key element in computer graphics applications. More specifically, a from-region potentially visible set (PVS) is an established tool in rendering acceleration, but its high computational cost means a from-region PVS is almost always precomputed. Precomputation restricts the use of PVS to static scenes and leads to high storage cost, in particular, if we need fine-grained regions. For dynamic applications, such as streaming content over a variable-bandwidth network, online PVS computation with configurable region size is required. We address this need with trim regions, a new method for generating from-region PVS for arbitrary scenes in real time. Trim regions perform controlled erosion of object silhouettes in image space, implicitly applying the shrinking theorem known from previous work. Our algorithm is the first that applies automatic shrinking to unconstrained 3D scenes, including non-manifold meshes, and does so in real time using an efficient GPU execution model. We demonstrate that our algorithm generates a tight PVS for complex scenes and outperforms previous online methods for from-viewpoint and from-region PVS. It runs at 60 Hz for realistic game scenes consisting of millions of triangles and computes PVS with a tightness matching or surpassing existing approaches.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/YyAW88KozcA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_415" style="display:none;">
    <div>
	  Thomas Neff Brian Budge, Zhao Dong, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>PSAO: Point-Based Split Rendering for Ambient Occlusion</b>
	</div><div>
	  
	    In <i>Proc. High Performance Graphics</i>,
	  
      
	  August 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_413" style="display:none;">
    <div>
	  Domagoj Bosnjak, Antonio Pepe, Richard Schussnig, Dieter Schmalstieg, Thomas-Peter Fries:
	</div><div>
	  <b>Higher-order block-structured hex meshing of tubular structures</b>
	</div><div>
	  
	    <i>Engineering with Computers</i>, 
	    
	    
	  
      
	  May 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_411" style="display:none;">
    <div>
	  Christina Gsaxner, Jianning Li, Antonio Pepe, Yuan Jin, Jens Kleesiek, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>The HoloLens in medicine: A systematic review and taxonomy</b>
	</div><div>
	  
	    <i>Medical Image Analysis</i>, 
	    vol. 85,
	    
	  
      
	  April 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The HoloLens (Microsoft Corp., Redmond, WA), a head-worn, optically see-through augmented reality (AR) display, is the main player in the recent boost in medical AR research. In this systematic review, we provide a comprehensive overview of the usage of the first-generation HoloLens within the medical domain, from its release in March 2016, until the year of 2021. We identified 217 relevant publications through a systematic search of the PubMed, Scopus, IEEE Xplore and SpringerLink databases. We propose a new taxonomy including use case, technical methodology for registration and tracking, data sources, visualization as well as validation and evaluation, and analyze the retrieved publications accordingly. We find that the bulk of research focuses on supporting physicians during interventions, where the HoloLens is promising for procedures usually performed without image guidance. However, the consensus is that accuracy and reliability are still too low to replace conventional guidance systems. Medical students are the second most common target group, where AR-enhanced medical simulators emerge as a promising technology. While concerns about human-computer interactions, usability and perception are frequently mentioned, hardly any concepts to overcome these issues have been proposed. Instead, registration and tracking lie at the core of most reviewed publications, nevertheless only few of them propose innovative concepts in this direction. Finally, we find that the validation of HoloLens applications suffers from a lack of standardized and rigorous evaluation protocols. We hope that this review can advance medical AR research by identifying gaps in the current literature, to pave the way for novel, innovative directions and translation into the medical routine.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_412" style="display:none;">
    <div>
	  Christoph Ebner, Peter Mohr, Tobias Langlotz, Yifan Peng, Dieter Schmalstieg, Gordon Wetzstein, Denis Kalkofen:
	</div><div>
	  <b>Off-Axis Layered Displays: Hybrid Direct-View/Near-Eye Mixed Reality with Focus Cues</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	  March 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This work introduces off-axis layered displays, the first approach to stereoscopic direct-view displays with support for focus cues. Off-axis layered displays combine a head-mounted display with a traditional direct-view display for encoding a focal stack and thus, for providing focus cues. To explore the novel display architecture, we present a complete processing pipeline for the real-time computation and post-render warping of off-axis display patterns. In addition, we build two prototypes using a head-mounted display in combination with a stereoscopic direct-view display, and a more widely available monoscopic direct-view display. In addition we show how extending off-axis layered displays with an attenuation layer and with eye-tracking can improve image quality. We thoroughly analyze each component in a technical evaluation and present examples captured through our prototypes.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/EdqvMNhDsjk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_410" style="display:none;">
    <div>
	  Yvonne Jansen, Federica Bucchieri, Pierre Dragicevic, Martin Hachet, Morgane Koval, Leana Petiot, Arnaud Prouzeau, Dieter Schmalstieg, Lijie Yao, Petra Isenberg:
	</div><div>
	  <b>Envisioning Situated Visualizations of Environmental Footprints in an Urban Environment</b>
	</div><div>
	  
	    In <i>VIS 2022 Workshop on Visualization for Social Good</i>,
	  
      
	  October 2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_403" style="display:none;">
    <div>
	  Christoph Ebner, Shohei Mori, Peter Mohr, Yifan Peng, Dieter Schmalstieg, Gordon Wetzstein, Denis Kalkofen:
	</div><div>
	  <b>Video See-Through Mixed Reality with Focus Cues</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 28,
	    
	  
      
	  May 2022, Best Journal Paper at IEEE Virtual Reality 2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This work introduces the first approach to video see-through mixed reality with full support for focus cues. By combining the flexibility to adjust the focal distance found in varifocal designs with the robustness to eye-tracking error found in multifocal designs, our novel display architecture reliably delivers focus cues over a large workspace. In particular, we introduce gaze-contingent layered displays and mixed reality focal stacks, an efficient representation of mixed reality content that lends itself to fast processing for driving layered displays in real-time. We thoroughly evaluate this approach by building a complete end-to-end pipeline for capture, render, and display of focus cues in video see-through displays that uses only off-the-shelf hardware and compute components.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_405" style="display:none;">
    <div>
	  Thomas Neff, Joerg Mueller, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Meshlets and How to Shade Them: A Study on Texture-Space Shading</b>
	</div><div>
	  
	    <i>Computer Graphics Forum (Proc. EUROGRAPHICS)</i>, 
	    vol. 41,
	    
	  
      
	  May 2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Commonly used image-space layouts of shading points, such as used in deferred shading, are strictly view-dependent, which restricts efficient caching and temporal amortization. In contrast, texture-space layouts can represent shading on all surface points and can be tailored to the needs of a particular application. However, the best grouping of shading points - which we call a shading unit - in texture space remains unclear. Choices of shading unit granularity (how many primitives or pixels per unit) and in shading unit parametrization (how to assign texture coordinates to shading points) lead to different outcomes in terms of final image quality, overshading cost, and memory consumption. Among the possible choices, shading units consisting of larger groups of scene primitives, so-called meshlets, remain unexplored as of yet. In this paper, we introduce a taxonomy for analyzing existing texture-space shading methods based on the group size and parametrization of shading units. Furthermore, we introduce a novel texture-space layout strategy that operates on large shading units: the meshlet shading atlas. We experimentally demonstrate that the meshlet shading atlas outperforms previous approaches in terms of image quality, run-time performance and temporal upsampling for a given number of fragment shader invocations. The meshlet shading atlas lends itself to work together with popular cluster-based rendering of meshes with high geometric detail.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/h1Z3BU0ZlW0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_409" style="display:none;">
    <div>
	  Lucchas Ribeiro Skreinig, Ana Stanescu, Shohei Mori, Frank Heyen, Peter Mohr, Michael Sedlmair, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>AR Hero: Generating Interactive Augmented Reality Guitar Tutorials</b>
	</div><div>
	  
	    In <i>2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops</i>,
	  
      
	  March 2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_404" style="display:none;">
    <div>
	  Philipp Fleck, Aimee Sousa-Calepso, Sebastian Hubenschmid, Michael Sedlmair, Dieter Schmalstieg:
	</div><div>
	  <b>RagRug: A Toolkit for Situated Analytics</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	   2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present RagRug, an open-source toolkit for situated analytics. The abilities of RagRug go beyond previous immersive analytics toolkits by focusing on specific requirements emerging when using augmented reality (AR) rather than virtual reality. RagRug combines state of the art visual encoding capabilities with a comprehensive physical-virtual model, which lets application developers systematically describe the physical objects in the real world and their role in AR. We connect AR visualizations with data streams from the Internet of Things using distributed dataflow. To this end, we use reactive programming patterns so that visualizations become context-aware, i.e., they adapt to events coming in from the environment. The resulting authoring system is low-code; it emphasises describing the physical and the virtual world and the dataflow between the elements contained therein. We describe the technical design and implementation of RagRug, and report on five example applications illustrating the toolkit's abilities.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/mFxSdvQhSVU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_406" style="display:none;">
    <div>
	  Shohei Mori, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Good Keyframes to Inpaint</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	   2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Diminished Reality (DR) propagates pixels from a keyframe to subsequent frames for real-time inpainting. Keyframe selection has a significant impact on the inpainting quality, but untrained users struggle to identify good keyframes. Automatic selection is not straightforward either, since no previous work has formalized or verified what determines a good keyframe. We propose a novel metric to select good keyframes to inpaint. We examine the heuristics adopted in existing DR inpainting approaches and derive multiple simple criteria measurable from SLAM. To combine these criteria, we empirically analyze their effect on the quality using a novel representative test dataset. Our results demonstrate that the combined metric selects RGBD keyframes leading to high-quality inpainting results more often than a baseline approach in both color and depth domains. Also, we confirmed that our approach has a better ranking ability of distinguishing good and bad keyframes. Compared to random selections, our metric selects keyframes that would lead to higher-quality and more stably converging inpainting results. We present three DR examples, automatic keyframe selection, user navigation, and marker hiding.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/a0JOzRNFnag" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_407" style="display:none;">
    <div>
	  Fernando Reyes-Aviles, Philipp Fleck, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Compact World Anchors: Registration Using Parametric Primitives as Scene Description</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	   2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present a registration method relying on geometric constraints extracted from parametric primitives contained in 3D parametric models. Our method solves the registration in closed-form from three line-to-line, line-to-plane or plane-to-plane correspondences. The approach either works with semantically segmented RGBD scans of the scene or with the output of plane detection in common frameworks like ARKit and ARCore. Based on the primitives detected in the scene, we build a list of descriptors using the normals and centroids of all the found primitives, and match them against the pre-computed list of descriptors from the model in order to find the scene-to-model primitive correspondences. Finally, we use our closed-form solver to estimate the 6DOF transformation from three lines and one point, which we obtain from the parametric representations of the model and scene parametric primitives. Quantitative and qualitative experiments on synthetic and real-world data sets demonstrate the performance and robustness of our method. We show that it can be used to create compact world anchors for indoor localization in AR applications on mobile devices leveraging commercial SLAM capabilities.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=T1Rs_1MxXHA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_408" style="display:none;">
    <div>
	  Ana Stanescu, Peter Mohr, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Model-Free Authoring by Demonstration of Assembly Instructions in Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	   2022.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Among the most compelling applications of Augmented Reality are spatially registered tutorials. The effort of creating such instructions remains one of the obstacles precluding a wider use. We propose a system that is capable of extracting 3D instructions in a completely model-free manner from demonstrations, based on volumetric changes. The instructions are visualised later in an interactive Augmented Reality guidance application, on a mobile head-mounted display. We enable a technology that can be used by anyone in an ad-hoc tabletop setup for assemblies with rigid components.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/vk_xcGKkgYQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_402" style="display:none;">
    <div>
	  Christina Gsaxner, Antonio Pepe, Dieter Schmalstieg, Jianning Li, Jan Egger:
	</div><div>
	  <b>Inside-Out Instrument Tracking for Surgical Navigation in Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. ACM Virtual Reality Software and Technology</i>,
	  
      
	  December 2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Surgical navigation requires tracking of instruments with respect to the patient. Conventionally, tracking is done with stationary cameras, and the navigation information is displayed on a stationary display. In contrast, an augmented reality (AR) headset can superimpose surgical navigation information directly in the surgeon's view. However, AR needs to track the headset, the instruments and the patient, often by relying on stationary infrastructure. We show that 6DOF tracking can be obtained without any stationary, external system by purely utilizing the on-board stereo cameras of a HoloLens 2 to track the same retro-reflective marker spheres used by current optical navigation systems. Our implementation is based on two tracking pipelines complementing each other, one using conventional stereo vision techniques, the other relying on a single-constraint-at-a-time extended Kalman filter. In a technical evaluation of our tracking approach, we show that clinically relevant accuracy of 1.70 mm/1.11 degree and real-time performance is achievable. We further describe an example application of our system for untethered end-to-end surgical navigation.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_401" style="display:none;">
    <div>
	  Lasse Hansen, Philipp Fleck, Marco Stranner, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Augmented Reality for Subsurface Utility Engineering, Revisited</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR)</i>, 
	    vol. 11,
	    
	  
      
	  November 2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Civil engineering is a primary domain for new augmented reality technologies. In this work, the area of subsurface utility engineering is revisited, and new methods tackling well-known, yet unsolved problems are presented. We describe our solution to the outdoor localization problem, which is deemed one of the most critical issues in outdoor augmented reality, proposing a novel, lightweight hardware platform to generate highly accurate position and orientation estimates in a global context. Furthermore, we present new approaches to drastically improve realism of outdoor data visualizations. First, a novel method to replace physical spraymarkings by indistinguishable virtual counterparts is described. Second, the visualization of 3D reconstructions of real excavations is presented, fusing seamlessly with the view onto the real environment. We demonstrate the power of these new methods on a set of different outdoor scenarios.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=cdWCWNEyy38" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_395" style="display:none;">
    <div>
	  Barrett Ens, Benjamin Bach, Maxime Cordeil, Ulrich Engelke, Marcos Serrano, Wesley Willett, Arnaud Prouzeau, Christoph Anthes, Wolfgang Bueschel, Cody Dunne, Tim Dwyer, Jens Grubert, Jason Haga, Nurit Kirshenbaum, Dylan Kobayashi, Tica Lin, Monsurat Olaosebikan, Fabian Pointecker, David Saffo, Nazmus Saquib, Dieter Schmalstieg, Danielle Albers Szafir, Matthew Whitlock, Yalong Yang:
	</div><div>
	  <b>Grand Challenges in Immersive Analytics</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  May 2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Immersive Analytics is a quickly evolving field that unites several areas such as visualisation, immersive environments, and human computer interaction to support human data analysis with emerging technologies. This research has thrived over the past years with multiple workshops, seminars, and a growing body of publications, spanning several conferences. Given the rapid advancement of interaction technologies and novel application domains, this paper aims toward a broader research agenda to enable widespread adoption. We present 17 key research challenges developed over multiple sessions by a diverse group of 24 international experts, initiated from a virtual scientific workshop at ACM CHI 2020. These challenges aim to coordinate future work by providing a systematic roadmap of current directions and impending hurdles to facilitate productive and effective applications for Immersive Analytics.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_396" style="display:none;">
    <div>
	  Joerg Mueller, Thomas Neff, Philip Voglreiter, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Temporally Adaptive Shading Reuse for Real-Time Rendering and Virtual Reality</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics</i>, 
	    
	    
	  
      
	   2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Temporal coherence has the potential to enable a huge reduction of shading costs in rendering. Existing techniques focus either only on spatial shading reuse or cannot adaptively choose temporal shading frequencies. We find that temporal shading reuse is possible for extended periods of time for a majority of samples, and we show under which circumstances users perceive temporal artifacts. Our analysis implies that we can approximate shading gradients to efficiently determine when and how long shading can be reused. While visibility usually stays temporally coherent from frame to frame for more than 90 percent, we find that, even in heavily animated game scenes with advanced shading, typically more than 50 percent of shading is temporally coherent. To exploit this potential, we introduce a temporally adaptive shading framework and apply it to two real-time methods. Its application saves more than 57 percent of the shader invocations, reducing overall rendering times up to 5 times in virtual reality applications without a noticeable loss in visual quality. Overall, our work shows that there is significantly more potential for shading reuse than currently exploited.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=TZvgqiOgyVk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_397" style="display:none;">
    <div>
	  Salvatore Andolina, Yi-Ta Hsieh, Denis Kalkofen, Antti Nurminen, Diogo Cabral, Anna Spagnolli, Luciano Gamberini, Ann Morrison, Dieter Schmalstieg, Giulio Jacucci:
	</div><div>
	  <b>Designing for Mixed Reality Urban Exploration</b>
	</div><div>
	  
	    <i>Journal of Interaction Design and Architecture(s)</i>, 
	    
	    
	  
      
	   2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_398" style="display:none;">
    <div>
	  Christina Gsaxner, Ulrich Eck, Dieter Schmalstieg, Nassir Navab, Jan Egger:
	</div><div>
	  <b>Augmented reality in oral and maxillofacial surgery</b>
	</div><div>
	  
      
	   2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Augmented reality (AR) is a technology which extends the user's reality by including computer-generated, virtual information within their view. As such, AR technology is a valuable asset in the medical domain, where it has the potential to grant X-ray vision to physicians, allowing them to view medical data in situ, in the same physical space as the patient, in the most intuitive way. Consequently, medical applications have been the focus of considerable research efforts since the early days of AR, be it in the context of medical education and training, patient rehabilitation and therapy, or in clinical applications such as computer-aided interventions. In this chapter, we will review the most important technical concepts of AR in general, discussing display technology, tracking paradigms and visualization techniques, among other things. Furthermore, we provide an extensive overview over current applications, practices, and challenges of AR, specific to the medical domain. Finally, AR in oral and cranio-maxillofacial surgery will be discussed, starting with a discussion of shortcomings of current computer-assisted procedures and how AR can aid to overcome them. We then provide a historical perspective on AR in oral and maxillofacial surgery, ending with a review of the current state-of-the-art.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_399" style="display:none;">
    <div>
	  Jianning Li, Pedro Pimentel, Angelika Szengel, Moritz Ehlke, Hans Lamecker, Stefan Zachow, Laura Estacio, Christian Doenitz, Heiko Ramm, Haochen Shi, Xiaojun Chen, Franco Matzkin, Virginia Newcombe, Enzo Ferrante, Yuan Jin, David G. Ellis, Michele R. Aizenberg, Oldrich Kodym, Michal Spanel, Adam Herout, James G. Mainprize, Zachary Fishman, Michael R. Hardisty, Amirhossein Bayat, Suprosanna Shit, Bomin Wang, Zhi Liu, Matthias Eder, Antonio Pepe, Christina Gsaxner, Victor Alves, Ulrike Zefferer, Gord von Campe, Karin Pistracher, Ute Schaefer, Dieter Schmalstieg, Bjoern H. Menze, Ben Glocker, Jan Egger:
	</div><div>
	  <b>AutoImplant 2020 - First MICCAI Challenge on Automatic Cranial Implant Design</b>
	</div><div>
	  
	    <i>IEEE Transactions on Medical Imaging</i>, 
	    
	    
	  
      
	   2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The aim of this paper is to provide a comprehensive overview of the MICCAI 2020 AutoImplant Challenge1. The approaches and publications submitted and accepted within the challenge will be summarized and reported, highlighting common algorithmic trends and algorithmic diversity. Furthermore, the evaluation results will be presented, compared and discussed in regard to the challenge aim: seeking for low cost, fast and fully automated solutions for cranial implant design. Based on feedback from collaborating neurosurgeons, this paper concludes by stating open issues and post-challenge requirements for intra-operative use. The codes can be found at https://github.com/Jianningli/tmi.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_400" style="display:none;">
    <div>
	  Jianning Li, Gord {von Campe}, Antonio Pepe, Christina Gsaxner, Enpeng Wang, Xiaojun Chen, Ulrike Zefferer, Martin Toedtling, Marcell Krall, Hannes Deutschmann, Ute Schaefer, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Automatic Skull Defect Restoration and Cranial Implant Generation for Cranioplasty</b>
	</div><div>
	  
	    <i>Medical Image Analysis</i>, 
	    
	    
	  
      
	   2021.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">A fast and fully automatic design of 3D printed patient-specific cranial implants is highly desired in cranioplasty - the process to restore a defect on the skull. We formulate skull defect restoration as a 3D volumetric shape completion task, where a partial skull volume is completed automatically. The difference between the completed skull and the partial skull is the restored defect; in other words, the implant that can be used in cranioplasty. To fulfill the task of volumetric shape completion, a fully data-driven approach is proposed. Supervised skull shape learning is performed on a database containing 167 high-resolution healthy skulls. In these skulls, synthetic defects are injected to create training and evaluation data pairs. We propose a patch-based training scheme tailored for dealing with high-resolution and spatially sparse data, which overcomes the disadvantages of conventional patch-based training methods in high-resolution volumetric shape completion tasks. In particular, the conventional patch-based training is applied to images of high resolution and proves to be effective in tasks such as segmentation. However, we demonstrate the limitations of conventional patch-based training for shape completion tasks, where the overall shape distribution of the target has to be learnt, since it cannot be captured efficiently by a sub-volume cropped from the target. Additionally, the standard dense implementation of a convolutional neural network tends to perform poorly on sparse data, such as the skull, which has a low voxel occupancy rate. Our proposed training scheme encourages a convolutional neural network to learn from the high-resolution and spatially sparse data. In our study, we show that our deep learning models, trained on healthy skulls with synthetic defects, can be transferred directly to craniotomy skulls with real defects of greater irregularity, and the results show promise for clinical use. Project page: https://github.com/Jianningli/MIA.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_392" style="display:none;">
    <div>
	  Philipp Fleck, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Creating IoT-Ready XR-WebApps with Unity3D</b>
	</div><div>
	  
	    In <i>ACM International Conference on 3D Web Technology</i>,
	  
      
	  November 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The rise of IoT-ready devices is supported through well-established web concepts for communication and analytics, but interaction yet remains in the world of web browsers and screen-based 2D interaction during times of tablet and smartphone popularity. Transforming IoT interaction concepts into 3D for future exploitation with head-worn XR devices is a difficult task due to the lack of support and continued disengagement of game engines used in XR development. In this work, we present an approach to overcome this limitation, tightly including web technology into a 3D game engine. Our work leverages the versatility of web concepts to create immersive and scalable web applications in XR, without the need for deep-tech know-how about XR concepts or tiring customization work. We describe the methodology and tools in detail and provide some exemplary XR applications.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_380" style="display:none;">
    <div>
	  Shohei Mori, Okan Erat, Wolfgang Broll, Hideo Saito, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>InpaintFusion:Incremental RGB-D Inpainting for 3D Scenes</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	  October 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">State-of-the-art methods for diminished reality propagate pixel information from a keyframe to subsequent frames for real-time inpainting. However, these approaches produce artifacts, if the scene geometry is not sufficiently planar. In this paper, wepresent InpaintFusion, a new real-time method that extends inpainting to non-planar scenes by considering both color and depth information in the inpainting process. We use an RGB-D sensor for simultaneous localization and mapping, in order to both track the camera and obtain a surfel map in addition to RGB images. We use the RGB-D information in a cost function for both the color and the geometric appearance to derive a global optimization for simultaneous inpainting of color and depth. The inpainted depth is merged in a global map by depth fusion. For the final rendering, we project the map model into image space, where we can use it for effects such as relighting and stereo rendering of otherwise hidden structures. We demonstrate the capabilities of our method by comparing it to inpainting results with methods using planar geometric proxies.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=RPqf7wAEkZQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_391" style="display:none;">
    <div>
	  Leonel Merino, Magdalena Schwarzl, Matthias Kraus, Michael Sedlmair, Dieter Schmalstieg, Daniel Weiskopf:
	</div><div>
	  <b>Evaluating Mixed and Augmented Reality: A Systematic Literature Review (2009-2019)</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality</i>,
	  
      
	  October 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_393" style="display:none;">
    <div>
	  Antonio Pepe, Gabriel Mistelbauer, Christina Gsaxner, Jianning Li, Dominik Fleischmann, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Semi-supervised Virtual Regression of Aortic Dissections Using 3D Generative Inpainting</b>
	</div><div>
	  
	    In <i>Proc. International Workshop on Thoracic Image Analysis</i>,
	  
      
	  October 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_377" style="display:none;">
    <div>
	  Johannes Unterguggenberger, Bernhard Kerbl, Markus
Steinberger, Dieter Schmalstieg, Michael Wimmer:
	</div><div>
	  <b>Fast Multi-View Rendering for Real-Time Applications</b>
	</div><div>
	  
	    In <i>Eurographics Symposium on Parallel Graphics and Visualization</i>,
	  
      
	  May 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Efficient rendering of multiple views can be a critical performance factor for real-time rendering applications. Generating more than one view multiplies the amount of rendered geometry, which can cause a huge performance impact. Minimizing that impact has been a target of previous research and GPU manufacturers, who have started to equip devices with dedicated acceleration units. However, vendor-specific acceleration is not the only option to increase multi-view rendering (MVR) performance. Available graphics API features, shader stages and optimizations can be exploited for improved MVR performance, while generally offering more versatile pipeline configurations, including the preservation of custom tessellation and geometry shaders. In this paper, we present an exhaustive evaluation of MVR pipelines available on modern GPUs. We provide a detailed analysis of previous techniques, hardware-accelerated MVR and propose a novel method, leading to the creation of an MVR catalogue. Our analyses cover three distinct applications to help gain clarity on overall MVR performance characteristics. Our interpretation of the observed results provides a guideline for selecting the most appropriate one for various use cases on different GPU architectures.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_378" style="display:none;">
    <div>
	  Fernando Reyes-Aviles, Philipp Fleck, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Improving RGB Image Consistency for Depth-Camera</b>
	</div><div>
	  
	    <i>Journal of WSCG</i>, 
	    vol. 28,
	    
	  
      
	  May 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_390" style="display:none;">
    <div>
	  Dieter Schmalstieg, Philipp Fleck:
	</div><div>
	  <b>Towards Embedded Visualization Authoring</b>
	</div><div>
	  
	    In <i>Proc. ACM CHI Workshop on Immersive Analytics</i>,
	  
      
	  May 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_374" style="display:none;">
    <div>
	  Peter Mohr-Ziak, Shohei Mori, Tobias Langlotz, Bruce Thomas, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Mixed Reality Light Fields for Interactive Remote Assistance</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  April 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Remote assistance represents an important use case for mixed reality. With the rise of handheld and wearable devices, remote assistance has become practical in the wild. However, spontaneous provisioning of remote assistance requires an easy, fast and robust approach for capturing and sharing of unprepared environments. In this work, we make a case for utilizing interactive light fields for remote assistance. We demonstrate the advantages of object representation using light fields over conventional geometric reconstruction. Moreover, we introduce an interaction method for quickly annotating light fields in 3D space without requiring surface geometry to anchor annotations. We present results from a user study demonstrating the effectiveness of our interaction techniques, and we provide feedback on the usability of our overall system.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=NNmt-5NMuOk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_375" style="display:none;">
    <div>
	  Mehdi Stapleton, Dieter Schmalstieg, Clemens Arth, Thomas Gloor:
	</div><div>
	  <b>Learning Effective Sparse Sampling Strategies using Deep Active Sensing</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Computer Vision Theory and Applications (VISAPP)</i>,
	  
      
	  February 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Registering a known model with noisy sample measurements is in general a difficult task due to the problem in finding correspondences between the samples and points on the known model. General frameworks exist, such as variants of the classical iterative closest point (ICP) method to iteratively refine correspondence estimates. However, the methods are prone to getting trapped in locally optimal configurations, which may be far from the true registration. The quality of the final registration depends strongly on the set of samples. The quality of the set of sample measurements is more noticeable when the number of samples is relatively low (about 20). We consider sample selection in the context of active perception, i.e. an objective-driven decision-making process, to motivate our research and the construction of our system. We design a system for learning how to select the regions of the scene to sample, and, in doing so, improve the accuracy and efficiency of the sampling process. We present a full environment for learning how best to sample a scene in order to quickly and accurately register a model with the scene. This work has broad applicability from the fields of geodesy to medical robotics, where the cost of taking a measurement is much higher than the cost of incremental changes to the pose of the equipment.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_376" style="display:none;">
    <div>
	  Philipp Fleck, Fernando Reyes-Aviles, Christian Pirchheim, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>MAUI: Tele-Assistence for Maintenance of Cyber-Physical Systems</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Computer Vision Theory and Applications (VISAPP)</i>,
	  
      
	  February 2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we present the maintenance assistance user interface (MAUI), a novel approach for providing tele-assistance to a worker charged with maintenance of a cyber-physical system. Such a system comprises both physical and digital interfaces, making it challenging for a worker to understand the required steps and to assess work progress. A remote expert can access the digital interfaces and provide the worker with timely information and advice in an augmented reality display. The remote expert has full control over the user interface of the worker in a manner comparable to remote desktop systems. The worker needs to perform all physical operations and retrieve physical information, such as reading physical labels or meters. Thus, worker and remote expert collaborate not only via shared audio, video or pointing, but also share control of the digital interface presented in the augmented reality space. We report results on two studies: The first study evaluates the benefits of our system against a condition with the same cyber-physical interface, but without tele-assistance. Results indicate significant benefits concerning speed, cognitive load and subjective comfort of the worker. The second study explores how interface designers use our system, leading to initial design guidelines for tele-presence interfaces like ours.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_379" style="display:none;">
    <div>
	  Christina Gsaxner, Antonio Pepe, Jianning Li, Una Ibrahimpasic, Juergen Wallner, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Augmented Reality for Head and Neck Carcinoma Imaging: Description and Feasibility of an Instant Calibration, Markerless Approach</b>
	</div><div>
	  
	    <i>Computer Methods and Programs in Biomedicine</i>, 
	    
	    
	  
      
	   2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_394" style="display:none;">
    <div>
	  Manuela Waldner, Thomas Geymayer, Dieter Schmalstieg, Michael Sedlmair:
	</div><div>
	  <b>Linking unstructured evidence to structured observations</b>
	</div><div>
	  
	    In <i>SAGE Information Visualization</i>,
	  
      
	   2020.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_369" style="display:none;">
    <div>
	  Okan Erat, Markus Hoell, Karl Haubenwallner, Christian Pirchheim, Dieter Schmalstieg:
	</div><div>
	  <b>Real-Time View Planning for Unstructured Lumigraph Modeling</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    
	    
	  
      
	  October 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We propose an algorithm for generating an unstructured lumigraph in real-time from an image stream. This problem has important applications in mixed reality, such as telepresence, interior design or as-built documentation. Unlike conventional texture optimization in structure from motion, our method must choose views from the input stream in a strictly incremental manner, since only a small number of views can be stored or transmitted. This requires formulating an online variant of the well-known view-planning problem, which must take into account what parts of the scene have already been seen and how the lumigraph sample distribution could improve in the future. We address this highly unconstrained problem by regularizing the scene structure using a regular grid structure. Upon the grid structure, we define a coverage metric describing how well the lumigraph samples cover the grid in terms of spatial and angular resolution, and we greedily keep incoming views if they improve the coverage. We evaluate the performance of our algorithm quantitatively and qualitatively on a variety of synthetic and real scenes, and demonstrate visually appealing results obtained at real-time frame rates (in the range of 3Hz-100Hz per incoming image, depending on configuration).</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=LCL4pv7Klpw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_370" style="display:none;">
    <div>
	  Christina Gsaxner, Antonio Pepe, Juergen Wallner, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Markerless Image-to-Face Registration for Untethered Augmented Reality in Head and Neck Surgery</b>
	</div><div>
	  
	    In <i>Proceedings MICCAI</i>,
	  
      
	  October 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In the treatment of head and neck cancer, physicians can benefit from augmented reality in preparing and executing treatment. We present a system allowing a physician wearing an untethered augmented reality headset to see medical visualizations precisely overlaid onto the patient. Our main contribution is a strategy for markerless registration of 3D imaging to the patient's face. We use a neural network to detect the face using the headset's depth sensor and register it to computed tomography data. The face registration is seamlessly combined with the headset's continuous self-localization. We report on registration error and compare our approach to an external, high-precision infrared tracking system.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_372" style="display:none;">
    <div>
	  Marco Stranner, Philipp Fleck, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>A High-Precision Localization Device for Outdoor Augmented Reality</b>
	</div><div>
	  
	    In <i>IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In contrast to indoor tracking using computer vision, which has reached a good amount of maturity, outdoor tracking still suffers from comparably poor localization on a global scale. Smartphones and other commodity devices contain consumer-grade sensors for GPS, compass and inertial measurements, which are not accurate enough for augmented reality (AR) in most situations. This restricts what AR can offer to application areas such as surveying or building constructions. We present a self-contained localization device which connects wirelessly to any AR device, such as a smartphone or headset. The device gives centimeter-level accuracy and can be built out of commercial-of-the-shelf components for less than 500 EUR. We demonstrate the performance of the localization device using a variety of position and orientation sensing benchmarks.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_371" style="display:none;">
    <div>
	  Ryo Hachiuma, Christian Pirchheim, Dieter Schmalstieg, Hideo Saito:
	</div><div>
	  <b>DetectFusion: Detecting and Segmenting Both Known and Unknown Dynamic Objects in Real-time SLAM</b>
	</div><div>
	  
	    In <i>Proceedings British Machine Vision Conference (BMVC)</i>,
	  
      
	  September 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present DetectFusion, an RGB-D SLAM system that runs in real time and can ro-bustly handle semantically known and unknown objects that can move dynamically inthe scene. Our system detects, segments and assigns semantic class labels to knownobjects in the scene, while tracking and reconstructing them even when they move in-dependently in front of the monocular camera. In contrast to related work, we achievereal-time computational performance on semantic instance segmentation with a novelmethod combining 2D object detection and 3D geometric segmentation. In addition, wepropose a method for detecting and segmenting the motion of semantically unknown ob-jects, thus further improving the accuracy of camera tracking and map reconstruction. We show that our method performs on par or better than previous work in terms of lo-calization and object reconstruction accuracy, while achieving about 20 fps even if theobjects are segmented in each frame</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=Ys3FXEP3A_4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_373" style="display:none;">
    <div>
	  W. Alexander Isop, Christoph Gebhardt, Tobias Naegeli, Friedrich Fraundorfer, Otmar Hilliges, D. Schmalstieg:
	</div><div>
	  <b>High-Level Teleoperation System For Aerial Exploration Of Indoor Environments</b>
	</div><div>
	  
	    <i>Frontiers in Robotics and AI</i>, 
	    
	    
	  
      
	  September 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Exploration of challenging indoor environments is a demanding task. While automation with aerial robots seems a promising solution, fully autonomous systems still struggle with high-level cognitive tasks and intuitive decision making. To facilitate automation, we introduce a novel teleoperation system with an aerial telerobot that is capable of handling all demanding low-level tasks. Motivated by the typical structure of indoor environments, the system creates an interactive scene topology in real-time that reduces scene details and supports affordances. Thus, difficult high-level tasks can be effectively supervised by a human operator. To elaborate on the effectiveness of our system during a real-world exploration mission, we conducted a user study. Despite being limited by real-world constraints, results indicate that our system better supports operators with indoor exploration, compared to a baseline system with traditional joystick control.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_365" style="display:none;">
    <div>
	  Markus Dokter, Jozef Hladky, Matthias Parger, Dieter Schmalstieg, Hans-Peter Seidel, Markus Steinberger:
	</div><div>
	  <b>Hierarchical Rasterization of Curved Primitives for Vector Graphics Rendering on the GPU</b>
	</div><div>
	  
	    <i>Computer Graphics Forum (Proc. EUROGRAPHICS)</i>, 
	    
	    
	  
      
	  May 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we introduce the CPatch, a curved primitive that can be used to construct arbitrary vector graphics. A CPatch is a generalization of a 2D polygon: Any number of curves up to a cubic degree bound a primitive. We show that a CPatch can be rasterized efficiently in a hierarchical manner on the GPU, locally discarding irrelevant portions of the curves. Our rasterizer is fast and scalable, works on all patches in parallel, and does not require any approximations. We show a parallel implementation of our rasterizer, which naturally supports all kinds of color spaces, blending and super-sampling. Additionally, we show how vector graphics input can efficiently be converted to a CPatch representation, solving challenges like patch self intersections and false inside-outside classification. Results indicate that our approach is faster than the state-of-the-art, more flexible and could potentially be implemented in hardware.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_366" style="display:none;">
    <div>
	  Peter Mohr, Markus Tatzgern, Tobias Langlotz, Andreas Lang, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>TrackCap: Enabling Smartphones for 3D Interaction on Mobile Head-Mounted Displays</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  May 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The latest generation of consumer market head-mounted displays (HMD) now include self-contained inside-out tracking of head motions, which makes them suitable for mobile applications. However, 3D tracking of input devices is either not included at all or requires to keep the device in sight, so that it can be observed from a sensor mounted on the HMD. Both approaches make natural interactions cumbersome in mobile applications. TrackCap, a novel approach for 3D tracking of input devices, turns a conventional smart-phone into a precise 6DOF input device for an HMD user. The device can be conveniently operated both inside and outside the HMD's field of view, while it provides additional 2D input and output capabilities.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/http://youtu.be/cwi8HUxMkLo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_368" style="display:none;">
    <div>
	  Dieter Schmalstieg:
	</div><div>
	  <b>Unified Patterns for Realtime Interactive Simulation in Games and Digital Storytelling</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 39,
	    
	  
      
	  January 2019.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_364" style="display:none;">
    <div>
	  Mathias Parger, Joerg Mueller, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Human Upper-Body Inverse Kinematics for Increased Embodiment in Consumer-Grade Virtual Reality</b>
	</div><div>
	  
	    In <i>Proc. ACM Virtual Reality Software and Technology (VRST)</i>,
	  
      
	  December 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Having a virtual body can increase embodiment in virtual reality (VR) applications. However, comsumer-grade VR falls short of delivering sufficient sensory information for full-body motion capture. Consequently, most current VR applications do not even show arms, although they are often in the field of view. We address this shortcoming with a novel human upper-body inverse kinematics algorithm specifically targeted at tracking from head and hand sensors only. We present heuristics for elbow positioning depending on the shoulder-to-hand distance and for avoiding reaching unnatural joint limits. Our results show that our method increases the accuracy compared to general inverse kinematics applied to human arms with the same tracking input. In a user study, participants preferred our method over displaying disembodied hands without arms, but also over a more expensive motion capture system. In particular, our study shows that virtual arms animated with our inverse kinematics system can be used for applications involving heavy arm movement. We demonstrate that our method can not only be used to increase embodiment, but can also support interaction involving arms or shoulders, such as holding up a shield.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/yasn-aTXa8g" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_362" style="display:none;">
    <div>
	  Joerg Mueller, Philip Voglreiter, Mark Dokter, Thomas Neff, Mina Makar, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Shading Atlas Streaming</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics (Proc. SIGGRAPH Asia)</i>, 
	    vol. 37,
	    
	  
      
	  November 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Streaming high quality rendering for virtual reality applications requires minimizing perceived latency. We introduce Shading Atlas Streaming (SAS), a novel object-space rendering framework suitable for streaming virtual reality content. SAS decouples server-side shading from client-side rendering, allowing the client to perform framerate upsampling and latency compensation autonomously for short periods of time. The shading information created by the server in object space is temporally coherent and can be efficiently compressed using standard MPEG encoding. Our results show that SAS compares favorably to previous methods for remote image-based rendering in terms of image quality and network bandwidth efficiency. SAS allows highly efficient parallel allocation in a virtualized-texture-like memory hierarchy, solving a common efficiency problem of object-space shading. With SAS, untethered virtual reality headsets can benefit from high quality rendering without paying in increased latency.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=ZW8MOwpOwI8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_367" style="display:none;">
    <div>
	  Antonio Pepe, Gianpaolo Trotta, Christina Gsaxner, Dieter Schmalstieg, Juergen Wallner, Jan Egger, Vitoantonio Bevilacqua:
	</div><div>
	  <b>Pattern Recognition and Mixed Reality for Computer-Aided Maxillofacial Surgery and Oncological Assessment</b>
	</div><div>
	  
	    In <i>IEEE Biomedical Engineering International Conference</i>,
	  
      
	  November 2018, Best paper award..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_357" style="display:none;">
    <div>
	  Shohei Mori, Jan Herling, Wolfgang Broll, Norihiko Kawai, Hideo Saito, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>3D PixMix: Image-Inpainting in 3D Environments</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_358" style="display:none;">
    <div>
	  Ana Stanescu, Philipp Fleck, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Semantic Segmentation of Geometric Primitives in Dense 3D Point clouds using Machine Learning</b>
	</div><div>
	  
	    In <i>Proc. IEEE Internatational Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_359" style="display:none;">
    <div>
	  Christoph Klug, Clemens Arth, Dieter Schmalstieg, Thomas Gloor:
	</div><div>
	  <b>Semi-Automatic Registration of a Robotic Total Station and a CAD Model Without Control Points</b>
	</div><div>
	  
	    In <i>Proc. IEEE Industrial Electronics Conference (IECON)</i>,
	  
      
	  October 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_363" style="display:none;">
    <div>
	  Christoph Klug, Clemens Arth, Dieter Schmalstieg, Thomas Gloor:
	</div><div>
	  <b>Measurement Uncertainty Analysis of a Robotic Total Station Simulation</b>
	</div><div>
	  
	    In <i>Proc. IEEE Industrial Electronics Conference (IECON)</i>,
	  
      
	  October 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_360" style="display:none;">
    <div>
	  Christoph Klug, Dieter Schmalstieg, Thomas Gloor, Clemens Arth:
	</div><div>
	  <b>A Complete Workfow for Automatic Forward Kinematics Model Extraction of Robotic Total Stations Using the Denavit-Hartenberg Convention</b>
	</div><div>
	  
	    In <i>J. Intell. Robot. Syst.</i>,
	  
      
	  September 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_350" style="display:none;">
    <div>
	  Michael Kenzel, Bernhard Kerbl, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>A High-Performance Software Graphics Pipeline Architecture for the GPU</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics (Proceedings SIGGRAPH)</i>, 
	    vol. 37,
	    
	  
      
	  August 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we present a real-time graphics pipeline implemented entirely in software on a modern GPU. As opposed to previous work, our approach features a fully-concurrent, multi-stage, streaming design with dynamic load balancing, capable of operating efficiently within bounded memory. We address issues such as primitive order, vertex reuse, and screen-space derivatives of dependent variables, which are essential to real-world applications, but have largely been ignored by comparable work in the past. The power of a software approach lies in the ability to tailor the graphics pipeline to any given application. In exploration of this potential, we design and implement four novel pipeline modifications. Evaluation of the performance of our approach on more than 100 real-world scenes collected from video games shows rendering speeds within one order of magnitude of the hardware graphics pipeline as well as significant improvements over previous work, not only in terms of capabilities and performance, but also robustness.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=UzEtinmdXE8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_351" style="display:none;">
    <div>
	  Bernhard Kerbl, Michael Kenzel, Elena Ivanchenko, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>Revisiting The Vertex Cache: Understanding and Optimizing Vertex Processing on the modern GPU</b>
	</div><div>
	  
	    <i>Proceedings of the ACM on Computer Graphics and Interactive Techniques</i>, 
	    vol. 1,
	    
	  
      
	  August 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_352" style="display:none;">
    <div>
	  Michael Kenzel, Bernhard Kerbl, Wolfgang Tatzgern, Elena Ivanchenko, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>On-the-fly Vertex Reuse for Massively-Parallel Software Geometry Processing</b>
	</div><div>
	  
	    <i>Proceedings of the ACM on Computer Graphics and Interactive Techniques</i>, 
	    vol. 1,
	    
	  
      
	  August 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_355" style="display:none;">
    <div>
	  Jan Egger, Birgit Pfarrkirchner, Christina Gsaxner, Lydia Lindner, Dieter Schmalstieg, Juergen Wallner:
	</div><div>
	  <b>Fully Convolutional Mandible Segmentation on a valid Ground-Truth Dataset</b>
	</div><div>
	  
	    In <i>Proc. IEEE Engineering in Medicine and Biology Conference (EMBC)</i>,
	  
      
	  July 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_344" style="display:none;">
    <div>
	  Alexander Bornik, Martin Urschler, Dieter Schmalstieg, Horst Bischof, Astrid Krauskopf, Thorsten Schwark, Eva Scheurer, Kathrin Yen:
	</div><div>
	  <b>Integrated Computer-aided Forensic Case Analysis, Presentation, and Documentation based on Multimodal 3D Data</b>
	</div><div>
	  
	    <i>Forensic Science International</i>, 
	    vol. 287,
	    
	  
      
	  June 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Three-dimensional (3D) crime scene documentation using 3D scanners and medical imaging modalities like computed tomography (CT) and magnetic resonance imaging (MRI) are increasingly applied in forensic casework. Together with digital photography, these modalities enable comprehensive and non-invasive recording of forensically relevant information regarding injuries/pathologies inside the body and on its surface. Furthermore, it is possible to capture traces and items at crime scenes. Such digitally secured evidence has the potential to similarly increase case understanding by forensic experts and non-experts in court. Unlike photographs and 3D surface models, images from CT and MRI are not self-explanatory. Their interpretation and understanding requires radiological knowledge. Findings in tomography data must not only be revealed, but should also be jointly studied with all the 2D and 3D data available in order to clarify spatial interrelations and to optimally exploit the data at hand. This is technically challenging due to the heterogeneous data representations including volumetric data, polygonal 3D models, and images. This paper presents a novel computer-aided forensic toolbox providing tools to support the analysis, documentation, annotation, and illustration of forensic cases using heterogeneous digital data. Conjoint visualization of data from different modalities in their native form and efficient tools to visually extract and emphasize findings help experts to reveal unrecognized correlations and thereby enhance their case understanding. Moreover, the 3D case illustrations created for case analysis represent an efficient means to convey the insights gained from case analysis to forensic non-experts involved in court proceedings like jurists and laymen. The capability of the presented approach in the context of case analysis, its potential to speed up legal procedures and to ultimately enhance legal certainty is demonstrated by introducing a number of representative forensic cases.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_353" style="display:none;">
    <div>
	  Bernhard Kerbl, Michael Kenzel, Joerg Mueller, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>The Broker Queue: A Fast, Linearizable FIFO Queue for Fine-Granular Work Distribution on the GPU</b>
	</div><div>
	  
	    In <i>Proc. of the International Conference on Supercomputing (ICS)</i>,
	  
      
	  June 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Harnessing the power of massively parallel devices like the graphics processing unit (GPU) is difficult for algorithms that show dynamic or inhomogeneous workloads. To achieve high performance, such advanced algorithms require scalable, concurrent queues to collect and distribute work. We show that previous queuing approaches are unfit for this task, as they either (1) do not work well in a massively parallel environment, or (2) obstruct the use of individual threads on top of single-instruction-multiple-data (SIMD) cores, or (3) block during access, thus prohibiting multi-queue setups. With these issues in mind, we present the Broker Queue, a highly efficient, fully linearizable FIFO queue for fine-granular parallel work distribution on the GPU. We evaluate its performance and usability on modern GPU models against a wide range of existing algorithms. The Broker Queue is up to three orders of magnitude faster than non-blocking queues and can even outperform significantly simpler techniques that lack desired properties for fine-granular work distribution.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_356" style="display:none;">
    <div>
	  Juergen Wallner, Kerstin Hochegger, Xiaojun Chen, Irene Mischak, Knut Reinbacher, Mauro Pau, Tomislav Zrnc, Katja Schwenzer-Zimmerer, Wolfgang Zemann, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Clinical evaluation of semi-automatic open-source algorithmic software segmentation of the mandibular bone: Practical feasibility and assessment of a new course of action</b>
	</div><div>
	  
	    <i>PLoS ONE</i>, 
	    vol. 13,
	    
	  
      
	  May 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_341" style="display:none;">
    <div>
	  Okan Erat, W. Alexander Isop, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Drone-Augmented Human Vision: Exocentric Control for Drones Exploring Hidden Areas</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 24,
	    
	  
      
	  April 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Drones allow exploring dangerous or impassable areas safely from a distant point of view. However, flight control froman egocentric view in narrow or constrained environments can be challenging. Arguably, an exocentric view would afford a betteroverview and, thus, more intuitive flight control of the drone. Unfortunately, such an exocentric view is unavailable when exploringindoor environments. This paper investigates the potential of drone-augmented human vision, i.e., of exploring the environment andcontrolling the drone indirectly from an exocentric viewpoint. If used with a see-through display, this approach can simulate X-rayvision to provide a natural view into an otherwise occluded environment. The user's view is synthesized from a three-dimensionalreconstruction of the indoor environment using image-based rendering. This user interface is designed to reduce the cognitive load ofthe drone's flight control. The user can concentrate on the exploration of the inaccessible space, while flight control is largely delegatedto the drone's autopilot system. We assess our system with a first experiment showing how drone-augmented human vision supportsspatial understanding and improves natural interaction with the drone.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=drwgdPe7VzE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_342" style="display:none;">
    <div>
	  Rafael Roberto, Joao Paulo Lima, Hideaki Uchiyama, Clemens Arth, Veronica Teichrieb, Rin-Ichiro Taniguchi, Dieter Schmalstieg:
	</div><div>
	  <b>Incremental Structural Modeling Based on Geometric and Statistical Analyses</b>
	</div><div>
	  
	    In <i>Proc. Winter Conference on Application of Computer Vision (WACV)</i>,
	  
      
	  March 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_345" style="display:none;">
    <div>
	  Lydia Lindner, Birgit Pfarrkirchner, Christina Gsaxner, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>TuMore: generation of synthetic brain tumor MRI data for deep learning based segmentation approaches</b>
	</div><div>
	  
	    In <i>Proceedings of SPIE Medical Imaging</i>,
	  
      
	  February 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_346" style="display:none;">
    <div>
	  Simon Gunacker, Markus Gall, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Multi-threaded integration of HTC-Vive and MeVisLab</b>
	</div><div>
	  
	    In <i>Proceedings of SPIE Medical Imaging</i>,
	  
      
	  February 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_347" style="display:none;">
    <div>
	  Birgit Pfarrkirchner, Christina Gsaxner, Lydia Lindner, Norbert Jakse, Juergen Wallner, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Lower jawbone data generation for deep learning tools under MeVisLab</b>
	</div><div>
	  
	    In <i>Proceedings of SPIE Medical Imaging</i>,
	  
      
	  February 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_348" style="display:none;">
    <div>
	  Christina Gsaxner, Birgit Pfarrkirchner, Lydia Lindner, Norbert Jakse, Juergen Wallner, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Exploit 18F-FDG enhanced urinary bladder in PET data for deep learning ground truth generation in CT scans</b>
	</div><div>
	  
	    In <i>Proceedings of SPIE Medical Imaging</i>,
	  
      
	  February 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_354" style="display:none;">
    <div>
	  Bernhard Kerbl, Joerg Mueller, Michael Kenzel, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>A Scalable Queue for Work Distribution on GPUs</b>
	</div><div>
	  
	    <i>SIGPLAN Not.</i>, 
	    vol. 53,
	    
	  
      
	  February 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_343" style="display:none;">
    <div>
	  Giulio Jacucci, Salvatore Andolina, Denis Kalkofen, Dieter Schmalstieg, Antti Nurminen, Anna Spagnolli, Luciano Gamberini, Tuukka Ruotsalo:
	</div><div>
	  <b> Combining Intelligent Recommendation and Mixed Reality in Itineraries for Urban Exploration</b>
	</div><div>
	  
	    <i>International SERIES on Information Systems and Management in Creative eMedia (CreMedia)</i>, 
	    vol. 2017,
	    
	  
      
	  January 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_361" style="display:none;">
    <div>
	  Christoph Klug, Dieter Schmalstieg, Thomas Gloor, Clemens Arth:
	</div><div>
	  <b>On Using 3D Support Geometries for Measuring Human-made Corner Structures With a Robotic Total Station</b>
	</div><div>
	  
	    In <i>Communications in Computer and Information Science</i>,
	  
      
	   2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_363a" style="display:none;">
    <div>
	  Bruce Thomas, Gregory Welch, Pierre Dragicevic, Niklas Elmqvist, Pourang Irani, Yvonne Jansen, Dieter Schmalstieg, Aurelien Tabard, Neven Elsayed, Ross Smith, Wesley Willett:
	</div><div>
	  <b>Situated Analytics</b>
	</div><div>
	  
	    In <i>Immersive Analytics (LNCS 11190)</i>,
	  
      
	   2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_337" style="display:none;">
    <div>
	  David Mandl, Kwang Moo Yi, Peter Mohr, Peter Roth, Pascal Fua, Vincent Lepetit, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Learning Lightprobes for Mixed Reality Illumination</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper presents the first photometric registration pipeline for Mixed Reality based on high quality illumination estimation byconvolutional neural network (CNN) methods. For easy adaptation and deployment of the system, we train the CNN using purelysynthetic images and apply them to real image data. To keep thepipeline accurate and efficient, we propose to fuse the light estimation results from multiple CNN instances, and we show an approach for caching estimates over time. For optimal performance, we furthermore explore multiple strategies for the CNN training. Experimental results show that the proposed method yields highly accurate estimates for photo-realistic augmentation</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/oWi5I3vllHo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_339" style="display:none;">
    <div>
	  Jan Egger, Juergen Wallner, Markus Gall, Xiaojun Chen, Katja Schwenzer-Zimmerer, Knut Reinbacher, Dieter Schmalstieg:
	</div><div>
	  <b>Computer-aided Position Planning of Miniplates to treat Facial bone Defects</b>
	</div><div>
	  
	    <i>PLoS ONE</i>, 
	    vol. 12,
	    
	  
      
	  August 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_340" style="display:none;">
    <div>
	  Jan Egger, Xiaojun Chen, Lucas Bettac, Mark Haenle, Tilmann Graeter, Wolfram Zoller, Dieter Schmalstieg, Alexander Hann:
	</div><div>
	  <b>In-depth Assessment of an Interactive Graph-based Approach for the Segmentation for Pancreatic Metastasis in Ultrasound Acquisitions of the Liver with two Specialists in Internal Medicine</b>
	</div><div>
	  
	    In <i>Proc. IEEE Biomedical Engineering International Conference (BMEiCON2017)</i>,
	  
      
	  August 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_338" style="display:none;">
    <div>
	  Bernhard Kerbl, Michael Kenzel, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>Effective Static Bin Patterns for Sort-Middle Rendering</b>
	</div><div>
	  
	    In <i>Proc. High Performance Graphics (HPG)</i>,
	  
      
	  July 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_335" style="display:none;">
    <div>
	  Christof Sirk, Alexander Bornik, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Dynamic Label Placement for Forensic Volume Visualization</b>
	</div><div>
	  
	    In <i>Proc. EG/VGTC Conference on Visualization (EuroVis)</i>,
	  
      
	  June 2017, Best short paper award.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_336" style="display:none;">
    <div>
	  Thomas Geymayer, Manuela Waldner, Alexander Lex, Dieter Schmalstieg:
	</div><div>
	  <b>How Sensemaking Tools Influence Display Usage</b>
	</div><div>
	  
	    In <i>Proc. International EuroVis Workshop on Visual Analytics (EuroVA)</i>,
	  
      
	  June 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_330" style="display:none;">
    <div>
	  Peter Mohr, David Mandl, Markus Tatzgern, Eduardo Veas, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  May 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">A video tutorial effectively conveys complex motions, butmay be hard to follow precisely because of its restriction toa predetermined viewpoint. Augmented reality (AR) tutori-als have been demonstrated to be more effective. We bringthe advantages of both together by interactively retargetingconventional, two-dimensional videos into three-dimensionalAR tutorials. Unlike previous work, we do not simply overlayvideo, but synthesize 3D-registered motion from the video.Since the information in the resulting AR tutorial is registeredto 3D objects, the user can freely change the viewpoint with-out degrading the experience. This approach applies to manystyles of video tutorials. In this work, we concentrate on aclass of tutorials which alter the surface of an object.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=FWytd1m6dKk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_328" style="display:none;">
    <div>
	  Markus Gall, Knut Reinbacher, Juergen Wallner, Katja Schwenzer-Zimmerer, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Interaktive Planung von Gesichtsimplantaten</b>
	</div><div>
	  
	    In <i>Proc. Bildverarbeitung fuer die Medizin (BVM)</i>,
	  
      
	  March 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_331" style="display:none;">
    <div>
	  Peter Mohr, Markus Tatzgern, Jens Grubert, Dieter Schmalstieg, Denis Kalkofen:
	</div><div>
	  <b>Adaptive User Perspective Rendering for Handheld Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE Symposium on 3D User Interfaces</i>,
	  
      
	  March 2017, Best paper honorable mention award..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_333" style="display:none;">
    <div>
	  Jan Egger, Markus Gall, Juergen Wallner, Pedro Boechat, Alexander Hann, Xing Li, Xiaojun Chen, Dieter Schmalstieg:
	</div><div>
	  <b>HTC Vive MeVisLab integration via OpenVR for medical applications</b>
	</div><div>
	  
	    <i>PLOS ONE</i>, 
	    vol. 12,
	    
	  
      
	  March 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_334" style="display:none;">
    <div>
	  Jan Egger, Markus Gall, Alois Tax, Muammer Uecal, Ulrike Zefferer, Xing Li, Gord von Campe, Ute Schaefer, Dieter Schmalstieg, Xiaojun Chen:
	</div><div>
	  <b>Interactive reconstructions of cranial 3D implants under MeVisLab as an alternative to commercial planning software</b>
	</div><div>
	  
	    <i>PLOS ONE</i>, 
	    vol. 12,
	    
	  
      
	  March 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_324" style="display:none;">
    <div>
	  Markus Gall, Knut Reinbacher, Juergen Wallner, Jan Stanzel, Xiaojun Chen, Katja Schwenzer-Zimmerer, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Interactive Planning of Miniplates</b>
	</div><div>
	  
	    In <i>Proc. SPIE Medical Imaging</i>,
	  
      
	  February 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_325" style="display:none;">
    <div>
	  Jan Egger, Kerstin Hochegger, Markus Gall, Xiaojun Chen, Knut Reinbacher, Katja Schwenzer-Zimmerer, Dieter Schmalstieg, Juergen Wallner:
	</div><div>
	  <b>Algorithmic evaluation of lower jawbone segmentations</b>
	</div><div>
	  
	    In <i>Proc. SPIE Medical Imaging</i>,
	  
      
	  February 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_326" style="display:none;">
    <div>
	  Jan Egger, Markus Gall, Juergen Wallner, Pedro Boechat, Alexander Hann, Xing Li, Xiaojun Chen, Dieter Schmalstieg:
	</div><div>
	  <b>Integration of the HTC Vive into the Medical Platform MeVisLab</b>
	</div><div>
	  
	    In <i>Proc. SPIE Medical Imaging</i>,
	  
      
	  February 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_329" style="display:none;">
    <div>
	  Christoph Klug, Dieter Schmalstieg, Clemens Arth:
	</div><div>
	  <b>Measuring Human-made Corner Structures With a Robotic Total Station using Support Points, Lines and Planes</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Computer Vision Theory and Applications (VISAPP)</i>,
	  
      
	  February 2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_332" style="display:none;">
    <div>
	  Jan Egger, Dieter Schmalstieg, Xiaojun Chen, Wolfram G. Zoller, Alexander Hann:
	</div><div>
	  <b>Interactive Outlining of Pancreatic Cancer Liver Metastases in Ultrasound Images</b>
	</div><div>
	  
	    <i>Nature Scientific Reports</i>, 
	    vol. 7,
	    
	  
      
	   2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_349" style="display:none;">
    <div>
	  A. Hann, L. Bettac, M. M. Haenle, T. Graeter, A. W. Berger, J. Dreyhaupt, D. Schmalstieg, W. G. Zoller, J. Egger:
	</div><div>
	  <b>Algorithm Guided Outlining of 105 Pancreatic Cancer Liver Metastases in Ultrasound</b>
	</div><div>
	  
	    <i>Scientific Reports</i>, 
	    
	    
	  
      
	   2017.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_319" style="display:none;">
    <div>
	  Pedro Boechat, Mark Dokter, Michael Kenzel, Hans-Peter Seidel, Dieter Schmalstieg, Markus Steinberger:
	</div><div>
	  <b>Representing and Scheduling Procedural Generation using Operator Graphs</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics (Proc. SIGGRAPH Asia)</i>, 
	    
	    
	  
      
	  December 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we present the concept of operator graph scheduling for high performance procedural generation on the graphics processing unit (GPU). The operator graph forms an intermediate representation that describes all possible operations and objects that can arise during a specific procedural generation. While previous methods have focused on parallelizing a specific procedural approach, the operator graph is applicable to all procedural generation methods that can be described by a graph, such as L-systems, shape grammars, or stack based generation methods. Using the operator graph, we show that all partitions of the graph correspond to possible ways of scheduling a procedural generation on the GPU, including the scheduling strategies of previous work. As the space of possible partitions is very large, we describe three search heuristics, aiding an optimizer in finding the fastest valid schedule for any given operator graph. The best partitions found by our optimizer increase performance of 8 to 30x over the previous state of the art in GPU shape grammar and L-system generation.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=CvAlSffwB18" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_320" style="display:none;">
    <div>
	  Jens Grubert, Michel Pahud, Matthias Kranz, Dieter Schmalstieg:
	</div><div>
	  <b>GlassHands: Interaction Around Unmodified Mobile Devices Using Sunglasses</b>
	</div><div>
	  
	    In <i>Proc. ACM Interactive Surfaces and Spaces 2016</i>,
	  
      
	  November 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present a novel approach for extending the input spacearound unmodified mobile devices. Using built-in front-facing cameras of unmodified handheld devices, GlassHandsestimates hand poses and gestures through reflections in sun-glasses, ski goggles or visors. Thereby, GlassHands createsan enlarged input space, rivaling input reach on large touchdisplays. We introduce the idea along with its technical con-cept and implementation. We demonstrate the feasibility andpotential of our proposed approach in several applicationscenarios, such as map browsing or drawing using a set ofinteraction techniques previously possible only with modifiedmobile devices or on large touch displays. Our research isbacked up with a user study.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/aUFi6zNcdKc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_318" style="display:none;">
    <div>
	  W. Alexander Isop, Jesus Pestana Puerta, Gabriele Ermacora, Friedrich Fraundorfer, Dieter Schmalstieg:
	</div><div>
	  <b>Micro Aerial Projector - Stabilizing Projected Images Of An Airborne Robotics Projection Platform</b>
	</div><div>
	  
	    In <i>Proc. IEEE/RJS International Conference on Intelligent Robots and Systems (IROS'16)</i>,
	  
      
	  October 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">A mobile flying projector is hard to build dueto the limited size and payload capability of a micro aerial vehicle. Few flying projector designs have been studied inrecent research. However, to date, no practical solution has been presented. We propose a versatile laser projection system enabling in-flight projection with feed forward correction for stabilization of projected images. We present a quantitative evaluation of the accuracy of the projection stabilization intwo autonomous flight experiments. While this approach isour first step towards a flying projector, we foresee interesting applications, such as providing on-site instructions in various human machine interaction scenarios.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_316" style="display:none;">
    <div>
	  Thomas Richter-Trummer, Jinwoo Park, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Instant Mixed Reality Lighting from Casual Scanning</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  September 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present a method for recovering both incident lighting and surface materials from casually scanned geometry. By casual, we mean a rapid and potentially noisy scanning procedure of unmodified and uninstrumented scenes with a commodity RGB-D sensor. In other words, unlike reconstruction procedures which require careful preparations in a laboratory environment, our method works with input that can be obtained by consumer users. To ensure a robust procedure, we segment the reconstructed geometry into surfaces with homogeneous material properties and compute the radiance transfer on these segments. With this input, we solve the inverse rendering problem of factorization into lighting and material properties using an iterative optimization in spherical harmonics form. This allows us to account for self-shadowing and recover specular properties. The resulting data can be used to generate a wide range of mixed reality applications, including the rendering of synthetic objects with matching lighting into a given scene, but also re-rendering the scene (or a part of it) with new lighting. We show the robustness of our approach with real and synthetic examples under a variety of lighting conditions and compare them with ground truth data.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=ax-4SqCPfrs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_321" style="display:none;">
    <div>
	  Philipp Fleck, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Scalable Mobile Image Recognition for Real-Time Video Annotation</b>
	</div><div>
	  
	    In <i>Adjunct Proceedings of IEEE International Symposium on Mixed and Augmented Reality (ISMAR'16)</i>,
	  
      
	  September 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_323" style="display:none;">
    <div>
	  Philip Voglreiter, Michael Hofmann, Christoph Ebner, Dieter Schmalstieg, Roberto Blanco Sequeiros, Horst R. Portugaller, Juergen Fuetterer, Michael Moche, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Visualization-Guided Evaluation of Simulated Minimally Invasive Cancer Treatment</b>
	</div><div>
	  
	    In <i>Proc. EUROGRAPHICS Workshop on Visual Computing in Biology and Medicine (VCBM)</i>,
	  
      
	  September 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_312" style="display:none;">
    <div>
	  Markus Gall, Xing Li, Xiaojun Chen, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Computer-Aided Planning and Reconstruction of Cranial 3D Implants</b>
	</div><div>
	  
	    In <i>Proc. IEEE Engineering in Medicine and Biology Society (EMBC'16)</i>,
	  
      
	  August 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_313" style="display:none;">
    <div>
	  Jan Egger, Juergen Wallner, Kerstin Hochegger, Markus Gall, Knut Reinbacher, Katja Schwenzer-Zimmerer, Dieter Schmalstieg:
	</div><div>
	  <b>Clinical Evaluation of Mandibular Bone Segmentation</b>
	</div><div>
	  
	    In <i>Proc. IEEE Engineering in Medicine and Biology Society (EMBC'16), Posters</i>,
	  
      
	  August 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_314" style="display:none;">
    <div>
	  Markus Gall, Juergen Wallner, Katja Schwenzer-Zimmerer, Dieter Schmalstieg, Knut Reinbacher, Jan Egger:
	</div><div>
	  <b>Computer-aided Reconstruction of Facial Defects</b>
	</div><div>
	  
	    In <i>Proc. IEEE Engineering in Medicine and Biology Society (EMBC'16), Posters</i>,
	  
      
	  August 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_306" style="display:none;">
    <div>
	  Markus Gall, Xiaojun Chen, Dieter Schmalstieg, Jan Egger:
	</div><div>
	  <b>Computer-Aided Planning of Cranial 3D Implants</b>
	</div><div>
	  
	    <i>International Journal of Computer Aided Radiology and Surgery</i>, 
	    vol. 11,
	    
	  
      
	  June 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_307" style="display:none;">
    <div>
	  Philip Voglreiter, Panchatcharam Mariappan, Tuomas Alhonnoro, Harald Busse, Phil Weir, Mika Pollari, Ronan Flanagan, Michael Hofmann, Daniel Seider, Philipp Brandmaier, Martinus Johannes van Amerongen, Riitta Rautio, Sjoerd Jenniskens, Roberto Blanco Sequeiros, Horst Portugaller, Philipp Stiegler, Jurgen Futterer, Dieter Schmalstieg, Marina Kolesnik, Michael Moche:
	</div><div>
	  <b>RFA Guardian: Comprehensive Simulation of the Clinical Workflow for Patient specific Planning, Guidance and Validation of RFA Treatment of Liver Tumors</b>
	</div><div>
	  
	    <i>International Journal of Computer Aided Radiology and Surgery</i>, 
	    vol. 11,
	    
	  
      
	  June 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_308" style="display:none;">
    <div>
	  Christian Partl, Samuel Gratzl, Marc Streit, Anne-Mai Wassermann, Hanspeter Pfister, Dieter Schmalstieg, Alexander Lex:
	</div><div>
	  <b>Pathfinder: Visual Analysis of Paths in Graphs</b>
	</div><div>
	  
	    <i>Computer Graphics Forum (Proc. EuroVis)</i>, 
	    
	    
	  
      
	  June 2016, Best paper honorable mention..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The analysis of paths in graphs is highly relevant in many domains. Typically, path-related tasks are performed in node-link layouts. Unfortunately, graph layouts often do not scale to the size of many real world networks. Also, many networks are multivariate, i.e., contain rich attribute sets associated with the nodes and edges. These attributes are often critical in judging paths, but directly visualizing attributes in a graph layout exacerbates the scalability problem. In this paper, we present visual analysis solutions dedicated to path-related tasks in large and highly multivariate graphs. We show that by focusing on paths, we can address the scalability problem of multivariate graph visualization, equipping analysts with a powerful tool to explore large graphs. We introduce Pathfinder, a technique that provides visual methods to query paths, while considering various constraints. The resulting set of paths is visualized in both a ranked list and as a node-link diagram. For the paths in the list, we display rich attribute data associated with nodes and edges, and the node-link diagram provides topological context. The paths can be ranked based on topological properties, such as path length or average node degree, and scores derived from attribute data. Pathfinder is designed to scale to graphs with tens of thousands of nodes and edges by employing strategies such as incremental query results. We demonstrate Pathfinder's fitness for use in scenarios with data from a coauthor network and biological pathways.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/aZF7AC8aNXo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_317" style="display:none;">
    <div>
	  Dieter Schmalstieg, Tobias Hoellerer:
	</div><div>
	  <b>Augmented Reality - Principles and Practice</b>
	</div><div>
	  
	    <i>Addison-Wesley Professional</i>, 
	  
      
	  June 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_304" style="display:none;">
    <div>
	  Markus Tatzgern, Valeria Orso, Denis Kalkofen, Giulio Jacucci, Luciano Gamberini, Dieter Schmalstieg:
	</div><div>
	  <b>Adaptive Information Density for Augmented Reality Displays</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Augmented Reality (AR) browsers show geo-referenced data in the current view of a user. When the amount of data grows too large, the display quickly becomes cluttered. Clustering items by spatial and semantic attributes can temporarily alleviate the issue, butis not effective against an increasing amount of data. We present an adaptive information density display for AR that balances the amount of presented information against the potential clutter created by placing items on the screen. We use hierarchical clustering to create a level-of-detail structure, in which nodes closer to the root encompass groups of items, while the leaf nodes contain single items. Our method selects items and groups from different levels of this hierarchy based on user-defined preferences and on the amount of visual clutter caused by placing these items. The number of presented items is adapted during user interaction to avoid clutter. We compare our interface to a conventional AR browser interface in a qualitative user study. Users clearly preferred our interface, because it provided a better overview of the data and allowed for easier comparison. In a second study, we evaluated the effect of different degrees of clustering on search and recall tasks. Users generally made fewer errors, when using our interface for a search task, which indicates that the reduced clutter allowed them to stay focused on finding the relevant item</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=zbNtM4eN75I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_305" style="display:none;">
    <div>
	  Thomas Geymayer, Dieter Schmalstieg:
	</div><div>
	  <b>Collaborative Distributed Cognition Using A Seamless Desktop Infrastructure</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality Workshop on Immersive Analytics</i>,
	  
      
	  March 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_309" style="display:none;">
    <div>
	  Philipp Fleck, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Visionary Collaborative Outdoor Reconstruction using SLAM and SfM</b>
	</div><div>
	  
	    In <i>Proc. IEEE VR Workshop on Software Engineering and Architectures for Realtime Interactive Systems (SEARIS)</i>,
	  
      
	  March 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_315" style="display:none;">
    <div>
	  Juergen Wallner, Knut Reinbacher, Jan Egger, Mauro Pau, Wolfgang Zemann, Tomislav Zrnc, Dieter Schmalstieg, Katja Schwenzer-Zimmerer:
	</div><div>
	  <b>Image-guided real-time-segmentation of the mandibular bone: Can a simple Segmentation approach provide a satisfying result for a practicable use?</b>
	</div><div>
	  
	    In <i>Proc. 20. Jahreskongress der oesterreichischen Gesellschaft fuer Mund-, Kiefer- und Gesichtschirurgie (oeGMKG'16)</i>,
	  
      
	  January 2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_302" style="display:none;">
    <div>
	  Andreas Hartl, Clemens Arth, Jens Grubert, Dieter Schmalstieg:
	</div><div>
	  <b>Efficient Verification of Holograms Using Mobile Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 22,
	    
	  
      
	   2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Paper documents such as passports, visas and banknotes are frequently checked by inspection of security elements. Inparticular, optically variable devices such as holograms are important, but difficult to inspect. Augmented Reality can provide all relevant information on standard mobile devices. However, hologram verification on mobiles still takes long and provides lower accuracy than inspection by human individuals using appropriate reference information. We aim to address these drawbacks by automatic matching combined with a special parametrization of an efficient goal-oriented user interface which supports constrained navigation. We first evaluate a series of similarity measures for matching hologram patches to provide a sound basis for automatic decisions. Then a re-parametrized user interface is proposed based on observations of typical user behavior during document capture. These measures help to reduce capture time to approximately 15 s with better decisions regarding the evaluated samples than what can be achieved by untrained users.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=TXKjRU78zKA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_303" style="display:none;">
    <div>
	  Jacob Madsen, Markus Tatzgern, Denis Kalkofen, Dieter Schmalstieg, Claus Madsen:
	</div><div>
	  <b>Temporal Coherence Strategies for Augmented Reality Labeling</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. VR 2016)</i>, 
	    
	    
	  
      
	   2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Temporal coherence of annotations is an important factor in augmented reality user interfaces and for information visualization. In this paper, we empirically evaluate four different techniques for annotation. Based on these findings, we follow up with subjective evaluations in a second experiment. Results show that presenting annotations in object space or image space leads to a significant difference in task performance. Furthermore, there is a significant interaction between rendering space and update frequency of annotations. Participants improve significantly in locating annotations, when annotations are presented in object space, and view management update rate is limited. In a follow-up experiment, participants appear to be more satisfied with limited update rate in comparison to a continuous update rate of the view management system.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=fX3M3vR2Q5k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_311" style="display:none;">
    <div>
	  Jan Egger, Philip Voglreiter, Mark Dokter, Michael Hofmann, Xiaojun Chen, Wolfram G. Zoller, Dieter Schmalstieg, Alexander Hann:
	</div><div>
	  <b>US-Cut: interactive algorithm for rapid detection and segmentation of liver tumors in ultrasound acquisitions</b>
	</div><div>
	  
	    In <i>Proc. SPIE</i>,
	  
      
	   2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_327" style="display:none;">
    <div>
	  Bernhard Kerbl, Michael Kenzel, Dieter Schmalstieg, Hans-Peter Seidel, Markus Steinberger:
	</div><div>
	  <b>Hierarchical Bucket Queuing for Fine-grained Priority Scheduling on the GPU</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    
	    
	  
      
	   2016.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">While the modern graphics processing unit (GPU) offers massive parallel compute power, the ability to influence the schedulingof these immense resources is severely limited. Therefore, the GPU is widely considered to be only suitable as an externallycontrolled co-processor for homogeneous workloads which greatly restricts the potential applications of GPU computing.To address this issue, we present a new method to achieve fine-grained priority scheduling on the GPU: hierarchical bucketqueuing. By carefully distributing the workload among multiple queues and efficiently deciding which queue to draw work fromnext, we enable a variety of scheduling strategies. These strategies include fair-scheduling, earliest-deadline-first scheduling,and user-defined dynamic priority scheduling. In a comparison with a sorting-based approach, we reveal the advantages ofhierarchical bucket queuing over previous work. Finally, we demonstrate the benefits of using priority scheduling in real-worldapplications by example of path tracing and foveated micropolygon rendering.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=U9mFAT07WBg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_294" style="display:none;">
    <div>
	  Thanh Nguyen, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Structural Modeling from Depth Images</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR 2015)</i>, 
	    vol. 21,
	    
	  
      
	  November 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this work, we present a new automatic system for scene reconstruction of high-level structural models. We start with identifying planar regions in depth images obtained with a SLAM system. Our main contribution is an approach which identifies constraints such as incidence and orthogonality of planar surfaces and uses them in an incremental optimization framework to extract high-level structural models. The result is a manifold mesh with a low number of polygons, immediately useful in many Augmented Reality applications such as inspection, interior design or spatial interaction</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/r5T8snHEafE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_295" style="display:none;">
    <div>
	  Clemens Arth, Christian Pirchheim, Jonathan Ventura, Dieter Schmalstieg, Vincent Lepetit:
	</div><div>
	  <b>Instant Outdoor Localization and SLAM Initialization from 2.5D Maps</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. ISMAR 2015)</i>, 
	    vol. 21,
	    
	  
      
	  November 2015, Best paper award..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present a method for large-scale geo-localization and global tracking of mobile devices in urban outdoor environments. In contrast to existing methods, we instantaneously initialize and globally register a SLAM map by localizing the first keyframe with respect towidely available untextured 2.5D maps. Given a single image frame and a coarse sensor pose prior, our localization method estimatesthe absolute camera orientation from straight line segments and the translation by aligning the city map model with a semantic segmentation of the image. We use the resulting 6DOF pose, together with information inferred from the city map model, to reliably initialize and extend a 3D SLAM map in a global coordinate system, applying a model-supported SLAM mapping approach. We show the robustness and accuracy of our localization approach on a challenging dataset, and demonstrate unconstrained global SLAM mapping and tracking of arbitrary camera motion on several sequence</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/WegHxIOHAQM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_298" style="display:none;">
    <div>
	  Cledja Rolim, Dieter Schmalstieg, Denis Kalkofen, Veronica Teichrieb:
	</div><div>
	  <b>Design Guidelines for Generating Augmented Reality Instructions</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Mixed and Augmented Reality (ISMAR 2015) Posters</i>,
	  
      
	  November 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_299" style="display:none;">
    <div>
	  Philipp Fleck, Clemens Arth, Christian Pirchheim, Dieter Schmalstieg:
	</div><div>
	  <b>Tracking and Mapping with a Swarm of Heterogeneous Clients</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Mixed and Augmented Reality (ISMAR 2015) Posters</i>,
	  
      
	  November 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_300" style="display:none;">
    <div>
	  Christian Poglitsch, Clemens Arth, Dieter Schmalstieg, Jonathan Ventura:
	</div><div>
	  <b>A Particle Filter Approach to Outdoor Localization using Image-based Rendering</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Mixed and Augmented Reality (ISMAR 2015) Posters</i>,
	  
      
	  November 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_296" style="display:none;">
    <div>
	  Alexander Plopski, Christian Nitschke, Kiyoshi Kiyokawa, Dieter Schmalstieg, Haruo Takemura:
	</div><div>
	  <b>Hybrid Eye Tracking - Combining Iris Contour and Corneal Imaging</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Artificial Reality and Telexistence and Eurographics Symposium on Virtual Environments (ICAT-EGVE 2015)</i>,
	  
      
	  October 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_310" style="display:none;">
    <div>
	  Andreas Hartl, W. Alexander Isop, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Towards Mobile Recognition and Verification of Holograms using Orthogonal Sampling</b>
	</div><div>
	  
	    In <i>Proc. IEEE ISMAR Workshop on Workshop on Visual Recognition and Retrieval for Mixed and Augmented Reality</i>,
	  
      
	  October 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_297" style="display:none;">
    <div>
	  Jan Egger, Harald Busse, Philipp Brandmaier, Daniel Seider, Matthias Gawlitza, Steffen Strocka, Philip Voglreiter, Mark Dokter, Michael Hofmann, Bernhard Kainz, Xiaojun Chen, Alexander Hann, Pedro Boechat, Wei Yu, Bernd Freisleben, Tuomas Alhonnoro, Mika Pollari, Michael Moche, Dieter Schmalstieg:
	</div><div>
	  <b>RFA-Cut: Semi-automatic Segmentation of Radiofrequency Ablation Zones with and without Needles via Optimal s-t-Cuts</b>
	</div><div>
	  
	    In <i>Proc. IEEE Engineering in Medicine and Biology (EMBC 2015)</i>,
	  
      
	  August 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_287" style="display:none;">
    <div>
	  Jens Grubert, Matthias Heinisch, Aaron Quigley, Dieter Schmalstieg:
	</div><div>
	  <b>MultiFi: Multi Fidelity Interaction with Displays On and Around the Body</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  April 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Display devices on and around the body such as smart-watches, head-mounted displays or tablets enable users to interact on the go. However, diverging input and output fidelities of these devices can lead to interaction seams that can inhibit efficient mobile interaction, when users employ multiple devices at once. We present MultiFi, an interactive system that combines the strengths of multiple displays and overcomes the seams of mobile interaction with widgets distributed over multiple devices. A comparative user study indicates that combined head-mounted display and smartwatch interfaces can outperform interaction with single wearable devices.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=QsfQWZpiR18" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_288" style="display:none;">
    <div>
	  Peter Mohr, Bernhard Kerbl, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Retargeting Technical Documentation to Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  April 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present a system which automatically transfers printed technical documentation, such as handbooks, to three-dimensional Augmented Reality. Our system identifies themost frequent forms of instructions found in printed documentation, such as image sequences, explosion diagrams, textual annotations and arrows indicating motion. The analysis of the printed documentation works automatically, with minimal user input. The system only requires the documentation itself and a CAD model or 3D scan of the object described in the documentation. The output is a fully interactive Augmented Reality application, presenting the information from the printed documentation in 3D, registered to the real object.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=UnMbK-gY_kM&amp;list=PLlDsBa-6PMG0AwYG9hzvBn4fj_brn91G_&amp;index=7&amp;t=0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_289" style="display:none;">
    <div>
	  Bernhard Kerbl, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Disassembly Planning of Complex Objects</b>
	</div><div>
	  
	    <i>Computer Graphics Forum(Proc. EUROGRAPHICS 2015)</i>, 
	    
	    
	  
      
	  April 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present an approach for the automatic generation, interactive exploration and real-time modification of disassembly procedures for complex, multipartite CAD data sets. In order to lift the performance barriers prohibiting interactive disassembly planning, we run a detailed analysis on the input model to identify recurring part constellations and efficiently determine blocked part motions in parallel on the GPU. Building on the extracted information, we present an interface for computing and editing extensive disassembly sequences in real-time while considering user-defined constraints and avoiding unstable configurations. To evaluate the performance of our C++/CUDA implementation, we use a variety of openly available CAD data sets, ranging from simple to highly complex. In contrast to previous approaches, our work enables interactive disassembly planning for objects which consist of several thousand parts and require cascaded translations during part removal.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=hXoeMdTx48s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_290" style="display:none;">
    <div>
	  Lukas Gruber, Jonathan Ventura, Dieter Schmalstieg:
	</div><div>
	  <b>Image-Space Illumination for Augmented Reality in Dynamic Environments</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality (VR'15)</i>,
	  
      
	  March 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present an efficient approach for probeless light estimation andcoherent rendering of Augmented Reality in dynamic scenes. Thisapproach can handle dynamically changing scene geometry and dy-namically changing light sources in real time with a single mobileRGB-D sensor and without relying on an invasive lightprobe. Wejointly filter both in-view dynamic geometry and outside-view staticgeometry. The resulting reconstruction provides the input for effi-cient global illumination computation in image-space. We demon-strate that our approach can deliver state-of-the-art Augmented Re-ality rendering effects for scenes that are more scalable and moredynamic than previous work.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=7nf7VFo9Goo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_291" style="display:none;">
    <div>
	  Andreas Hartl, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Mobile User Interfaces for Efficient Verification of Holograms</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality (VR'15)</i>,
	  
      
	  March 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_292" style="display:none;">
    <div>
	  Andreas Hartl, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Real-time Detection and Recognition of Machine-Readable Zones with Mobile Devices</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Computer Vision Theory and Applications (VISAPP'15)</i>,
	  
      
	  March 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_293" style="display:none;">
    <div>
	  Jan Egger, Harald Busse, Michael Moche, Philipp Brandmaier, Daniel Seider, Matthias Gawlitza, Steffen Strocka, Nikita Garnov, Jochen Fuchs, Peter Voigt, Florian Dazinger, Philip Voglreiter, Mark Dokter, Michael Hofmann, Alexander Hann, Bernd Freisleben, Thomas Kahn, Dieter Schmalstieg:
	</div><div>
	  <b>Semi-automatische Segmentierung von Schaedigungszonen in post-interventionellen CT-Daten</b>
	</div><div>
	  
	    In <i>Bildverarbeitung fuer die Medizin 2015</i>,
	  
      
	  February 2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_301" style="display:none;">
    <div>
	  Jan Egger, Harald Busse, Philipp Brandmaier, Daniel Seider, Matthias Gawlitza, Steffen Strocka, Philip Voglreiter, Mark Dokter, Michael Hofmann, Bernhard Kainz, Alexander Hann, Xiaojun Chen, Tuomas Alhonnoro, Mika Pollari, Michael Moche, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Volumetry of Liver Ablation Zones</b>
	</div><div>
	  
	    <i>Scientific Reports</i>, 
	    vol. 5,
	    
	  
      
	   2015.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_285" style="display:none;">
    <div>
	  Andreas Hartl, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>AR-based Hologram Detection on Security Documents using a Mobile Phone</b>
	</div><div>
	  
	    In <i>International Symposium on Visual Computing - (ISVC'14)</i>,
	  
      
	  December 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_286" style="display:none;">
    <div>
	  Markus Steinberger, Michael Kenzel, Pedro Boechat, Bernhard Kerbl, Mark Dokter, Dieter Schmalstieg:
	</div><div>
	  <b>Whippletree: Task-based Scheduling of Dynamic Workloads on the GPU</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics (Proc. SIGGRAPH Asia 2014)</i>, 
	    
	    
	  
      
	  December 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Conventional pipelines for capturing, displaying, and storing images are usually defined as a series of cascaded modules, each responsible for addressing a particular problem. While this divide-and-conquer approach offers many benefits, it also introduces a cumulative error, as each step in the pipeline only considers the output of the previous step, not the original sensor data. We propose an end-to-end system that is aware of the camera and image model, enforces natural-image priors, while jointly accounting for common image processing steps like demosaicking, denoising, deconvolution, and so forth, all directly in a given output representation (e.g., YUV, DCT). Our system is flexible and we demonstrate it on regular Bayer images as well as images from custom sensors. In all cases, we achieve large improvements in image quality and signal reconstruction compared to state-of-the-art techniques. Finally, we show that our approach is capable of very efficiently handling high-resolution images, making even mobile implementations feasible.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_280" style="display:none;">
    <div>
	  Christian Partl, Alexander Lex, Marc Streit, Hendrik Strobelt, Anne-Mai Wassermann, Hanspeter Pfister, Dieter Schmalstieg:
	</div><div>
	  <b>ConTour: Data-Driven Exploration of Multi-Relational Datasets for Drug Discovery</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 20,
	    
	  
      
	  November 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Large scale data analysis is nowadays a crucial part of drug discovery. Biologists and chemists need to quickly explore and evaluate potentially effective yet safe compounds based on many datasets that are in relationship with each other. However, there is a is a lack of tools that support them in these processes. To remedy this, we developed ConTour, an interactive visual analytics technique that enables the exploration of these complex, multi-relational datasets. At its core ConTour lists all items of each dataset in a column. Relationships between the columns are revealed through interaction: selecting one or multiple items in one column highlights and re-sorts the items in other columns. Filters based on relationships enable drilling down into the large data space. To identify interesting items in the first place, ConTour employs advanced sorting strategies, including strategies based on connectivity strength and uniqueness, as well as sorting based on item attributes. ConTour also introduces interactive nesting of columns, a powerful method to show the related items of a child column for each item in the parent column. Within the columns, ConTour shows rich attribute data about the items as well as information about the connection strengths to other datasets. Finally, ConTour provides a number of detail views, which can show items from multiple datasets and their associated data at the same time. We demonstrate the utility of our system in case studies conducted with a team of chemical biologists, who investigate the effects of chemical compounds on cells and need to understand the underlying mechanisms.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/0tFayr3prDY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_277" style="display:none;">
    <div>
	  Feng Zheng, Dieter Schmalstieg, Greg Welch:
	</div><div>
	  <b>Closed-Loop Registration in Video-Based Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  September 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_278" style="display:none;">
    <div>
	  Elias Tappeiner, Dieter Schmalstieg, Tobias Langlotz :
	</div><div>
	  <b>Local Optimization for Natural Feature Tracking Targets</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  September 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_279" style="display:none;">
    <div>
	  Jens Grubert, Hartmut Seichter, Dieter Schmalstieg:
	</div><div>
	  <b>Towards User Perspective Augmented Reality for Public Displays</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  September 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_281" style="display:none;">
    <div>
	  Marc Streit, Alexander Lex, Samuel Gratzl, Christian Partl, Dieter Schmalstieg, Hanspeter Pfister, Peter J. Park, Nils Gehlenborg:
	</div><div>
	  <b>Guided visual exploration of genomic stratifications in cancer</b>
	</div><div>
	  
	    <i>Nature Methods</i>, 
	    vol. 11,
	    
	  
      
	  September 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Cancer is a heterogeneous disease, and molecular profiling of tumors from large cohorts has enabled characterization of new tumor subtypes. This is a prerequisite for improving personalized treatment and ultimately achieving better patient outcomes. Potential tumor subtypes can be identified with methods such as unsupervised clustering or network-based stratification, which assign patients to sets based on high-dimensional molecular profiles. Detailed characterization of identified sets and their interpretation, however, remain a time-consuming exploratory process. To address these challenges, we combined 'StratomeX', an interactive visualization tool that is freely available at http://www.caleydo.org/, with exploration tools to efficiently compare multiple patient stratifications, to correlate patient sets with clinical information or genomic alterations and to view the differences between molecular profiles across patient sets. Although we focus on cancer genomics here, StratomeX can also be applied in other disease cohorts.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/s2ZofJ2GVHU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_273" style="display:none;">
    <div>
	  Michael Donoser, Dieter Schmalstieg:
	</div><div>
	  <b>Discriminative Feature-to-Point Matching in Image-Based Localization</b>
	</div><div>
	  
	    In <i>Proc. IEEE Computer Vision and Pattern Recognition 2014</i>,
	  
      
	  June 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_274" style="display:none;">
    <div>
	  Michael Donoser, Dieter Schmalstieg:
	</div><div>
	  <b>Discrete-Continuous Gradient Orientation Estimation for Faster Image Segmentation</b>
	</div><div>
	  
	    In <i>Proc. IEEE Computer Vision and Pattern Recognition 2014</i>,
	  
      
	  June 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_275" style="display:none;">
    <div>
	  Jonathan Ventura, Clemens Arth, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>A Minimal Solution to the Generalized Pose-and-Scale Problem</b>
	</div><div>
	  
	    In <i>Proc. IEEE Computer Vision and Pattern Recognition 2014</i>,
	  
      
	  June 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_276" style="display:none;">
    <div>
	  Rostislav Khlebnikov, Philip Voglreiter, Markus Steinberger, Bernhard Kainz, Dieter Schmalstieg:
	</div><div>
	  <b>Parallel Irradiance Caching for Interactive Monte-Carlo Direct Volume Rendering</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 33,
	    
	  
      
	  June 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We propose a technique to build the irradiance cache for isotropic scattering simultaneously with Monte Carlo progressive direct volume rendering on a single GPU, which allows us to achieve up to four times increased convergence rate for complex scenes with arbitrary sources of light. We use three procedures that run concurrently on a single GPU. The first is the main rendering procedure. The second procedure computes new cache entries, and the third one corrects the errors that may arise after creation of new cache entries. We propose two distinct approaches to allow massive parallelism of cache entry creation. In addition, we show a novel extrapolation approach which outputs high quality irradiance approximations and a suitable prioritization scheme to increase the convergence rate by dedicating more computational power to more complex rendering areas.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://vimeo.com/100661850" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_264" style="display:none;">
    <div>
	  Bernhard Kainz, Philip Voglreiter, Michael Sereinigg, Iris
Wiederstein-Grasser, Ursula Mayrhauser, Sonja Koestenbauer and
Mika Pollari, Rostislav Khlebnikov, Matthias Seise, Tuomas
Alhonnoro, Yrjoe Haeme, Daniel Seider, Ronan Flanagan
and Claire Bost, Judith Muehl, David O'Neill, Tingying
Peng, Stephen Payne, Daniel Rueckert, Dieter Schmalstieg
and Marina Kolesnik, Philipp Stiegler, Rupert H. Portugaller:
	</div><div>
	  <b>High-Resolution Contrast Enhanced Multi-Phase Hepatic Computed Tomography Data from a Porcine Radio-Frequency Ablation Study</b>
	</div><div>
	  
	    In <i>IEEE International Symposium on Biomedical Imaging</i>,
	  
      
	  April 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_265" style="display:none;">
    <div>
	  Thomas Geymayer, Markus Steinberger, Alexander Lex, Marc Streit, Dieter Schmalstieg:
	</div><div>
	  <b>Show me the Invisible: Guidance to Hidden Content</b>
	</div><div>
	  
	    In <i>ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  April 2014, Best of CHI Honorable Mention Award..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Content on computer screens is often inaccessible to users because it is hidden, e.g., occluded by other windows, outside the viewport, or overlooked. In search tasks, the efficient retrieval of sought content is important. Current software, however, only provides limited support to visualize hidden occurrences and rarely supports search synchronization crossing application boundaries. To remedy this situation, we introduce two novel visualization methods to guide users to hidden content. Our first method generates awareness for occluded or out-of-viewport content using see-through visualization. For content that is either outside the screen's viewport or for data sources not opened at all, our second method shows off-screen indicators and an on-demand smart preview. To reduce the chances of overlooking content, we use visual links, i.e., visible edges, to connect the visible content or the visible representations of the hidden content. We show the validity of our methods in a user study, which demonstrates that our technique enables a faster localization of hidden content compared to traditional search functionality and thereby assists users in information retrieval tasks.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=3sjXqKuOX_w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_267" style="display:none;">
    <div>
	  Markus Steinberger, Michael Kenzel, Bernhard Kainz, Joerg Mueller, Peter Wonka, Dieter Schmalstieg:
	</div><div>
	  <b>Parallel Generation of Architecture on the GPU</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 33,
	    
	  
      
	  April 2014, Best paper honorable mention award.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we present a novel approach for the parallel evaluation of procedural shape grammars on the graphics processing unit GPU. Unlike previous approaches that are either limited in the kind of shapes they allow, the amount of parallelism they can take advantage of, or both, our method supports state of the art procedural modeling including stochasticity and context-sensitivity. To increase parallelism, we explicitly express independence in the grammar, reduce inter-rule dependencies required for context-sensitive evaluation, and introduce intra-rule parallelism. Our rule scheduling scheme avoids unnecessary back and forth between CPU and GPU and reduces round trips to slow global memory by dynamically grouping rules in on-chip shared memory. Our GPU shape grammar implementation is multiple orders of magnitude faster than the standard in CPU-based rule evaluation, while offering equal expressive power. In comparison to the state of the art in GPU shape grammar derivation, our approach is nearly 50 times faster, while adding support for geometric context-sensitivity.  </div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=DFtCyaBpxCk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_268" style="display:none;">
    <div>
	  Markus Steinberger, Michael Kenzel, Bernhard Kainz, Peter Wonka, Dieter Schmalstieg:
	</div><div>
	  <b>On-the-fly Generation and Rendering of Infinite Cities on the GPU</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 33,
	    
	  
      
	  April 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=u-J7JokvHyw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_269" style="display:none;">
    <div>
	  Jonathan Ventura, Clemens Arth, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Global Localization from Monocular SLAM on a Mobile Phone</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 20,
	    
	  
      
	  March 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=3gHacMDIPEw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_270" style="display:none;">
    <div>
	  Markus Tatzgern, Denis Kalkofen, Raphael Grasset, Dieter Schmalstieg:
	</div><div>
	  <b>Hedgehog Labeling: View Management Techniques for External Labels in 3D Space</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality 2014</i>,
	  
      
	  March 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=XUQu4XAc2MI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_271" style="display:none;">
    <div>
	  Markus Tatzgern, Raphael Grasset, Denis Kalkofen Dieter Schmalstieg:
	</div><div>
	  <b>Transitional Augmented Reality Navigation for Live Captured Scenes</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality 2014</i>,
	  
      
	  March 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_272" style="display:none;">
    <div>
	  Lukas Gruber, Tobias Langlotz, Pradeep Sen, Tobias Hollerer, Dieter Schmalstieg:
	</div><div>
	  <b>Efficient and Robust Radiance Transfer for Probeless Photorealistic Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality 2014</i>,
	  
      
	  March 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_266" style="display:none;">
    <div>
	  Tobias Langlotz, Thanh Nguyen, Dieter Schmalstieg, Raphael Grasset:
	</div><div>
	  <b>Next Generation Augmented Reality Browsers: Rich, Seamless, and Adaptive</b>
	</div><div>
	  
	    <i>Proceedings of the IEEE</i>, 
	    vol. 102,
	    
	  
      
	  February 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_263" style="display:none;">
    <div>
	  Andreas Hartl, Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>Client-Side Mobile Visual Search</b>
	</div><div>
	  
	    In <i>9th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP)</i>,
	  
      
	  January 2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_283" style="display:none;">
    <div>
	  Markus Tatzgern, Raphael Grasset, Eduardo Veas, Denis Kalkofen, Hartmut Seichter, Dieter Schmalstieg:
	</div><div>
	  <b>{Exploring Real World Points of Interest: Design and Evaluation of Object-centric Exploration Techniques for Augmented Reality}</b>
	</div><div>
	  
	    <i>Pervasive and Mobile Computing</i>, 
	    
	    
	  
      
	   2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_284" style="display:none;">
    <div>
	  Jens Grubert, Michel Pahud, Raphael Grasset, Dieter Schmalstieg
and Hartmut Seichter:
	</div><div>
	  <b>The Utility of Magic Lens Interfaces on Handheld Devices for Touristic Map Navigation</b>
	</div><div>
	  
	    <i>Pervasive and Mobile Computing</i>, 
	    
	    
	  
      
	   2014.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_262" style="display:none;">
    <div>
	  Markus Tatzgern, Raphael Grasset, Eduardo Veas, Denis Kalkofen, Hartmut Seichter, Dieter Schmalstieg:
	</div><div>
	  <b>Exploring Distant Real World Objects with Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. Joint Virtual Reality Conference (JVRC 2013)</i>,
	  
      
	  December 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_250" style="display:none;">
    <div>
	  Christian Partl, Alexander Lex, Marc Streit, Denis Kalkofen, Karl Kashofer, Dieter Schmalstieg:
	</div><div>
	  <b>{enRoute:} Dynamic Path Extraction from Biological Pathway Maps for Exploring Heterogeneous Experimental Datasets</b>
	</div><div>
	  
	    <i>{BMC} Bioinformatics</i>, 
	    vol. 14,
	    
	  
      
	  November 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=lOX1XFKNqo0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_261" style="display:none;">
    <div>
	  Tobias Langlotz, Holger Regenbrecht, Stefanie Zollmann, Dieter Schmalstieg:
	</div><div>
	  <b>Audio Stickies: Visually-guided Spatial Audio Annotations on a Mobile Augmented Reality Platform</b>
	</div><div>
	  
	    In <i>Proc. OzCHI 2013</i>,
	  
      
	  November 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_248a" style="display:none;">
    <div>
	  Philip Voglreiter, Markus Steinberger, Rostislav Khlebnikov, Bernhard Kainz, Dieter Schmalstieg:
	</div><div>
	  <b>Volume Rendering with Advanced GPU Scheduling Strategies</b>
	</div><div>
	  
	    In <i>IEEE Scientific Visualization Posters</i>,
	  
      
	  October 2013, Best Poster Honorable Mention.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_253" style="display:none;">
    <div>
	  Rostislav Khlebnikov, Bernhard Kainz, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Noise-based volume rendering for the visualization of multivariate volumetric data</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. ,
	    
	  
      
	  October 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Analysis of multivariate data is of great importance in many scientific disciplines. However, visualization of 3D spatially-fixed multivariate volumetric data is a very challenging task. In this paper we present a method that allows simultaneous real-time visualization of multivariate data. We redistribute the opacity within a voxel to improve the readability of the color defined by a regular transfer function, and to maintain the see-through capabilities of volume rendering. We use predictable procedural noise--random-phase Gabor noise--to generate a high-frequency redistribution pattern and construct an opacity mapping function, which allows to partition the available space among the displayed data attributes. This mapping function is appropriately filtered to avoid aliasing, while maintaining transparent regions. We show the usefulness of our approach on various data sets and with different example applications. Furthermore, we evaluate our method by comparing it to other visualization techniques in a controlled user study. Overall, the results of our study indicate that users are much more accurate in determining exact data values with our novel 3D volume visualization method. Significantly lower error rates for reading data values and high subjective ranking of our method imply that it has a high chance of being adopted for the purpose of visualization of multivariate 3D data.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/UzSGyecFVgI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_254" style="display:none;">
    <div>
	  Alexander Lex, Christian Partl, Denis Kalkofen, Marc Streit, Samuel Gratzl, Anne Mai Wassermann, Dieter Schmalstieg, Hanspeter Pfister:
	</div><div>
	  <b>Entourage: Visualizing Relationships between Biological Pathways using Contextual Subsets</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. ,
	    
	  
      
	  October 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/gyEjtTHUqLg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_255" style="display:none;">
    <div>
	  Denis Kalkofen, Eduardo Veas, Stefanie Zollmann, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Adaptive Ghosted Views for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2013</i>,
	  
      
	  October 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In Augmented Reality (AR), ghosted views allow a viewer to explore hidden structure within the real-world environment. A body of previous work has explored which features are suitable to support the structural interplay between occluding and occluded elements. However, the dynamics of AR environments pose serious challenges to the presentation of ghosted views. While a model of the real world may help determine distinctive structural features, changes in appearance or illumination detriment the composition of occluding and occluded structure. In this paper, we present an approach that considers the information value of the scene before and after generating the ghosted view. Hereby, a contrast adjustment of preserved occluding features is calculated, which adaptively varies their visual saliency within the ghosted view visualization. This allows us to not only preserve important features, but to also support their prominence after revealing occluded structure, thus achieving a positive effect on the perception of ghosted views.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=xQlbeVjx0TI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_256" style="display:none;">
    <div>
	  Thanh Nguyen, Raphael Grasset, Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>Interactive Syntactic Modeling With a Single-Point Laser Range Finder and Camera</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2013</i>,
	  
      
	  October 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_257" style="display:none;">
    <div>
	  Andreas Hartl, Jens Grubert, Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>Mobile Interactive Hologram Verification</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2013</i>,
	  
      
	  October 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=t5TzFtcIFN8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_258" style="display:none;">
    <div>
	  Christian Pirchheim, Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>Handling Pure Camera Rotation in Keyframe-Based SLAM</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2013</i>,
	  
      
	  October 2013, .
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=Nq07MCO-lCw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_259" style="display:none;">
    <div>
	  Lukas Gruber, Pradeep Sen, Tobias Hollerer, Dieter Schmalstieg:
	</div><div>
	  <b>Acceleration Methods for Radiance Transfer in Photorealistic Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2013</i>,
	  
      
	  October 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_260" style="display:none;">
    <div>
	  Philipp Voglreiter, Markus Steinberger, Bernhard Kainz, Rostislav Khlebnikov, Dieter Schmalstieg:
	</div><div>
	  <b>Dynamic GPU Scheduling for Volume Rendering</b>
	</div><div>
	  
	    In <i>Proc. IEEE Scientific Visualization 2013</i>,
	  
      
	  October 2013, Best poster honorable mention for IEEE SciVis 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_251" style="display:none;">
    <div>
	  Jens Grubert, Dieter Schmalstieg:
	</div><div>
	  <b>Playing it Real Again: A Repeated Evaluation of Magic Lens and Static Peephole Interfaces in Public Space</b>
	</div><div>
	  
	    In <i>Proc. ACM MobileHCI 2013</i>,
	  
      
	  August 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_252" style="display:none;">
    <div>
	  Clemens Arth, Jonathan Ventura, Dieter Schmalstieg:
	</div><div>
	  <b>Geospatial Management and Utilization of Large-Scale Urban Visual Reconstruction</b>
	</div><div>
	  
	    In <i>Proc. 4th International Conference on Computing for Geospatial Research and Application (COM.Geo 2013)</i>,
	  
      
	  July 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_249" style="display:none;">
    <div>
	  Manuela Waldner, Dieter Schmalstieg:
	</div><div>
	  <b>Towards Ubiquitous Information Space Management</b>
	</div><div>
	  
	    In <i>Proc. CHI 2013 International Workshop on Interactive Ultra-High-Resolution Displays</i>,
	  
      
	  April 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_248" style="display:none;">
    <div>
	  Markus Tatzgern, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Dynamic Compact Visualizations for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality (VR) 2013</i>,
	  
      
	  March 2013.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=xL1aV9C4tYY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_243" style="display:none;">
    <div>
	  Bernhard Kainz, Stefan Hauswiesner, Raphael Grasset, Markus Steinberger, Lukas Gruber, Jens Grubert, Eduardo Veas, Denis Kalkofen, Hartmut Seichter, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>OmniKinect: Real-Time Dense Volumetric Data Acquisition and Applications</b>
	</div><div>
	  
	    In <i>Proc. Virtual Reality Software and Technology (VRST) 2012</i>,
	  
      
	  December 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Real-time three-dimensional acquisition of real-world scenes has many important applications in computer graphics, computer vision and human-computer interaction. Inexpensive depth sensors such as the Microsoft Kinect allow to leverage the development of such applications. However, this technology is still relatively recent, and no detailed studies on its scalability to dense and view-independent acquisition have been reported. This paper addresses the question of what can be done with a larger number of Kinects used simultaneously. We describe an interference-reducing physical setup, a calibration procedure and an extension to the KinectFusion algorithm, which allows to produce high quality volumetric reconstructions from multiple Kinects whilst overcoming systematic errors in the depth measurements. We also report on enhancing image based visual hull rendering by depth measurements, and compare the results to KinectFusion. Our system provides practical insight into achievable spatial and radial range and into bandwidth requirements for depth data acquisition. Finally, we present a number of practical applications of our system.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=CQjisWt1d9w" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_235" style="display:none;">
    <div>
	  Clemens Arth, Alessandro Mulloni, Dieter Schmalstieg:
	</div><div>
	  <b>Exploiting Sensors on Mobile Phones to Improve Wide-Area Localization</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Pattern Recognition (ICPR) 2012</i>,
	  
      
	  November 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=4rQLDwf8yac" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_242" style="display:none;">
    <div>
	  Alessandro Mulloni, Dieter Schmalstieg:
	</div><div>
	  <b>Enhancing Handheld Navigation Systems with Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Service-Oriented Mapping (SOMAP) 2012</i>,
	  
      
	  November 2012, Invited paper.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_244" style="display:none;">
    <div>
	  Raphael Grasset, Markus Tatzgern, Tobias Langlotz, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Image-Driven View Management for Augmented Reality Browsers</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2012</i>,
	  
      
	  November 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/TUKuoDD6Hxw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_245" style="display:none;">
    <div>
	  Lukas Gruber, Thomas Richter-Trummer, Dieter Schmalstieg:
	</div><div>
	  <b>Real-time Photometric Registration from Arbitrary Geometry</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR) 2012</i>,
	  
      
	  November 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=YfYLN39bO2U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_246" style="display:none;">
    <div>
	  Clemens Arth, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Full 6DOF Pose Estimation from Geo-Located Images</b>
	</div><div>
	  
	    In <i>Proc. Asian Conference on Computer Vision (ACCV) 2012</i>,
	  
      
	  November 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_247" style="display:none;">
    <div>
	  Markus Steinberger, Bernhard Kainz, Bernhard Kerbl and
Stefan Hauswiesner, Michael Kenzel, Dieter Schmalstieg:
	</div><div>
	  <b>Softshell: Dynamic Scheduling on GPUs</b>
	</div><div>
	  
	    <i>ACM Transactions on Graphics (Proc. SIGGRAPH Asia)</i>, 
	    vol. 31,
	    
	  
      
	  November 2012, Article 161.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper we present Softshell, a novel execution model for devices composed of multiple processing cores operating in a single instruction, multiple data fashion, such as graphics processing units (GPUs). The Softshell model is intuitive and more flexible than the kernel-based adaption of the stream processing model, which is currently the dominant model for general purpose GPU computation. Using the Softshell model, algorithms with a relatively low local degree of parallelism can execute efficiently on massively parallel architectures. Softshell has the following distinct advantages: (1) work can be dynamically issued directly on the device, eliminating the need for synchronization with an external source, i.e., the CPU; (2) its three-tier dynamic scheduler supports arbitrary scheduling strategies, including dynamic priorities and real-time scheduling; and (3) the user can influence, pause, and cancel work already submitted for parallel execution. The Softshell processing model thus brings capabilities to GPU architectures that were previously only known from operating-system designs and reserved for CPU programming. As a proof of our claims, we present a publicly available implementation of the Softshell processing model realized on top of CUDA. The benchmarks of this implementation demonstrate that our processing model is easy to use and also performs substantially better than the state-of-the-art kernel-based processing model for problems that have been difficult to parallelize in the past.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_229" style="display:none;">
    <div>
	  Markus Steinberger, Bernhard Kainz, Stefan Hauswiesner and
Rostislav Khlebnikov, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Ray Prioritization Using Stylization and Visual Saliency</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 36,
	    
	  
      
	  October 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper presents a new method to control scene sampling in complex ray-based rendering environments. It proposes to constrain image sampling density with a combination of object features, which are known to be well perceived by the human visual system, and image space saliency, which captures effects that are not based on the object's geometry. The presented method uses Non- Photorealistic Rendering techniques for the object space feature evaluation and combines the image space saliency calculations with image warping to infer quality hints from previously generated frames. In order to map different feature types to sampling densities, we also present an evaluation of the object space and image space features' impact on the resulting image quality. In addition, we present an efficient, adaptively aligned fractal pattern that is used to reconstruct the image from sparse sampling data. Furthermore, this paper presents an algorithm which uses our method in order to guarantee a desired minimal frame rate. Our scheduling algorithm maximizes the utilization of each given time slice by rendering features in the order of visual importance values until a time constraint is reached. We demonstrate how our method can be used to boost or stabilize the rendering time in complex ray- based image generation consisting of geometric as well as volumetric data.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=HjZYv_FaPSI&amp;list=PLlDsBa-6PMG0AwYG9hzvBn4fj_brn91G_&amp;index=22&amp;t=0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_236" style="display:none;">
    <div>
	  Christian Partl, Alexander Lex, Denis Kalkofen, Marc Streit, Karl Kashofer, Dieter Schmalstieg:
	</div><div>
	  <b>enRoute: Dynamic Path Extraction from Biological Pathway Maps for In-Depth Experimental Data Analysis</b>
	</div><div>
	  
	    In <i>Proc. IEEE Symposium on Biological Data Visualization (BioVis) 2012</i>,
	  
      
	  October 2012, Best paper award..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Biological pathway maps are highly relevant tools for many tasks in molecular biology. They reduce the complexity of the overall biological network by partitioning it into smaller manageable parts. While this reduction of complexity is their biggest strength, it is, at the same time, their biggest weakness. By removing what is deemed not important for the primary function of the pathway, biologists lose the ability to follow and understand cross-talks between pathways. Considering these cross-talks is, however, critical in many analysis scenarios, such as judging effects of drugs. In this paper we introduce Entourage, a novel visualization technique that provides contextual information lost due to the artificial partitioning of the biological network, but at the same time limits the presented information to what is relevant to the analyst's task. We use one pathway map as the focus of an analysis and allow a larger set of contextual pathways. For these context pathways we only show the contextual subsets, i.e., the parts of the graph that are relevant to a selection. Entourage suggests related pathways based on similarities and highlights parts of a pathway that are interesting in terms of mapped experimental data. We visualize interdependencies between pathways using stubs of visual links, which we found effective yet not obtrusive. By combining this approach with visualization of experimental data, we can provide domain experts with a highly valuable tool. We demonstrate the utility of Entourage with case studies conducted with a biochemist who researches the effects of drugs on pathways. We show that the technique is well suited to investigate interdependencies between pathways and to analyze, understand, and predict the effect that drugs have on different cell types.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/lOX1XFKNqo0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_238" style="display:none;">
    <div>
	  Bernhard Kerbl, Philip Voglreiter, Rostislav Khlebnikov, Dieter Schmalstieg, Philipp Stiegler, Daniel Seider, Michael Moche, Bernhard Kainz:
	</div><div>
	  <b>Intervention Planning of Hepatocellular Carcinoma Radio-Frequency Ablations</b>
	</div><div>
	  
	    In <i>Proc. MICCAI Workshop on Clinical Image-based Procedures (CLIP) 2012</i>,
	  
      
	  October 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_239" style="display:none;">
    <div>
	  Philip Voglreiter, Markus Steinberger, Dieter Schmalstieg, Bernhard Kainz:
	</div><div>
	  <b>Volumetric Real-Time Particle-Based Representation of Large Unstructured Tetrahedral Polygon Meshes</b>
	</div><div>
	  
	    In <i>Proc. MICCAI Workshop on Workshop on Mesh Processing in Medical Image Analysis (MeshMed) 2012</i>,
	  
      
	  October 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_241" style="display:none;">
    <div>
	  Alexander Lex, Marc Streit, Hans-Joerg Schulz, Christian Partl, Dieter Schmalstieg, Peter Park, Nils Gehlenborg:
	</div><div>
	  <b>StratomeX: Enabling Visualization-Driven Cancer Subtype Analysis</b>
	</div><div>
	  
	    In <i>Proc. IEEE Symposium on Biological Data Visualization (BioVis) 2012</i>,
	  
      
	  October 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=UcKDbGqHsdE&amp;list=PLlDsBa-6PMG0AwYG9hzvBn4fj_brn91G_&amp;index=54&amp;t=0s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_221" style="display:none;">
    <div>
	  Bernhard Kainz, Rupert Portugaller, Daniel Seider, Michael Moche, Philipp Stiegler, Dieter Schmalstieg:
	</div><div>
	  <b>Volume Visualization in the Clinical Practice</b>
	</div><div>
	  
	    In <i>Augmented Environments for Computer-Assisted Interventions</i>,
	  
      
	  September 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_237" style="display:none;">
    <div>
	  Alessandro Mulloni, Jens Grubert, Hartmut Seichter, Tobias Langlotz, Raphael Grasset, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Experiences with the Impact of Tracking Technology in Mobile Augmented Reality Evaluations</b>
	</div><div>
	  
	    In <i>Proc. MobileHCI Workshop on Mobile Vision and HCI (MobiVis) 2012</i>,
	  
      
	  September 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_210" style="display:none;">
    <div>
	  Martin Urschler, Alexander Bornik, Eva Scheurer, Kathrin
Yen, Horst Bischof, Dieter Schmalstieg:
	</div><div>
	  <b>Forensic Case Analysis: From 3D Imaging to Interactive Visualization</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 32,
	    
	  
      
	  July 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=n1Q4jmbbC-Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_228" style="display:none;">
    <div>
	  Michael Gervautz, Dieter Schmalstieg:
	</div><div>
	  <b>Anywhere Interfaces Using Handheld Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Computer</i>, 
	    vol. 45,
	    
	  
      
	  July 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_233" style="display:none;">
    <div>
	  Alexander Bornik, Wolfgang Knecht, Markus Hadwidger, Dieter Schmalstieg:
	</div><div>
	  <b>Clustered Deep Shadow Maps for Integrated Polyhedral and Volume Rendering</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Visual Computing (ISVC) 2012</i>,
	  
      
	  July 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_234" style="display:none;">
    <div>
	  Stefan Hauswiesner, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Frame Cache Management for Multi-frame Rate Systems</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Visual Computing (ISVC) 2012</i>,
	  
      
	  July 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_209" style="display:none;">
    <div>
	  Marc Streit, Hans-Joerg Schulz, Alexander Lex, Dieter Schmalstieg
and Heidrun Schumann:
	</div><div>
	  <b>Model-Driven Design for the Visual Analysis of Heterogeneous Data</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 18,
	    
	  
      
	  June 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">As heterogeneous data from different sources are being increasingly linked, it becomes difficult for users to understand how the data are connected, to identify what means are suitable to analyze a given data set, or to find out how to proceed for a given analysis task. We target this challenge with a new model-driven design process that effectively codesigns aspects of data, view, analytics, and tasks. We achieve this by using the workflow of the analysis task as a trajectory through data, interactive views, and analytical processes. The benefits for the analysis session go well beyond the pure selection of appropriate data sets and range from providing orientation or even guidance along a preferred analysis path to a potential overall speedup, allowing data to be fetched ahead of time. We illustrate the design process for a biomedical use case that aims at determining a treatment plan for cancer patients from the visual analysis of a large, heterogeneous clinical data pool. As an example for how to apply the comprehensive design approach, we present Stack'n'flip, a sample implementation which tightly integrates visualizations of the actual data with a map of available data sets, views, and tasks, thus capturing and communicating the analytical workflow through the required data sets.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/a5qBmOrYS7M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_231" style="display:none;">
    <div>
	  Rostislav Khlebnikov, Bernhard Kainz, Markus Steinberger, Marc Streit, Dieter Schmalstieg:
	</div><div>
	  <b>Procedural texture synthesis for zoom-independent visualization of multivariate data</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 31,
	    
	  
      
	  June 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Simultaneous visualization of multiple continuous data attributes in a single visualization is a task that is important for many application areas. Unsurprisingly, many methods have been proposed to solve this task. However, the behavior of such methods during the exploration stage, when the user tries to understand the data with panning and zooming, has not been given much attention. In this paper, we propose a method that uses procedural texture synthesis to create zoom-independent visualizations of three scalar data attributes. The method is based on random-phase Gabor noise, whose frequency is adapted for the visualization of the first data attribute. We ensure that the resulting texture frequency lies in the range that is perceived well by the human visual system at any zoom level. To enhance the perception of this attribute, we also apply a specially constructed transfer function that is based on statistical properties of the noise. Additionally, the transfer function is constructed in a way that it does not introduce any aliasing to the texture. We map the second attribute to the texture orientation. The third attribute is color coded and combined with the texture by modifying the value component of the HSV color model. The necessary contrast needed for texture and color perception was determined in a user study. In addition, we conducted a second user study that shows significant advantages of our method over current methods with similar goals. We believe that our method is an important step towards creating methods that not only succeed in visualizing multiple data attributes, but also adapt to the behavior of the user during the data exploration stage.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=vSwBiOs54b8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_232" style="display:none;">
    <div>
	  Alexander Lex, Marc Streit, Hans-Joerg Schulz, Christian Partl, Dieter Schmalstieg, Peter Park, Nils Gehlenborg:
	</div><div>
	  <b>StratomeX: Visual Analysis of Large-Scale Heterogeneous Genomics Data for Cancer Subtype Characterization</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 31,
	    
	  
      
	  June 2012, 3rd Best Paper Award at EuroVis 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Identification and characterization of cancer subtypes are important areas of research that are based on the integrated analysis of multiple heterogeneous genomics datasets. Since there are no tools supporting this process, much of this work is done using ad-hoc scripts and static plots, which is inefficient and limits visual exploration of the data. To address this, we have developed StratomeX, an integrative visualization tool that allows investigators to explore the relationships of candidate subtypes across multiple genomic data types such as gene expression, DNA methylation, or copy number data. StratomeX represents datasets as columns and subtypes as bricks in these columns. Ribbons between the columns connect bricks to show subtype relationships across datasets. Drill-down features enable detailed exploration. StratomeX provides insights into the functional and clinical implications of candidate subtypes by employing small multiples, which allow investigators to assess the effect of subtypes on molecular pathways or outcomes such as patient survival. As the configuration of viewing parameters in such a multi-dataset, multi-view scenario is complex, we propose a meta visualization and configuration interface for dataset dependencies and data-view relationships. StratomeX is developed in close collaboration with domain experts. We describe case studies that illustrate how investigators used the tool to explore subtypes in large datasets and demonstrate how they efficiently replicated findings from the literature and gained new insights into the data.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/UcKDbGqHsdE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_174a" style="display:none;">
    <div>
	  Markus Steinberger, Michael Kenzel, Bernhared Kainz, Dieter Schmalstieg:
	</div><div>
	  <b>ScatterAlloc: Massively parallel dynamic memory allocation for the GPU</b>
	</div><div>
	  
	    In <i>Proc. Innovative Parallel Computing (InPar)</i>,
	  
      
	  May 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we analyze the special requirements of a dynamic memory allocator that is designed for massively parallel architectures such as Graphics Processing Units (GPUs). We show that traditional strategies, which work well on CPUs, are not well suited for the use on GPUs and present the thorough design of ScatterAlloc, which can efficiently deal with hundreds of requests in parallel. Our allocator greatly reduces collisions and congestion by scattering memory requests based on hashing. We analyze ScatterAlloc in terms of allocation speed, data access time and fragmentation, and compare it to current state-of-the-art allocators, including the one provided with the NVIDIA CUDA toolkit. Our results show, that ScatterAlloc clearly outperforms these other approaches, yielding speed-ups between 10 to 100.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_225" style="display:none;">
    <div>
	  Markus Steinberger, Manuela Waldner, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Self-Organizing Windows</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 31,
	    
	  
      
	  May 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper, we present the design and implementation of a dynamic window management technique that changes the perception of windows as fixed-sized rectangles. The primary goal of self-organizing windows is to automatically display the most relevant information for a user's current activity, which removes the burden of organizing and arranging windows from the user. We analyze the image-based representation of each window and identify coherent pieces of information. The windows are then automatically moved, scaled and composed in a contentaware manner to fit the most relevant information into the limited area of the screen. During the design process, we consider findings from previous experiments and show how users can benefit from our system. We also describe how the immense processing power of current graphics processing units can be exploited to build an interactive system that finds an optimal solution within the complex design space of all possible window transformations in real time.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=1Al-oFbOq58" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_227" style="display:none;">
    <div>
	  Alessandro Mulloni, Hartmut Seichter, Andreas Duenser, Patrick Baudisch, Dieter Schmalstieg:
	</div><div>
	  <b>360 Degree Panoramic Overviews for Location-Based Services</b>
	</div><div>
	  
	    In <i>ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  May 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_230" style="display:none;">
    <div>
	  Alessandro Mulloni, Hartmut Seichter, Dieter Schmalstieg:
	</div><div>
	  <b>Indoor Navigation with Mixed Reality World-in-Miniature Views and Sparse Localization on Mobile Devices</b>
	</div><div>
	  
	    In <i>Proc. Advanced Visual Interfaces (AVI) 2012</i>,
	  
      
	  May 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_200" style="display:none;">
    <div>
	  Tobias Langlotz, Daniel Wagner, Alessandro Mulloni, Dieter
Schmalstieg:
	</div><div>
	  <b>Online Creation of Panoramic Augmented Reality Annotations on Mobile Phones</b>
	</div><div>
	  
	    <i>IEEE Pervasive Computing</i>, 
	    vol. 11,
	    
	  
      
	  April 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_226" style="display:none;">
    <div>
	  Eduardo Veas, Raphael Grasset, Ernst Kruijff, Dieter Schmalstieg:
	</div><div>
	  <b>Extended Overview Techniques for Outdoor Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 18,
	    
	  
      
	  April 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_222" style="display:none;">
    <div>
	  Clemens Holzhueter, Alexander Lex, Dieter Schmalstieg, {Hans-Joerg} Schulz, Heidrun Schumann, Marc Streit:
	</div><div>
	  <b>Visualizing Uncertainty in Biological Expression Data</b>
	</div><div>
	  
	    In <i>Proceedings of the {SPIE} Conference on Visualization and Data Analysis {(VDA} '12)</i>,
	  
      
	  January 2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_240" style="display:none;">
    <div>
	  Eduardo Veas, Raphael Grasset, Ioan Ferencik, Thomas Gruenewald, Dieter Schmalstieg:
	</div><div>
	  <b>Mobile Augmented Reality for Environmental Monitoring</b>
	</div><div>
	  
	    <i>Personal and Ubiquitous Computing</i>, 
	    
	    
	  
      
	   2012.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_223" style="display:none;">
    <div>
	  Manuela Waldner, Raphael Grasset, Markus Steinberger, Dieter Schmalstieg:
	</div><div>
	  <b>Display-Adaptive Window Management for Irregular Surfaces</b>
	</div><div>
	  
	    In <i>ACM International Conference on Interactive Tabletops and Surfaces (ITS 2011)</i>,
	  
      
	  November 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Current projectors can easily be combined to create an everywhere display, using all suitable surfaces in offices or meeting rooms for the presentation of information. However, the resulting irregular display is not well supported by tradi tional desktop window managers, which are optimized for rectangular screens. In this paper, we present novel display-adaptive window management techniques, which provide semi-automatic placement for desktop elements (such as windows or icons) for users of large, irregularly shaped displays. We report results from an exploratory study, which reveals interesting emerging strategies of users in the manipulation of windows on large irregular displays and shows that the new techniques increase subjective satisfaction with the window management interface.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_213" style="display:none;">
    <div>
	  Alexander Lex, Hans-Joerg Schulz, Marc Streit, Christian Partl, Dieter Schmalstieg:
	</div><div>
	  <b>VisBricks: Multiform Visualization of Large, Inhomogeneous Data</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 17,
	    
	  
      
	  October 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=_5J80uDTxD8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_214" style="display:none;">
    <div>
	  Markus Steinberger, Manuela Waldner, Marc Streit, Alexander Lex, Dieter Schmalstieg:
	</div><div>
	  <b>Context-Preserving Visual Links</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 17,
	    
	  
      
	  October 2011, Best paper award at IEEE InfoVis 2011..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Evaluating, comparing, and interpreting related pieces of information are tasks that are commonly performed during visual data analysis and in many kinds of information-intensive work. Synchronized visual highlighting of related elements is a well-known technique used to assist this task. An alternative approach, which is more invasive but also more expressive is visual linking in which line connections are rendered between related elements. In this work, we present context-preserving visual links as a new method for generating visual links. The method specifically aims to fulfill the following two goals: first, visual links should minimize the occlusion of important information; second, links should visually stand out from surrounding information by minimizing visual interference. We employ an image-based analysis of visual saliency to determine the important regions in the original representation. A consequence of the image-based approach is that our technique is application-independent and can be employed in a large number of visual data analysis scenarios in which the underlying content cannot or should not be altered. We conducted a controlled experiment that indicates that users can find linked elements in complex visualizations more quickly and with greater subjective satisfaction than in complex visualizations in which plain highlighting is used. Context-preserving visual links were perceived as visually more attractive than traditional visual links that do not account for the context information.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=pdYc1N2XHtE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_216" style="display:none;">
    <div>
	  Rostislav Khlebnikov, Bernhard Kainz, Judith Muehl, Dieter Schmalstieg:
	</div><div>
	  <b>Crepuscular Rays for Tumor Accessibility Planning</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 12,
	    
	  
      
	  October 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=mHO6gCm9EP4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_220" style="display:none;">
    <div>
	  Clemens Arth, Manfred Klopschitz, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Real-Time Self-Localization from Panoramic Images on Mobile Devices</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/JdhismVQYYE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_220a" style="display:none;">
    <div>
	  Markus Tatzgern, Denis Kalkofen, Raphael Grasset, Dieter Schmalstieg:
	</div><div>
	  <b>Virtual Views for Augmented Reality Navigation</b>
	</div><div>
	  
	    In <i>Proc. ISMAR'11 Workshop on Visualization in Mixed Reality Environments</i>,
	  
      
	  October 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_224" style="display:none;">
    <div>
	  Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Challenges of Large-Scale Augmented Reality on Smartphones</b>
	</div><div>
	  
	    In <i>ISMAR 2011 Workshop on Enabling Large-Scale Outdoor Mixed Reality and Augmented Reality</i>,
	  
      
	  October 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_217" style="display:none;">
    <div>
	  Denis Kalkofen, Christian Sandor, Sean White, Dieter Schmalstieg:
	</div><div>
	  <b>Visualization Techniques for Augmented Reality</b>
	</div><div>
	  
	    In <i>Handbook of Augmented Reality</i>,
	  
      
	  September 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_218" style="display:none;">
    <div>
	  Raphael Grasset, Alessandro Mulloni, Mark Billinghurst, Dieter Schmalstieg:
	</div><div>
	  <b>Navigation Techniques in Augmented and Mixed Reality: Crossing the Virtuality Continuum</b>
	</div><div>
	  
	    In <i>Handbook of Augmented Reality</i>,
	  
      
	  September 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_202" style="display:none;">
    <div>
	  Alessandro Mulloni, Hartmut Seichter, Dieter Schmalstieg:
	</div><div>
	  <b>Handheld Augmented Reality Indoor Navigation with Activity-Based Instructions</b>
	</div><div>
	  
	    In <i>Proc. MobileHCI 2011</i>,
	  
      
	  August 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/kuFD7ul8BVQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_211" style="display:none;">
    <div>
	  Ann Morrison, Alessandro Mulloni, Saija Lemmelae, Antti
Oulasvirta, Giulio Jacucci, Peter Peltonen, Dieter Schmalstieg
and Holger Regenbrecht:
	</div><div>
	  <b>Collaborative use of mobile augmented reality with paper maps</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 35,
	    
	  
      
	  August 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/9cQIHbEcd08" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_212" style="display:none;">
    <div>
	  Alessadro Mulloni, Hartmut Seichter, Dieter Schmalstieg:
	</div><div>
	  <b>Enhancing Handheld Navigation Systems with Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. Mobile Augmented Reality Workshop at MobileHCI2011</i>,
	  
      
	  August 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_215" style="display:none;">
    <div>
	  Bernhard Kainz, Stefan Hauswiesner, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Stylization-based ray prioritization for guaranteed frame rates</b>
	</div><div>
	  
	    In <i>Proc. Non-Photorealistic Animation and Rendering (NPAR)</i>,
	  
      
	  August 2011, Best paper award..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_219" style="display:none;">
    <div>
	  Tobias Langlotz, Claus Degendorfer, Alessandro Mulloni and
Gerhard Schall, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Robust detection and tracking of annotations for outdoor augmented reality browsing</b>
	</div><div>
	  
	    <i>computers and graphics</i>, 
	    vol. 35,
	    
	  
      
	  August 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_199" style="display:none;">
    <div>
	  Daniel Pustka, Manuel Huber, Christian Waechter, Florian
Keitler, Gudrun Klinker, Joseph Newman, Dieter Schmalstieg:
	</div><div>
	  <b>Automatic Configuration of Pervasive Sensor Networks for Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Pervasive Computing</i>, 
	    vol. 10,
	    
	  
      
	  July 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_203" style="display:none;">
    <div>
	  Thomas Geymayer, Alexander Lex, Marc Streit, Dieter Schmalstieg:
	</div><div>
	  <b>Visualizing the Effects of Logically Combined Filters</b>
	</div><div>
	  
	    In <i>Proc. 15th International Conference on Information Visualisation (IV'2011)</i>,
	  
      
	  July 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_204" style="display:none;">
    <div>
	  Andreas Hartl, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Instant Medical Pill Regonition on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. IASTED International Conference on Computer Vision 2011</i>,
	  
      
	  June 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_205" style="display:none;">
    <div>
	  Clemens Arth, Andreas Hartl, Lukas Gruber, Stefan Hauswiesner
and Dieter Schmalstieg:
	</div><div>
	  <b>Rapid Reconstruction of Small Objects on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. Conference on Computer Vision and Pattern Recognition Workshops</i>,
	  
      
	  June 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_207" style="display:none;">
    <div>
	  Manuela Waldner, Markus Steinberger, Raphael Grasset, Dieter
Schmalstieg:
	</div><div>
	  <b>Importance-Driven Compositing Window Management</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  May 2011, Honorable Mention Award.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper we present importance-driven compositing window management, which considers windows not only as basic rectangular shapes but also integrates the importance of the windows' content using a bottom-up visual attention model. Based on this information, importance-driven compositing optimizes the spatial window layout for maximum visibility and interactivity of occluded content in combination with see-through windows. We employ this technique for emerging window manager functions to minimize information overlap caused by popping up windows or floating toolbars and to improve the access to occluded window content. An initial user study indicates that our technique provides a more effective and satisfactory access to occluded information than the well-adopted Alt+Tab window switching technique and see-through windows without optimized spatial layout.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=3BLJQWhsbDo" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_208" style="display:none;">
    <div>
	  Eduardo Veas, Erick Mendez, Steven Feiner, Dieter Schmalstieg:
	</div><div>
	  <b>Directing Attention and Influencing Memory with Visual Saliency Modulation</b>
	</div><div>
	  
	    In <i>Proc. ACM Conference on Human Factors in Computing Systems (CHI)</i>,
	  
      
	  May 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=S1kuPHfMlcI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_203a" style="display:none;">
    <div>
	  Rostislav Khlebnikov, Bernhard Kainz, Bernhard Roth, Judith Muehl, Dieter Schmalstieg:
	</div><div>
	  <b>GPU Based On-the-fly Light Emission-absorption Approximation for Direct Multi-volume Rendering</b>
	</div><div>
	  
	    In <i>Proc. EUROGRAPHICS 2011 Posters</i>,
	  
      
	  April 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_206" style="display:none;">
    <div>
	  Manuela Waldner, Dieter Schmalstieg:
	</div><div>
	  <b>Collaborative Information Linking: Bridging Knowledge Gaps between Users by Linking across Applications</b>
	</div><div>
	  
	    In <i>Proc. IEEE Pacific Visualization</i>,
	  
      
	  March 2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/4ZQqlhQ4V6k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_197" style="display:none;">
    <div>
	  Tobias Langlotz, Stefan Mooslechner, Stefanie Zollmann and
Claus Degendorfer, Dieter Schmalstieg:
	</div><div>
	  <b>Sketching up the world: In-situ authoring for mobile Augmented Reality</b>
	</div><div>
	  
	    <i>Journal of Personal and Ubiquitous Computing</i>, 
	    vol. 35,
	    
	  
      
	   2011.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/VikEPYTDzeA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_188" style="display:none;">
    <div>
	  Lukas Gruber, Steffen Gauglitz, Jonathan Ventura, Stefanie
Zollmann, Manuel Huber, Michael Schlegel, Gudrun Klinker
and Dieter Schmalstieg, Tobias Hollerer:
	</div><div>
	  <b>The City of Sights: Design, Construction, and Measurement of an Augmented Reality Stage Set</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR'10)</i>,
	  
      
	  October 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_189" style="display:none;">
    <div>
	  Lukas Gruber, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Color Harmonization for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR'10)</i>,
	  
      
	  October 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_190" style="display:none;">
    <div>
	  Manuela Waldner, Ernst Kruijff, Dieter Schmalstieg:
	</div><div>
	  <b>Bridging Gaps with Pointer Warping in Multi-Display Environments</b>
	</div><div>
	  
	    In <i>Proc. Nordic Conference on Human-Computer Interaction (NordiCHI 2010)</i>,
	  
      
	  October 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_191" style="display:none;">
    <div>
	  Manfred Klopschitz, Gerhard Schall, Dieter Schmalstieg and
Gerhard Reitmayr:
	</div><div>
	  <b>Visual Tracking for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Indoor Positioning and Indoor Navigation (IPIN 2010)</i>,
	  
      
	  September 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_192" style="display:none;">
    <div>
	  Alessandro Mulloni, Andreas Duenser, Dieter Schmalstieg:
	</div><div>
	  <b>Zooming Interfaces for Augmented Reality Browsers</b>
	</div><div>
	  
	    In <i>Proc. 13th International Conference on Human-Computer Interaction with Mobile Devices and Services (MobileHCI 2010)</i>,
	  
      
	  September 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/JvfGu-Yy6K4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_174" style="display:none;">
    <div>
	  Lukas Gruber, Stefanie Zollmann, Daniel Wagner, Dieter Schmalstieg
and Tobias Hollerer:
	</div><div>
	  <b>Optimization of Target Objects for Natural Feature Tracking</b>
	</div><div>
	  
	    In <i>Proc. International Conference on Pattern Recognition</i>,
	  
      
	  August 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_176" style="display:none;">
    <div>
	  Gerhard Reitmayr, Tobias Langlotz, Daniel Wagner, Alessandro
Mulloni, Gerhard Schall, Dieter Schmalstieg, Qi Pan:
	</div><div>
	  <b>Simultaneous Localization and Mapping for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Ubiquitous Virtual Reality</i>,
	  
      
	  July 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_185a" style="display:none;">
    <div>
	  Marc Streit, Alexander Lex, Helmut Doleisch, Dieter Schmalstieg:
	</div><div>
	  <b>Does software engineering pay off for research? Lessons learned from the Caleydo project</b>
	</div><div>
	  
	    In <i>Proc. Second Eurographics Workshop on Visual Computing for Biology and Medicine (VCBM)</i>,
	  
      
	  July 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_177" style="display:none;">
    <div>
	  Markus Tatzgern, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Compact Explosion Diagrams</b>
	</div><div>
	  
	    In <i>Proc. SIGGRAPH/EUROGRAPHICS Symposium on Non-Photorealistic Animation and Rendering (NPAR 2010)</i>,
	  
      
	  June 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_178" style="display:none;">
    <div>
	  Erick Mendez, Steve Feiner, Dieter Schmalstieg:
	</div><div>
	  <b>Focus and Context by Modulating First Order Salient Features for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. Smart Grapics 2010 (LNCS 6133</i>,
	  
      
	  June 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_182" style="display:none;">
    <div>
	  Markus Sareika, Dieter Schmalstieg:
	</div><div>
	  <b>Bimanual Handheld Mixed Reality Interfaces for Urban Planning</b>
	</div><div>
	  
	    In <i>Proc. of the International Conference on Advanced Visual Interfaces (AVI 2010)</i>,
	  
      
	  May 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_183" style="display:none;">
    <div>
	  Manfred Klopschitz, Arnold Irschara, Dieter Schmalstieg:
	</div><div>
	  <b>Robust Incremental Structure from Motion</b>
	</div><div>
	  
	    In <i>Proc. International Syposium on 3D Data Processing, Visualization and Transmission (3DPVT 2010)</i>,
	  
      
	  May 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_184" style="display:none;">
    <div>
	  Manuela Waldner, Werner Puff, Marc Streit, Alexander Lex
and Dieter Schmalstieg:
	</div><div>
	  <b>Visual Links Across Applications</b>
	</div><div>
	  
	    In <i>Proc. Graphics Interface 2010</i>,
	  
      
	  May 2010, Best student paper award.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=4uXvxAeb5xA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_185" style="display:none;">
    <div>
	  Alessandro Mulloni, Eduardo Veas, Ernst Kruijff, Dieter
Schmalstieg:
	</div><div>
	  <b>Techniques for View Transition in Multi-Camera Outdoor Environments</b>
	</div><div>
	  
	    In <i>Proc. Graphics Interface 2010</i>,
	  
      
	  May 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_186" style="display:none;">
    <div>
	  Stefan Hauswiesner, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Multi-Frame Rate Volume Rendering</b>
	</div><div>
	  
	    In <i>Proc. Eurographics Symposium on Parallel Graphics and Visualization</i>,
	  
      
	  May 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_187" style="display:none;">
    <div>
	  Manuela Waldner, Dieter Schmalstieg:
	</div><div>
	  <b>Experiences with Mouse-Controlled Multi-Display Environments.</b>
	</div><div>
	  
	    In <i>Proc. Advanced Visual Interfaces Workshop on Coupled Display Visual Interfaces</i>,
	  
      
	  May 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_173" style="display:none;">
    <div>
	  Dieter Schmalstieg, Alexander Bornik, Gernot Mueller-Putz and
Gert Pfurtscheller:
	</div><div>
	  <b>Gaze-Directed Ubiquitous Interaction Using a Brain-Computer Interface</b>
	</div><div>
	  
	    In <i>Proc. 1st Augmented Human International Conference (AH 2010)</i>,
	  
      
	  April 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_179" style="display:none;">
    <div>
	  Daniel Wagner, Alessandro Mulloni, Tobias Langlotz, Dieter
Schmalstieg:
	</div><div>
	  <b>Real-Time Panoramic Mapping and Tracking on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=jAkCUjAjdwQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_180" style="display:none;">
    <div>
	  Erick Mendez, Steve Feiner, Dieter Schmalstieg:
	</div><div>
	  <b>Experiences on Attention Direction Through Manipulation of Salient Features</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality Workshop on Perceptual Illusions in Virtual Environments (PIVE'10)</i>,
	  
      
	  March 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_181" style="display:none;">
    <div>
	  Alexander Lex, Marc Streit, Ernst Kruijff, Dieter Schmalstieg:
	</div><div>
	  <b>Caleydo: Design and Evaluation of a Visual Analysis Framework for Gene Expression Data in its Biological Context</b>
	</div><div>
	  
	    In <i>Proc. IEEE Pacific Visualization</i>,
	  
      
	  March 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=8SV3Id_lvNY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_175" style="display:none;">
    <div>
	  Manuela Waldner, Christian Pirchheim, Ernst Kruijff, Dieter
Schmalstieg:
	</div><div>
	  <b>Automatic Configuration of Spatially Consistent Mouse Pointer Navigation in Multi-Display Environments</b>
	</div><div>
	  
	    In <i>Proc. ACM Intelligent User Interfaces</i>,
	  
      
	  February 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_196" style="display:none;">
    <div>
	  Josef Faller, Gernot Mueller-Putz, Dieter Schmalstieg, Gert
Pfurtscheller:
	</div><div>
	  <b>An Application Framework for Controlling an Avatar in a Desktop Based Virtual Environment via a Software SSVEP Brain-Computer Interface</b>
	</div><div>
	  
	    <i>PRESENCE - Teleoperators and Virtual Environments</i>, 
	    vol. 19,
	    
	  
      
	  February 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_201" style="display:none;">
    <div>
	  Markus Tatzgern, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Multi-Perspective Compact Explosion Diagrams</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 35,
	    
	  
      
	  February 2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_193" style="display:none;">
    <div>
	  Andreas Hartl, Clemens Arth, Dieter Schmalstieg:
	</div><div>
	  <b>Instant Segmentation and Feature Extraction for Recognition of Simple Objects on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. IEEE Computer Vision and Pattern Recognition Workshop on Embedded Computer Vision 2010</i>,
	  
      
	   2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_194" style="display:none;">
    <div>
	  Josef Faller, Robert Leeb, Brendan Allison, Dieter Schmalstieg
and Gert Pfurtscheller:
	</div><div>
	  <b>SSVEP-based navigation using stimuli that are tightly integrated within a virtual feedback scenario</b>
	</div><div>
	  
	    In <i>Proc. BCI Meeting 2010</i>,
	  
      
	   2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_195" style="display:none;">
    <div>
	  Dieter Schmalstieg, Tobias Langlotz, Mark Billinghurst:
	</div><div>
	  <b>Augmented Reality 2.0</b>
	</div><div>
	  
	    In <i>Virtual Realities (Dagstuhl Seminar Proceedings)</i>,
	  
      
	   2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_198" style="display:none;">
    <div>
	  Alexander Lex, Marc Streit, Christian Partl, Karl Kashofer
and Dieter Schmalstieg:
	</div><div>
	  <b>Comparative Analysis of Multidimensional Quantitative Data</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics (Proc. InfoVis)</i>, 
	    vol. 16,
	    
	  
      
	   2010.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=vi-G3LqHFZA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_153a" style="display:none;">
    <div>
	  Erick Mendez, Dieter Schmalstieg:
	</div><div>
	  <b>Importance Masks for Revealing Occluded Objects in Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. ACM Virtual Reality Software and Technology</i>,
	  
      
	  November 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_163" style="display:none;">
    <div>
	  Gerhard Schall, Daniel Wagner, Gerhard Reitmayr, Elise Taichmann
and Manfred Wieser, Dieter Schmalstieg, Bernhard Hoffmann-Wellenhof:
	</div><div>
	  <b>Global Pose Estimation using Multi-Sensor Fusion for Outdoor Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/jtd1tp_ALQk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_164" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg, Horst Bischof:
	</div><div>
	  <b>Multiple Target Detection and Tracking with Guaranteed Framerates on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	  October 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=bMs101aTQL4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_159" style="display:none;">
    <div>
	  Judith Muehl, Alexander Bornik, Markus Grabner, Stefan Hauswiesner
and Dieter Schmalstieg:
	</div><div>
	  <b>The Future of Volume Graphics in Medical Virtual Reality</b>
	</div><div>
	  
	    In <i>Proc. 11th World Congress on Medical Physics and Biomedical Engineering</i>,
	  
      
	  September 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_153" style="display:none;">
    <div>
	  Heimo Mueller, Robert Reihs, Stefan Sauer, Kurt Zatloukal
and Marc Streit, Alexander Lex, Bernhard Schlegl, Dieter
Schmalstieg:
	</div><div>
	  <b>Connecting Genes with Diseases</b>
	</div><div>
	  
	    In <i>Proc. of 3rd International Conference on Information Visualization in Biomedical Informatics (IVBI'09)</i>,
	  
      
	  July 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_153b" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>History and Future of Tracking for Mobile Phone Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. International Symposium on Ubiquitous Virtual Reality (ISUVR 2009)</i>,
	  
      
	  July 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_154" style="display:none;">
    <div>
	  Marc Streit, Alexander Lex, Heimo Mueller, Dieter Schmalstieg:
	</div><div>
	  <b>Gaze-Based Focus Adaptation in an Information Visualization System</b>
	</div><div>
	  
	    In <i>Computer Graphics and Visualization and Image Processing Conference (CGVCVIP)</i>,
	  
      
	  June 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_155" style="display:none;">
    <div>
	  Daniela Markov-Vetter, Judith Muehl, Dieter Schmalstieg and
Erich Sorantin, Michael Riccabona:
	</div><div>
	  <b>3D Augmented Reality Simulator for Neonatale Cranial Sonography</b>
	</div><div>
	  
	    In <i>Proc. 23rd International Congress on Computer Aided Radiology and Surgery (CARS 2009)</i>,
	  
      
	  June 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_156" style="display:none;">
    <div>
	  Gudrun Schmidt-Gann, Katharina Schmid, Monika uehlein, Joachim
Struck, Andreas Bergmann, Dieter Schmalstieg, Marc Streit
and Alexander Lex, Douw G. van der Nest, Martijn van Griensven
and Heinz Redl:
	</div><div>
	  <b>Gene and Protein Expression Profiling in Liver in a Sepsis-Baboon Model</b>
	</div><div>
	  
	    In <i>Proc. 32nd Annual Meeting on Shock</i>,
	  
      
	  June 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_166" style="display:none;">
    <div>
	  Valerie Maquil, Markus Sareika, Dieter Schmalstieg, Ina
Wagner:
	</div><div>
	  <b>MR Tent: a place for co-constructing mixed realities in urban planning</b>
	</div><div>
	  
	    In <i>Proc. Graphics Interface 2009</i>,
	  
      
	  May 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_157" style="display:none;">
    <div>
	  Denis Kalkofen, Markus Tatzgern, Dieter Schmalstieg:
	</div><div>
	  <b>Explosion Diagrams in Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/MK3OnEsYQ_Y" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_158" style="display:none;">
    <div>
	  Christian Pirchheim, Manuela Waldner, Dieter Schmalstieg:
	</div><div>
	  <b>Deskotheque: Improved Spatial Awareness in Multi-Display Environments</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_150" style="display:none;">
    <div>
	  Denis Kalkofen, Erick Mendez, Dieter Schmalstieg:
	</div><div>
	  <b>Comprehensible Visualization for Augmented Reality</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 15,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_152" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>Making Augmented Reality Practical on Mobile Phones Part 1</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 29,
	    
	  
      
	  May/June 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_152a" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>Making Augmented Reality Practical on Mobile Phones Part 2</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 29,
	    
	  
      
	  July/August 2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_160" style="display:none;">
    <div>
	  Marc Streit, Hans-Joerg Schulz, Dieter Schmalstieg, Heidrun
Schumann:
	</div><div>
	  <b>Towards Multi-User Multi-Level Interaction</b>
	</div><div>
	  
	    In <i>Proc. VisWeek Workshop on Collaborative Visualization on Interactive Surfaces (CoVIS'09)</i>,
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_161" style="display:none;">
    <div>
	  Manuela Waldner, Alexander Lex, Marc Streit, Dieter Schmalstieg:
	</div><div>
	  <b>Design Considerations for Collaborative Information Workspaces in Multi-Display Environments</b>
	</div><div>
	  
	    In <i>Proc. VisWeek Workshop on Collaborative Visualization on Interactive Surfaces (CoVIS'09)</i>,
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_162" style="display:none;">
    <div>
	  Clemens Arth, Daniel Wagner, Manfred Klopschitz, Arnold
Irschara, Dieter Schmalstieg:
	</div><div>
	  <b>Wide Area Localization on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/f0cdO5GzkXI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_165" style="display:none;">
    <div>
	  Lukas Gruber, Stefanie Zollmann, Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>Evaluating the trackability of natural feature-point sets</b>
	</div><div>
	  
	    In <i>Proc. IEEE International Symposium on Mixed and Augmented Reality (ISMAR)</i>,
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_167" style="display:none;">
    <div>
	  Bernhard Kainz, Markus Grabner, Alexander Bornik, Stefan
Hauswiesner, Judith Muehl, Dieter Schmalstieg:
	</div><div>
	  <b>Ray Casting of Multiple Volumetric Datasets with Polyhedral Boundaries on Manycore GPUs</b>
	</div><div>
	  
	    <i>Transactions on Graphics (Proc. SIGGRAPH Asia)</i>, 
	    vol. 28,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=NEblcENepTc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_168" style="display:none;">
    <div>
	  Bernhard Kainz, Ursula Reiter, Gert Reiter, Dieter Schmalstieg:
	</div><div>
	  <b>In Vivo Interactive Visualization Of Four-Dimensional Blood Flow Patterns</b>
	</div><div>
	  
	    <i>The Visual Computer</i>, 
	    vol. 25,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_169" style="display:none;">
    <div>
	  Ina Wagner, Wolfgang Broll, Giulio Jacucci, Kari Kuutii
and Rod McCall, Ann Morrison, Dieter Schmalstieg, Jean-Jacques
Terrin:
	</div><div>
	  <b>On the Role of Presence in Mixed Reality</b>
	</div><div>
	  
	    <i>PRESENCE - Teleoperators and Virtual Environments</i>, 
	    vol. 18,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_170" style="display:none;">
    <div>
	  Daniel Wagner, Gerhard Reitmayr, Alessandro Mulloni, Dieter
Schmalstieg:
	</div><div>
	  <b>Real Time Detection and Tracking for Augmented Reality on Mobile Phones</b>
	</div><div>
	  
	    <i>IEEE Transactions on Visualization and Computer Graphics</i>, 
	    vol. 16,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=Xznr7V9MBJs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_171" style="display:none;">
    <div>
	  Alessandro Mulloni, Daniel Wagner, Istvan Barakonyi, Dieter
Schmalstieg:
	</div><div>
	  <b>Indoor Positioning and Navigation with Camera Phones</b>
	</div><div>
	  
	    <i>IEEE Pervasive Computing</i>, 
	    vol. 8,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_172" style="display:none;">
    <div>
	  Alexander Lex, Marc Streit, Michael Kalkusch, Kurt Zatloukal
and Dieter Schmalstieg:
	</div><div>
	  <b>Caleydo: Connecting Pathways with Gene Expression</b>
	</div><div>
	  
	    <i>Bioinformatics</i>, 
	    vol. 25,
	    
	  
      
	   2009.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=Uk-LgyA8ZBI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_140" style="display:none;">
    <div>
	  Sebastian Junghanns, Gerhard Schall, Dieter Schmalstieg:
	</div><div>
	  <b>Employing location-aware handheld augmented reality to assist utilities field personnel</b>
	</div><div>
	  
	    In <i>Proc. 5th International Symposium on LBS and TeleCartography (LBS 2008)</i>,
	  
      
	  November 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_141" style="display:none;">
    <div>
	  Gerhard Schall, Erick Mendez, Dieter Schmalstieg:
	</div><div>
	  <b>Virtual Redlining for Civil Engineering in Real Environments</b>
	</div><div>
	  
	    In <i>Proc. 7th IEEE/ACM International Symposium on Mixed and Augmented Reality</i>,
	  
      
	  September 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_142" style="display:none;">
    <div>
	  Daniel Wagner, Gerhard Reitmayr, Alessandro Mulloni, Tom
Drummond, Dieter Schmalstieg:
	</div><div>
	  <b>Pose Tracking from Natural Features on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. 7th IEEE International Symposium on Mixed and Augmented Reality</i>,
	  
      
	  September 2008, Best Paper Award 2008, lasting impact award 2018.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=4Q2TAUo-vQ0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_143" style="display:none;">
    <div>
	  Daniel Wagner, Tobias Langlotz, Dieter Schmalstieg:
	</div><div>
	  <b>Robust and Unobtrusive Marker Tracking on Mobile Phones</b>
	</div><div>
	  
	    In <i>Proc. 7th IEEE International Symposium on Mixed and Augmented Reality</i>,
	  
      
	  September 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_144" style="display:none;">
    <div>
	  Alessandro Mulloni, Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>Mobility and Social Interaction as Core Gameplay Elements in Multi-Player Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. 3rd International Conference on Digital Interactive Media in Entertainment and Arts (DIMEA 2008)</i>,
	  
      
	  September 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_132" style="display:none;">
    <div>
	  Manuela Waldner, Christian Pirchheim, Dieter Schmalstieg:
	</div><div>
	  <b>Multi Projector Displays Using a 3D Compositing Window Manager</b>
	</div><div>
	  
	    In <i>Proc. 3rd Workshop on Emerging Display Technologies (EDT-IPT'08)</i>,
	  
      
	  August 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_133" style="display:none;">
    <div>
	  Heimo Mueller, Kurt Zatloukal, Marc Streit, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Exploration of Medical Data Sets</b>
	</div><div>
	  
	    In <i>Symposium on Information Visualization in Biomedical Informatics</i>,
	  
      
	  July 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_134" style="display:none;">
    <div>
	  Manfred Klopschitz, Arnold Irschara, Christopher Zach, Dieter
Schmalstieg:
	</div><div>
	  <b>Generalized Detection and Merging of Loop Closures for Video Sequences</b>
	</div><div>
	  
	    In <i>Proc. International Syposium on 3D Data Processing Visualization and Transmission (3DPVT 2008)</i>,
	  
      
	  June 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_138" style="display:none;">
    <div>
	  Gerhard Schall, Erick Mendez, Ernst Kruijff, Eduardo Veas
and Sebastian Junghanns, Bernhard Reitinger, Dieter Schmalstieg:
	</div><div>
	  <b>Handheld Augmented Reality for Underground Infrastructure Visualization</b>
	</div><div>
	  
	    <i>Journal of Personal and Ubiquitous Computing</i>, 
	    vol. 13,
	    
	  
      
	  May 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=n4oOnPEO4z8" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_139" style="display:none;">
    <div>
	  Erick Mendez, Gerhard Schall, Sven Havemann, Sebastian Junghanns
and Dieter Fellner, Dieter Schmalstieg:
	</div><div>
	  <b>Generating Semantic 3D Models of Underground Infrastructure</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 28,
	    
	  
      
	  May 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_135" style="display:none;">
    <div>
	  Dieter Schmalstieg, Daniel Wagner:
	</div><div>
	  <b>Mobile Phones as a Platform for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the IEEE VR 2008 Workshop on Software Engineering and Architectures for Realtime Interactive Systems</i>,
	  
      
	  March 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_136" style="display:none;">
    <div>
	  Ralph Schoenfelder, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality for Industrial Building Acceptance</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_137" style="display:none;">
    <div>
	  Eduardo Veas, Dieter Schmalstieg:
	</div><div>
	  <b>Creating Meaningful Environment Models for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_145" style="display:none;">
    <div>
	  Daniel Wagner, Lukas Gruber, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality on Mobile Phones</b>
	</div><div>
	  
	    In <i>Shader X7</i>,
	  
      
	   2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_146" style="display:none;">
    <div>
	  Daniel Wagner, Bernhard Kainz, Dieter Schmalstieg:
	</div><div>
	  <b>Realtime 3D Graphics Programming Using the Quake3 Engine</b>
	</div><div>
	  
	    In <i>EUROGRAPHICS/SIGGRAPH Computer Graphics Educations Material Source (http://cgems.inesc.pt/)</i>,
	  
      
	   2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_147" style="display:none;">
    <div>
	  Gerhard Schall, Helmut Grabner, Paul Wohlhart, Dieter Schmalstieg
and Horst Bischof:
	</div><div>
	  <b>3D Tracking in Unknown Environments Using On-Line Keypoint Learning for Mobile Augmented Reality</b>
	</div><div>
	  
	    In <i>CVPR 2008 Workshop on Visual Localization for Mobile Platforms</i>,
	  
      
	   2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_148" style="display:none;">
    <div>
	  Istvan Barakonyi, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality Agents for User Interface Adaptation</b>
	</div><div>
	  
	    <i>Journal of Computer Animation and Virtual Worlds</i>, 
	    vol. 19,
	    
	  
      
	   2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_149" style="display:none;">
    <div>
	  Erick Mendez, Dieter Schmalstieg:
	</div><div>
	  <b>Context Sensitive Stylesheets for Scene Graphs</b>
	</div><div>
	  
	    <i>International Journal of Virtual Reality</i>, 
	    vol. 7,
	    
	  
      
	   2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_151" style="display:none;">
    <div>
	  Marc Streit, Michael Kalkusch, Karl Kashofer, Dieter Schmalstieg:
	</div><div>
	  <b>Navigation and Exploration of Interconnected Pathways</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 27,
	    
	  
      
	   2008.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_122" style="display:none;">
    <div>
	  Marc Streit, Michael Kalkusch, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Visualization of Metabolic Pathways</b>
	</div><div>
	  
	    In <i>Proc. IEEE Visualization Poster Companion</i>,
	  
      
	  October 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_123" style="display:none;">
    <div>
	  Manfred Klopschitz, Dieter Schmalstieg:
	</div><div>
	  <b>Automatic Reconstruction of Wide-Area Fiducial Marker Models</b>
	</div><div>
	  
	    In <i>Proc. 6th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'07)</i>,
	  
      
	  October 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_124" style="display:none;">
    <div>
	  Markus Sareika, Dieter Schmalstieg:
	</div><div>
	  <b>Urban Sketcher: Mixed Reality on Site for Urban Planning and Architecture</b>
	</div><div>
	  
	    In <i>Proc. 6th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'07)</i>,
	  
      
	  October 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_125" style="display:none;">
    <div>
	  Erick Mendez, Dieter Schmalstieg:
	</div><div>
	  <b>Adaptive Augmented Reality Using Context Markup and Style Maps</b>
	</div><div>
	  
	    In <i>Proc. 6th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'07)</i>,
	  
      
	  October 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_126" style="display:none;">
    <div>
	  Denis Kalkofen, Erick Mendez, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Focus and Context Visualization in Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. 6th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'07)</i>,
	  
      
	  October 2007, Best student paper award.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=NOkWzJG2Ru4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_127" style="display:none;">
    <div>
	  Dieter Schmalstieg, Daniel Wagner:
	</div><div>
	  <b>Experiences with Handheld Augmented Reality</b>
	</div><div>
	  
	    In <i>Proc. 6th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'07)</i>,
	  
      
	  October 2007, ISMAR Impact Paper Award 2023.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=1orI3Mv67kA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_116" style="display:none;">
    <div>
	  Manuela Waldner, Michael Kalkusch, Dieter Schmalstieg:
	</div><div>
	  <b>Optical Magic Lenses and Polarization Based Interaction Techniques</b>
	</div><div>
	  
	    In <i>Proc. 13th EUROGRAPHICS Symposium on Virtual Environments (EGVE'07)</i>,
	  
      
	  July 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_117" style="display:none;">
    <div>
	  Joseph Newman, Alexander Bornik, Daniel Pustka, Florian
Echtler, Manuel Huber, Dieter Schmalstieg, Gudrun Klinker:
	</div><div>
	  <b>Tracking for Distributed Mixed Reality Environments</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality Workshop on Trends and Issues in Tracking for Virtual Environments</i>,
	  
      
	  March 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_118" style="display:none;">
    <div>
	  Christian Pirchheim, Alexander Bornik, Dieter Schmalstieg:
	</div><div>
	  <b>Visual Programming for Hybrid User Interfaces</b>
	</div><div>
	  
	    In <i>Proc. of the 2nd International Workshop on Mixed Reality User Interfaces (MRUI'07) at the IEEE Virtual Reality 2007 Conference</i>,
	  
      
	  March 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_119" style="display:none;">
    <div>
	  Bernhard Reitinger, Christopher Zach, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality Scouting for Interactive 3D Reconstruction</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_120" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>Muddleware for Prototying Mixed Reality Multiuser Games</b>
	</div><div>
	  
	    In <i>Proc. IEEE Virtual Reality</i>,
	  
      
	  March 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_121" style="display:none;">
    <div>
	  Istvan Barakonyi, Dieter Schmalstieg, Helmut Prendinger and
Mitsuru Ishizuka:
	</div><div>
	  <b>Cascading Hand and Eye Movement for Augmented Reality Videoconferencing</b>
	</div><div>
	  
	    In <i>Proc. IEEE Symposium on 3D User Interfaces (3DUI'07)</i>,
	  
      
	  March 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_114" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>ARToolKitPlus for Pose Tracking on Mobile Devices</b>
	</div><div>
	  
	    In <i>Proc. 12th Computer Vision Winter Workshop (CVWW'07)</i>,
	  
      
	  February 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_115" style="display:none;">
    <div>
	  Jochen von Spiczak, Eigil Samset, Simon DiMaio, Gerhard
Reitmayr, Dieter Schmalstieg, Catherina Burghart, Ron Kikinis:
	</div><div>
	  <b>Multi-modal event streams for virtual reality</b>
	</div><div>
	  
	    In <i>Proc. 14th SPIE Annual Multimedia Computing and Networking Conference (MMCN'07)</i>,
	  
      
	  January 2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_128" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>Design Aspects of Handheld Augmented Reality Games</b>
	</div><div>
	  
	    In <i>Pervasive Games Vol. 2</i>,
	  
      
	   2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_129" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>The World as a User Interface: Augmented Reality for Ubiquitous Computing</b>
	</div><div>
	  
	    In <i>Lecture Notes in Geoinformation and Cartography</i>,
	  
      
	   2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_130" style="display:none;">
    <div>
	  Gerhard Schall, Erick Mendez, Sebastian Junghanns, Dieter
Schmalstieg:
	</div><div>
	  <b>Urban 3D Models: What's underneath? Handheld Augmented Reality for Subsurface Infrastructure Visualization</b>
	</div><div>
	  
	    In <i>9th International Conference on Ubiquitous Computing (UbiComp 2007)</i>,
	  
      
	   2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_130a" style="display:none;">
    <div>
	  Gerhard Schall, Bernhard Reitinger, Erick Mendez, Sebastian Junghanns, Dieter
Schmalstieg:
	</div><div>
	  <b>Handheld Geospatial Augmented Reality Using Urban 3D Models</b>
	</div><div>
	  
	    In <i>ACM CHI'07 Workshop on Mobile Spatial Interaction</i>,
	  
      
	   2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_131" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gerhard Reitmayr, Gerhard Schall, Joseph
Newman, Daniel Wagner, Florian Ledermann, Istvan Barakonyi:
	</div><div>
	  <b>Managing Complex Augmented Reality Models</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 27,
	    
	  
      
	   2007.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=N95bsDdNNM0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_105" style="display:none;">
    <div>
	  Michael Kalkusch, Dieter Schmalstieg:
	</div><div>
	  <b>Extending The Scene Graph With A Dataflow Visualization System</b>
	</div><div>
	  
	    In <i>Proceedings of Virtual Reality Software Technology (VRST'06)</i>,
	  
      
	  November 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_106" style="display:none;">
    <div>
	  Alexander Bornik, Reinhard Beichel, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Editing of Segmented Volumetric Datasets in a Hybrid 2D/3D Virtual Environment</b>
	</div><div>
	  
	    In <i>Proceedings of Virtual Reality Software Technology (VRST'06)</i>,
	  
      
	  November 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_107" style="display:none;">
    <div>
	  Ernst Kruijff, Dieter Schmalstieg, Steffi Beckhaus:
	</div><div>
	  <b>Using Neuromuscular Electrical Stimulation for Pseudo-Haptic Feedback</b>
	</div><div>
	  
	    In <i>Proceedings of Virtual Reality Software Technology (VRST'06)</i>,
	  
      
	  November 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_108" style="display:none;">
    <div>
	  Ernst Kruijff, Gerold Wesche, Kai Riege, Gernot Goebbels
and Martijn Kunstman, Dieter Schmalstieg:
	</div><div>
	  <b>Tactylus, a Pen-Input Device exploring Audiotactile Sensory Binding</b>
	</div><div>
	  
	    In <i>Proceedings of Virtual Reality Software Technology (VRST'06)</i>,
	  
      
	  November 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_102" style="display:none;">
    <div>
	  Istvan Barakonyi, Dieter Schmalstieg:
	</div><div>
	  <b>Ubiquitous Animated Agents for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 5th IEEE International Symposium for Mixed and Augmented Reality (ISMAR'06)</i>,
	  
      
	  October 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=w6A6VmCry4s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_103" style="display:none;">
    <div>
	  Erick Mendez, Denis Kalkofen, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Context-Driven Visualization Tools for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 5th IEEE International Symposium for Mixed and Augmented Reality (ISMAR'06)</i>,
	  
      
	  October 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=NxWvCmI_YBI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_104" style="display:none;">
    <div>
	  Joseph Newman, Gerhard Schall, Dieter Schmalstieg:
	</div><div>
	  <b>Modelling and Handling Seams in Wide-Area Sensor Networks</b>
	</div><div>
	  
	    In <i>Proceedings of the 10th IEEE International Symposium on Wearable Computers (ISWC'06)</i>,
	  
      
	  October 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_109" style="display:none;">
    <div>
	  Denis Kalkofen, Bernhard Reitinger, Petter Risholm, Alexander
Bornik, Reinhard Beichel, Dieter Schmalstieg, Eigil Samset:
	</div><div>
	  <b>Integrated Medical Workflow for Augmented Reality Applications</b>
	</div><div>
	  
	    In <i>Proceedings of MICCAI Workshop on Augmented Environments for Medical Imaging and Computer-Aided Surgery (AMI-ARCS'06)</i>,
	  
      
	  October 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_111" style="display:none;">
    <div>
	  Daniel Wagner, Mark Billinghurst, Dieter Schmalstieg:
	</div><div>
	  <b>How Real Should Virtual Characters Be?</b>
	</div><div>
	  
	    In <i>Conference on Advances in Computer Entertainment Technology 2006 (ACE 2006)</i>,
	  
      
	  June 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_095" style="display:none;">
    <div>
	  Hannes Kaufmann, Dieter Schmalstieg:
	</div><div>
	  <b>Designing Immersive Virtual Reality for Geometry Education</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality (VR'2006)</i>,
	  
      
	  March 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_096" style="display:none;">
    <div>
	  Bernhard Reitinger, Pascal Werlberger, Alexander Bornik and
Reinhard Beichel, Dieter Schmalstieg:
	</div><div>
	  <b>Spatial Analysis Tools for Medical Virtual Reality</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Symposium on 3D User Interfaces (3DUI 2006)</i>,
	  
      
	  March 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_097" style="display:none;">
    <div>
	  Alexander Bornik, Reinhard Beichel, Ernst Kruijff, Bernhard
Reitinger, Dieter Schmalstieg:
	</div><div>
	  <b>A Hybrid User Interface for Manipulation of Volumetric Medical Data</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Symposium on 3D User Interfaces (3DUI 2006)</i>,
	  
      
	  March 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_098" style="display:none;">
    <div>
	  Florian Ledermann, Istvan Barakonyi, Dieter Schmalstieg:
	</div><div>
	  <b>Abstraction and Implementation Strategies for Augmented Reality Authoring</b>
	</div><div>
	  
	    In <i>Emerging Technologies of Augmented Reality: Interfaces and Design</i>,
	  
      
	   2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_099" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>Augmented Reality as a Medium for Cartography</b>
	</div><div>
	  
	    In <i>Multimedia Cartography, 2nd ed.</i>,
	  
      
	   2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_100" style="display:none;">
    <div>
	  Joseph Newman, Istvan Barakonyi, Andreas Schuerzinger, Dieter
Schmalstieg:
	</div><div>
	  <b>Wide Area Tracking Tools for Augmented Reality</b>
	</div><div>
	  
	    In <i>Advances in Pervasive Computing</i>,
	  
      
	   2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_101" style="display:none;">
    <div>
	  Istvan Barakonyi, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality in the Character Animation Pipeline</b>
	</div><div>
	  
	    In <i>SIGGRAPH 2006 Sketches and Applications</i>,
	  
      
	   2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_110" style="display:none;">
    <div>
	  Bernhard Reitinger, Alexander Bornik, Reinhard Beichel and
Dieter Schmalstieg:
	</div><div>
	  <b>Liver Surgery Planning Using Virtual Reality</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 26,
	    
	  
      
	  November-December 2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=ndHDT5WRNDs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_112" style="display:none;">
    <div>
	  Bernhard Reitinger, Philipp Fuernstahl, Alexander Bornik and
Reinhard Beichel, Christopher Zach, Dieter Schmalstieg:
	</div><div>
	  <b>Global Mesh Partitioning for Surgical Planning</b>
	</div><div>
	  
	    In <i>Proceedings of the 3rd Central European Multimedia and Virtual Reality Conference</i>,
	  
      
	   2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_113" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg, Mark Billinghurst:
	</div><div>
	  <b>Handheld AR for Collaborative Edutainment</b>
	</div><div>
	  
	    In <i>Proceedings of 16th IEEE International Conference on Artificial Reality and Telexistence (Springer LNCS 4282</i>,
	  
      
	   2006.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_091" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>OpenTracker - A Flexible Software Design for Three-Dimensional Interaction</b>
	</div><div>
	  
	    <i>Virtual Reality</i>, 
	    vol. 9,
	    
	  
      
	  December 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_089" style="display:none;">
    <div>
	  Gerhard Schall, Friedrich Fraundorfer, Joseph Newman, Dieter
Schmalstieg:
	</div><div>
	  <b>Construction and Maintenance of Augmented Reality Environments Using a Mixture of Autonomous and Manual Surveying Techniques</b>
	</div><div>
	  
	    In <i>7th Conference on Optical 3-D Measurement Techniques</i>,
	  
      
	  October 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_093" style="display:none;">
    <div>
	  Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality Techniques in Games</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'05)</i>,
	  
      
	  October 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_094" style="display:none;">
    <div>
	  Berhard Reitinger, Pascal Werlberger, Alexander Bornik and
Reinhard Beichel, Dieter Schmalstieg:
	</div><div>
	  <b>Spatial Measurements for Medical Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th IEEE International Symposium on Mixed and Augmented Reality (ISMAR'05)</i>,
	  
      
	  October 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_092" style="display:none;">
    <div>
	  Istvan Barakonyi, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality Agents in the Development Pipeline of Computer Entertainment</b>
	</div><div>
	  
	    In <i>Proceedings 4th International Conference on Entertainment Computing</i>,
	  
      
	  September 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_085" style="display:none;">
    <div>
	  Istvan Barakonyi, Markus Weilguny, Thomas Psik, Dieter Schmalstieg:
	</div><div>
	  <b>MonkeyBridge: Autonomous Agents in Augmented Reality Games</b>
	</div><div>
	  
	    In <i>Proceedings of ACM SIGCHI International Conference on Advances in Computer Entertainment Technology (ACE 2005)</i>,
	  
      
	  June 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_086" style="display:none;">
    <div>
	  Dieter Schmalstieg, Daniel Wagner:
	</div><div>
	  <b>A Handheld Augmented Reality Museum Guide</b>
	</div><div>
	  
	    In <i>Proceedings of IADIS International Conference on Mobile Learning 2005 (ML 2005)</i>,
	  
      
	  June 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_090" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gerhard Reitmayr:
	</div><div>
	  <b>The World as a User Interface: Augmented Reality for Ubiquitous Computing</b>
	</div><div>
	  
	    In <i>Central European Multimedia and Virtual Reality Conference 2005 (CEMVRC 2005)</i>,
	  
      
	  June 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_083" style="display:none;">
    <div>
	  Thomas Pintaric, Daniel Wagner, Florian Ledermann, Dieter
Schmalstieg:
	</div><div>
	  <b>Towards Massively Multi-User Augmented Reality on Handheld Devices</b>
	</div><div>
	  
	    In <i>International Conference on Pervasive Computing (PERVASIVE 2005)</i>,
	  
      
	  May 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=O0CMtUImw-A" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_084" style="display:none;">
    <div>
	  Stephan Schmidt, Oliver Schoegl, Roland Kirchberger, Helmut
Doleisch, Philipp Muigg, Helwig Hauser, Markus Grabner and
Alexander Bornik, Dieter Schmalstieg:
	</div><div>
	  <b>Novel Visualization and Interaction Techniques for Gaining Insight into Fluid Dynamics in Internal Combustion Engines</b>
	</div><div>
	  
	    In <i>Proceedings of National Agency for Finite Element Methods and Standards World Congress Conference (NAFEMS)</i>,
	  
      
	  May 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_080" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Flexible Parameterization of Scene Graphs</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2005</i>,
	  
      
	  March 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_081" style="display:none;">
    <div>
	  Florian Ledermann, Dieter Schmalstieg:
	</div><div>
	  <b>APRIL - A High Level Framework for Creating Augmented Reality Presentations</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2005</i>,
	  
      
	  March 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_087" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Semantic World Models for Ubiquitous Augmented Reality</b>
	</div><div>
	  
	    In <i>Semantic Virtual Environments (SVE 2005)</i>,
	  
      
	  March 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_088" style="display:none;">
    <div>
	  Joseph Newman, Gerhard Schall, Dieter Schmalstieg:
	</div><div>
	  <b>Rapid and Accurate Deployment of Fiducial Markers for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of 10th Computer Vision Winter Workshop (CVWW 2005)</i>,
	  
      
	  February 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_082" style="display:none;">
    <div>
	  Raphael Grasset, Jean-Dominique Gascuel, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Mediated Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the Australasian User Interface Conference (AUIC'05)</i>,
	  
      
	  January 2005.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_078" style="display:none;">
    <div>
	  Istvan Barakonyi, Thomas Psik, Dieter Schmalstieg:
	</div><div>
	  <b>Agents That Talk And Hit Back: Animated Agents in Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 3rd International Symposium on Mixed and Augmented Reality (ISMAR'04)</i>,
	  
      
	  October 2004.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=TYpilv5GAmc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_079" style="display:none;">
    <div>
	  Joseph Newman, Martin Wagner, Martin Bauer, Asa MacWilliams
and Thomas Pintaric, Dagmar Beyer, Daniel Pustka, Franz
Strasser, Dieter Schmalstieg, Gudrun Klinker:
	</div><div>
	  <b>Ubiquitous Tracking for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 3rd International Symposium on Mixed and Augmented Reality (ISMAR'04)</i>,
	  
      
	  October 2004.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=rOWz8IESejQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_075" style="display:none;">
    <div>
	  Istvan Barakonyi, Tamer Fahmy, Dieter Schmalstieg:
	</div><div>
	  <b>Remote Collaboration Using Augmented Reality Videoconferencing</b>
	</div><div>
	  
	    In <i>Proceedings of Graphics Interface</i>,
	  
      
	  May 2004.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_076" style="display:none;">
    <div>
	  Istvan Barakonyi, Dieter Schmalstieg:
	</div><div>
	  <b>AR Puppet: Animated Agents in Augmented Reality</b>
	</div><div>
	  
	    In <i>First Central European International Multimedia and Virtual Reality Conference</i>,
	  
      
	  May 2004.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_077" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gottfried Eibner:
	</div><div>
	  <b>Hybrid User Interfaces Using Seamless Tiled Displays</b>
	</div><div>
	  
	    In <i>Proceedings of 8th Immersive Projection Technology Workshop (IPT 2004)</i>,
	  
      
	  May 2004.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_073" style="display:none;">
    <div>
	  Joseph Newman, Martin Wagner, Thomas Pintaric, Asa MacWilliams
and Martin Bauer, Gudrun Klinker, Dieter Schmalstieg:
	</div><div>
	  <b>Fundamentals of Ubiquitous Tracking for Augmented Reality</b>
	</div><div>
	  
	    In <i>Advances in Pervasive Computing</i>,
	  
      
	   2004.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_068" style="display:none;">
    <div>
	  Stephan Bruckner, Dieter Schmalstieg, Helwig Hauser, M.
Eduard Groeller:
	</div><div>
	  <b>The Inverse Warp: Non-Invasive Integration of Shear-Warp Volume Rendering into Polygon Rendering Pipelines</b>
	</div><div>
	  
	    In <i>Proceedings of 8th International Fall Workshop on Vision, Modeling and Visualization (VMV 2003)</i>,
	  
      
	  November 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_071" style="display:none;">
    <div>
	  Florian Ledermann, Dieter Schmalstieg:
	</div><div>
	  <b>Presenting Past and Present of an Archaeological Site in the Virtual Showcase</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th International Symposium on Virtual Reality, Archeology, and Intelligent Cultural Heritage (VAST 2003)</i>,
	  
      
	  November 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_066" style="display:none;">
    <div>
	  Raphael Grasset, Jean-Dominique Gascuel, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Mediated Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 2nd IEEE Symposium on Mixed and Augmented Reality (ISMAR 2003)</i>,
	  
      
	  October 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_067" style="display:none;">
    <div>
	  Daniel Wagner, Dieter Schmalstieg:
	</div><div>
	  <b>First Steps Towards Handheld Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 7th International Conference on Wearable Computers</i>,
	  
      
	  October 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/I_XpAo1yMnw" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_069" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Data Management Strategies for Mobile Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the International Workshop on Software Technology for Augmented Reality Systems (STARS 2003)</i>,
	  
      
	  October 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_070" style="display:none;">
    <div>
	  M. Bauer, Otmar Hilinges, Asa MacWilliams, Christian Sandor
and Martin Wagner, Gudrun Klinker, Joseph Newman, Gerhard
Reitmayr, Tamer Fahmy, Thomas Pintaric, Dieter Schmalstieg:
	</div><div>
	  <b>Integrating Studierstube and DWARF</b>
	</div><div>
	  
	    In <i>Proceedings of the International Workshop on Software Technology for Augmented Reality Systems (STARS 2003)</i>,
	  
      
	  October 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_065" style="display:none;">
    <div>
	  Christiane Ulbricht, Dieter Schmalstieg:
	</div><div>
	  <b>Tangible Augmented Reality for Computer Games</b>
	</div><div>
	  
	    In <i>The 3rd IASTED International Conference on Visualization, Imaging, and Image Processing (VIIP 2003)</i>,
	  
      
	  September 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_074" style="display:none;">
    <div>
	  Istvan Barakonyi, Werner Frieb, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality Videoconferencing for Collaborative Work</b>
	</div><div>
	  
	    In <i>Proceedings of the 2nd Hungarian Conference on Computer Graphics and Geometry</i>,
	  
      
	  May 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_063" style="display:none;">
    <div>
	  Erik Pojar, Dieter Schmalstieg:
	</div><div>
	  <b>User Controlled Creation of Multiresolution Meshes</b>
	</div><div>
	  
	    In <i>Proceedings of ACM SIGGRAPH 2003 Symposium on Interactive 3D Graphics</i>,
	  
      
	  April 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_062" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Location Based Applications for Mobile Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th Australasian User Interface Conference</i>,
	  
      
	  February 2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=iAB11Koq47M" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_055" style="display:none;">
    <div>
	  Oliver Bimber, Bernd Froehlich, Dieter Schmalstieg, L. Miguel
Encarnacao:
	</div><div>
	  <b>Real-time view-dependent image warping to correct non-linear distortion for curved virtual showcase displays</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 27,
	    
	  
      
	   2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_056" style="display:none;">
    <div>
	  Hannes Kaufmann, Dieter Schmalstieg:
	</div><div>
	  <b>Mathematics And Geometry Education With Collaborative Augmented Reality</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 27,
	    
	  
      
	   2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=FX0WDIhT6DI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_061" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gerhard Reitmayr, Gerd Hesina:
	</div><div>
	  <b>Distributed Applications for Collaborative Three-Dimensional Workspaces</b>
	</div><div>
	  
	    <i>PRESENCE - Teleoperators and Virtual Environments</i>, 
	    vol. 12,
	    
	  
      
	   2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/EjR-1tyelRE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_072" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Collaborative Augmented Reality for Outdoor Navigation and Information Browsing</b>
	</div><div>
	  
	    In <i>Geowissenschaftliche Mitteilungen</i>,
	  
      
	   2003.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_064" style="display:none;">
    <div>
	  Stan Stoev, Dieter Schmalstieg:
	</div><div>
	  <b>Application and Taxonomy of Through-The-Lens Techniques</b>
	</div><div>
	  
	    In <i>Proceedings of the ACM Symposium on Virtual Reality Software and Technology (VRST'02)</i>,
	  
      
	  November 2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_059" style="display:none;">
    <div>
	  Florian Ledermann, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Dynamically Shared Optical Tracking</b>
	</div><div>
	  
	    In <i>Proceedings of the IEEE First International Workshop on ARToolKit</i>,
	  
      
	  September 2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_060" style="display:none;">
    <div>
	  Michael Kalkusch, Thomas Lidy, Michael Knapp, Gerhard Reitmayr
and Hannes Kaufmann, Dieter Schmalstieg:
	</div><div>
	  <b>Structured Visual Markers for Indoor Pathfinding</b>
	</div><div>
	  
	    In <i>Proceedings of the IEEE First International Workshop on ARToolKit</i>,
	  
      
	  September 2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_053" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gerd Hesina:
	</div><div>
	  <b>Distributed Applications for Collaborative Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2002</i>,
	  
      
	  March 2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=LW1F8vqgq9k" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_054" style="display:none;">
    <div>
	  Stan Stoev, Dieter Schmalstieg, Wolfgang Strasser:
	</div><div>
	  <b>The Through-The-Lens Metaphor: Taxonomy and Application</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2002</i>,
	  
      
	  March 2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_045" style="display:none;">
    <div>
	  Dieter Schmalstieg, Anton Fuhrmann, Gerd Hesina, Zsolt Szalavari
and L. Miguel Encarnacao, Michael Gervautz, Werner Purgathofer:
	</div><div>
	  <b>The Studierstube Augmented Reality Project</b>
	</div><div>
	  
	    <i>PRESENCE - Teleoperators and Virtual Environments</i>, 
	    vol. 11,
	    
	  
      
	   2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper describes Studierstube, an augmented reality system developed over the past four years at Vienna University of Technology, Austria, in extensive collaboration with Fraunhofer CRCG, Inc. in Providence, Rhode Island, U.S. Our starting point for developing the Studierstube system was the belief that augmented reality, the less obtrusive cousin of virtual reality, has a better chance of becoming a viable user interface for applications requiring manipulation of complex three-dimensional information as a daily routine. In essence, we are searching for a 3D user interface metaphor as powerful as the desktop metaphor for 2D. At the heart of the Studierstube system, collaborative augmented reality is used to embed computer-generated images into the real work environment. In the first part of this paper, we review the user interface of the initial Studierstube system, in particular the implementation of collaborative augmented reality, and the Personal Interaction Panel, a two-handed interface for interaction with the system. In the second part, an extended Studierstube system based on a heterogeneous distributed architecture is presented. This system allows the user to combine multiple approaches - augmented reality, projection displays, ubiquitous computing - to the interface as needed. The environment is controlled by the Personal Interaction Panel, a two-handed pen-and-pad interface, which has versatile uses for interacting with the virtual environment. Studierstube also borrows elements from the desktop, such as multi-tasking and multi-windowing. The resulting software architecture resembles in some ways what could be called an augmented reality operating system. The presentation is complemented by selected application examples.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_057" style="display:none;">
    <div>
	  Eike Umlauf, Harald Piringer, Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>ARLib: The Augmented Library</b>
	</div><div>
	  
	    In <i>Proceedings of the IEEE First International Workshop on ARToolKit</i>,
	  
      
	   2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_058" style="display:none;">
    <div>
	  Stephan Veigl, Andreas Kaltenbach, Florian Ledermann, Gerhard
Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Two-Handed Direct Interaction with ARToolKit</b>
	</div><div>
	  
	    In <i>Proceedings of the IEEE First International Workshop on ARToolKit</i>,
	  
      
	   2002.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_049" style="display:none;">
    <div>
	  Oliver Bimber, Bernd Froehlich, Dieter Schmalstieg, L. Miguel
Encarnacao:
	</div><div>
	  <b>Virtual Showcases</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 21,
	    
	  
      
	  November 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present the Virtual Showcase, a new multiviewer augmented reality display device thathas the same form factor as a real showcase traditionally used for museum exhibits.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/70_j-ajZNw0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_052" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>An Open Software Architecture for Virtual Reality Interaction</b>
	</div><div>
	  
	    In <i>ACM Symposium on Virtual Reality Software and Technology 2001 (VRST 2001)</i>,
	  
      
	  November 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This article describes OpenTracker, an open software architecture that provides a framework for the different tasks involved in tracking input devices and processing multi-modal input data in virtual environments and augmented reality application. The OpenTracker framework eases the development and maintenance of hardware setups in a more flexible manner than what is typically offered by virtual reality development packages. This goal is achieved by using an object-oriented design based on XML, taking full advantage of this new technology by allowing to use standard XML tools for development, configuration and documentation. The OpenTracker engine is based on a data flow concept for multi-modal events. A multi-threaded execution model takes care of tunable performance. Transparent network access allows easy development of decoupled simulation models. Finally, the application developer's interface features both a time-based and an event based model, that can be used simultaneously, to serve a large range of applications. OpenTracker is a first attempt towards a write once, input anywhere approach to virtual reality application development. To support these claims, integration into an existing augmented reality system is demonstrated. We also show how a prototype tracking equipment for mobile augmented reality can be assembled from consumer input devices with the aid of OpenTracker. Once development is sufficiently mature, it is planned to make OpenTracker available to the public under an open source software license.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_048" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>A Wearable 3D Augmented Reality Workspace</b>
	</div><div>
	  
	    In <i>Proceedings of 5th International Symposium on Wearable Computers (ISCW 2001)</i>,
	  
      
	  October 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_050" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>Mobile Collaborative Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 2nd IEEE International Symposium on Augmented Reality (ISAR'01)</i>,
	  
      
	  October 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The combination of mobile computing and collaborative Augmented Reality into a single system makes the power of computer enhanced interaction and communication in the real world accessible anytime and everywhere. This paper describes our work to build a mobile collaborative Augmented Reality system that supports true stereoscopic 3D graphics, a pen and pad interface and direct interaction with virtual objects. The system is assembled from off-the-shelf hardware components and serves as a basic testbed for user interface experiments related to computer supported collaborative work in Augmented Reality. A mobile platform implementing the described features and collaboration between mobile and stationary users are demonstrated.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_051" style="display:none;">
    <div>
	  Klaus Dorfmueller-Ulhaas, Dieter Schmalstieg:
	</div><div>
	  <b>Finger Tracking for Interaction in Augmented Environments</b>
	</div><div>
	  
	    In <i>Proceedings of the 2nd IEEE International Symposium on Augmented Reality (ISAR'01)</i>,
	  
      
	  October 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Optical tracking systems allow three-dimensional input for virtual environment applications with high precision and without annoying cables. Spontaneous and intuitive interaction is possible through gestures. In this paper, we present a finger tracker that allows gestural interaction and is simple, cheap, fast, robust against occlusion and accurate. It is based on a marked glove, a stereoscopic tracking system and a kinematic 3-d model of the human finger. Within our augmented reality application scenario, the user is able to grab, translate, rotate, and release objects in an intuitive way. We demonstrate our tracking system in an augmented reality chess game allowing a user to interact with virtual objects.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=WKXDKjeoJTI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_046" style="display:none;">
    <div>
	  Oliver Bimber, Bernd Froehlich, Dieter Schmalstieg, L. Miguel
Encarnacao:
	</div><div>
	  <b>Virtual Showcases</b>
	</div><div>
	  
	    In <i>SIGGRAPH 2001 Sketches and Applications</i>,
	  
      
	  August 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_047" style="display:none;">
    <div>
	  Stan Stoev, Dieter Schmalstieg, Wolfgang Strasser:
	</div><div>
	  <b>Manipulate the Unreachable: Through-the-lens Remote Object Manipulation in Virtual Environments</b>
	</div><div>
	  
	    In <i>SIGGRAPH 2001 Sketches and Applications</i>,
	  
      
	  August 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_044" style="display:none;">
    <div>
	  Stan Stoev, Dieter Schmalstieg, Wolfgang Strasser:
	</div><div>
	  <b>Through-The-Lens Techniques for Remote Object Manipulation, Motion, and Navigation in Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of the Joint Immersive Projection Technology / EUROGRAPHICS Workshop on Virtual Environments (IPT/EGVE 2001)</i>,
	  
      
	  May 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_043" style="display:none;">
    <div>
	  Gerhard Reitmayr, Dieter Schmalstieg:
	</div><div>
	  <b>OpenTracker - An Open Software Architecture for Reconfigurable Tracking based on XML</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2001</i>,
	  
      
	  March 2001.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_041" style="display:none;">
    <div>
	  L. Miguel Encarnacao, Oliver Bimber, Dieter Schmalstieg and
Robert Barton III:
	</div><div>
	  <b>Walk-up VR: Virtual Reality beyond Projection Screens</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 20,
	    
	  
      
	  November 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_042" style="display:none;">
    <div>
	  Christian Faisstnauer, Dieter Schmalstieg, Werner Purgathofer:
	</div><div>
	  <b>Priority Scheduling for Networked Virtual Environments</b>
	</div><div>
	  
	    <i>IEEE Computer Graphics and Applications</i>, 
	    vol. 20,
	    
	  
      
	  November 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The problem of resource bottlenecks is encountered in almost any distributed virtual environment or networked game. In a typical client-server setup, where the virtual world is managed by a server and replicated by connected clients which visualize the scene, the server must repeatedly transmit update messages to the clients. The computational power needed to select the messages to transmit to each client, or the network bandwidth limitations often allow only a subset of the update messages to be transmitted to the clients; this leads to a performance degradation and an accumulation of errors, e.g., a visual error based on the positional displacement of moving objects. This paper presents a scheduling algorithm that enforces priorities based on a freely definable error metric, trying to minimize the overall error. It is able to achieve a graceful degradation of the system's performance and to minimize the risc of starvation, while retaining an output sensitive behavior. This makes it suitable not only to schedule the update messages to transmit to the various clients, but it also allows to employ filtering techniques at a constant effort.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_039" style="display:none;">
    <div>
	  Dieter Schmalstieg, Anton Fuhrmann, Gerd Hesina:
	</div><div>
	  <b>Bridging Multiple User Interface Dimensions with Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 3rd International Symposium on Augmented Reality (ISAR'00)</i>,
	  
      
	  October 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Studierstube is an experimental user interface system,which uses collaborative augmented reality to incorporate true 3D interaction into a productivity environment. This concept is extended to bridge multiple user interface dimensions by including multiple users, multiple host platforms, multiple display types, multiple concurrent applications, and a multi-context (i. e., 3D document) interface into a heterogeneous distributed environment. With this architecture, we can explore the user interface design space between pure augmented reality and the popular ubiquitous computing paradigm. We report on our design philosophy centered around the notion of contexts and locales, as well as the underlying software and hardware architecture. Contexts encapsulate a live application together with 3D (visual) and other data, while locales are used to organize geometric reference systems. By separating geometric relationships (locales) from semantic relationships (contexts), we achieve a great amount of flexibility in the configuration of displays. To illustrate our claims, we present several applications including a cinematographic design tool which showcases many features of our system.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=XAWQAdf2CbY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_035" style="display:none;">
    <div>
	  Oliver Bimber, L. Miguel Encarnacao, Dieter Schmalstieg:
	</div><div>
	  <b>Augmented Reality with Back-Projection Systems using Transflective Surfaces</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 19,
	    
	  
      
	  August 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_038" style="display:none;">
    <div>
	  Christian Faisstnauer, Dieter Schmalstieg, Werner Purgathofer:
	</div><div>
	  <b>Scheduling for Very Large Virtual Environments and Networked Games Using Visibility and Priorities</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th IEEE International Workshop on Distributed Simulation and Real Time Applications (DS-RT'00)</i>,
	  
      
	  August 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_034" style="display:none;">
    <div>
	  Anton Fuhrmann, Dieter Schmalstieg, Werner Purgathofer:
	</div><div>
	  <b>Practical Calibration Procedures for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of the 6th EUROGRAPHICS Workshop on Virtual Environments (EGVE'00)</i>,
	  
      
	  June 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Augmented Reality overlays computer generated images over the real world. This requires precise knowledge of the viewing projection of the head-mounted display (HMD) and its position. Most of the previously published methods are complicated or use special equipment for the calibration process. We present a collection of calibration methods usable for fast and easy calibration of camera parameters, object/camera to tracker transformations, and image rectification, which do not need additional instrumentation or complicated procedures. They are applicable for both see-through and video-based HMDs.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://youtu.be/XjPkMnz2tc4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_036" style="display:none;">
    <div>
	  Werner Wohlfahrter, L. Miguel Encarnacao, Dieter Schmalstieg:
	</div><div>
	  <b>Interactive Volume Exploration on the StudyDesk</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th International Projection Technology Workshop</i>,
	  
      
	  June 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_037" style="display:none;">
    <div>
	  Peter Wonka, Michael Wimmer, Dieter Schmalstieg:
	</div><div>
	  <b>Visibility Preprocessing with Occluder Fusion for Urban Walkthroughs</b>
	</div><div>
	  
	    In <i>Proceedings of the 11th EUROGRAPHICS Workshop on Rendering (EGRWS'00)</i>,
	  
      
	  June 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper presents an algorithm for occlusion culling from regions of space. It is conservative and able to find all significant occlusion. It discretizes the scene into view cells, for which cell-to-object visibility is precomputed, making on-line overhead negligible. Unlike other precomputation methods for view cells, it is able to conservatively compute all forms of occluder interaction for an arbitrary number of occluders. We describe an application of this algorithm to urban environments. A walkthrough system running an 8 million polygon model of the city of Vienna on consumer-level hardware illustrates our results.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_032" style="display:none;">
    <div>
	  Christian Faisstnauer, Dieter Schmalstieg, Werner Purgathofer:
	</div><div>
	  <b>Priority Round Robin Scheduling for Very Large Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2000</i>,
	  
      
	  March 2000, Honorably mention in the best paper competition..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_033" style="display:none;">
    <div>
	  Oliver Bimber, L. Miguel Encarnacao, Dieter Schmalstieg:
	</div><div>
	  <b>Real Mirrors Reflecting Virtual Worlds</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality 2000</i>,
	  
      
	  March 2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_040" style="display:none;">
    <div>
	  Hannes Kaufmann, Dieter Schmalstieg, Michael Wagner:
	</div><div>
	  <b>Construct3D: A Virtual Reality Application for Mathematics and Geometry Education</b>
	</div><div>
	  
	    <i>Journal of Education and Information Technologies</i>, 
	    vol. 5,
	    
	  
      
	   2000.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Construct3D is a three dimensional geometric construction tool based on the collaborative augmented reality system Studierstube. Our setup uses a stereoscopic head mounted display (HMD) and the Personal Interaction Panel(PIP) - a two-handed 3D interaction tool that simplifies 3D model interaction. Means of application in mathematics and geometry education at high school aswell as university level are being discussed. A pilot study summarizes the strengths and possible extensions of our system. Anecdotal evidence supports our claim that the use of Construct3D is easy to learn and encourages experimentation with geometric constructions.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=ce9tGgRZuHA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_029" style="display:none;">
    <div>
	  Gerd Hesina, Dieter Schmalstieg, Anton Fuhrmann, Werner
Purgathofer:
	</div><div>
	  <b>Distributed Open Inventor: A Practical Approach to Distributed 3D Graphics</b>
	</div><div>
	  
	    In <i>Proceedings of ACM Symposium on Virtual Reality Software and Technology (VRST'99)</i>,
	  
      
	  December 1999.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">Distributed Open Inventor is an extension to the popular Open Inventor toolkit for interactive 3D graphics. The toolkit is extended with the concept of a distributed shared scene graph, similar to distributed shared memory. From the application programmer's perspective, multiple workstations share a common scene graph. The proposed system introduces a convenient mechanism for writing distributed graphical applications based on a popular tool in an almost transparent manner. Local variations in the scene graph allow for a wide range of possible applications, and local low latency interaction mechanisms called input streams together with a sophisticated networking architecture enable high performance while saving the programmer from network peculiarities.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_030" style="display:none;">
    <div>
	  Anton Fuhrmann, Dieter Schmalstieg, Werner Purgathofer:
	</div><div>
	  <b>Fast Calibration for Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of ACM Symposium on Virtual Reality Software and Technology'99 (VRST'99)</i>,
	  
      
	  December 1999.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_027" style="display:none;">
    <div>
	  Peter Wonka, Dieter Schmalstieg:
	</div><div>
	  <b>Occluder Shadows for Fast Walkthroughs of Urban Environments</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 18,
	    
	  
      
	  September 1999.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper describes a new algorithm that employs image-based rendering for fast occlusion culling in complex urban environments. It exploits graphics hardware to render and automatically combine a relatively large set of occluders. The algorithm is fast to calculate and therefore also useful for scenes of moderate complexity and walkthroughs with over 20 frames per second. Occlusion is calculated dynamically and does not rely on any visibility precalculation or occluder preselection. Speed-ups of one order of magnitude can be obtained.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_028" style="display:none;">
    <div>
	  L. Miguel Encarnacao, Oliver Bimber, Dieter Schmalstieg and
Sean Chandler:
	</div><div>
	  <b>A Translucent Sketchpad for the Virtual Table Exploring Motion-based Gesture Recognition</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 18,
	    
	  
      
	  September 1999.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_024" style="display:none;">
    <div>
	  Dieter Schmalstieg, L. Miguel Encarnacao, Zsolt Szalavari:
	</div><div>
	  <b>Using Transparent Props For Interaction With The Virtual Table</b>
	</div><div>
	  
	    In <i>Proceedings of SIGGRAPH Symposium on Interactive 3D Graphics (I3D'99)</i>,
	  
      
	  April 1999, Best paper award 1999 (2nd rank) in the competition of Fraunhofer Haus der Graphischen Datenverarbeitung, Darmstadt, Germany..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The Virtual Table presents stereoscopic graphics to a user in a workbench-like setting. This paper reports on a user interface and new interaction techniques for the Virtual Table based on transparent props - a tracked hand-held pen and a pad. These props, but in particular the pad, are augmented with 3D graphics from the Virtual Table's display. This configuration creates a very powerful and flexible interface for two-handed interaction that can be applied to other back-projected stereographic displays as well: The pad can serve as a palette for tools and controls as well as a window-like see-through interface, a plane-shaped and through-the-plane tool, supporting a variety of new interaction techniques.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=GiFwNxsaNwA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_025" style="display:none;">
    <div>
	  Michael Wimmer, Markus Giegl, Dieter Schmalstieg:
	</div><div>
	  <b>Fast Walkthroughs with Image Caches and Ray Casting</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 23,
	    
	  
      
	   1999.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_026" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gernot Schaufler:
	</div><div>
	  <b>Sewing Virtual Worlds Together With SEAMS: A Mechanism to Construct Complex Virtual Environments</b>
	</div><div>
	  
	    <i>PRESENCE - Teleoperators and Virtual Environments</i>, 
	    vol. 8,
	    
	  
      
	   1999.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">This paper introduces the Spatially Extended Anchoring Mechanism (SEAM) as a 3-D user-interface metaphor to connect virtual worlds and manage scalability in distributed virtual environments. SEAMs provide a visual and navigable connection between worlds to manage both the complexity of rendering and network communication typically occurring in such environments. In the context of augmented reality, SEAMs can be applied as a 3-D window interface. A rendering algorithm is described which performs well on the graphics accelerators of standard personal computers.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_031" style="display:none;">
    <div>
	  Dieter Schmalstieg, Robert F. Tobler:
	</div><div>
	  <b>Fast Projected Area Computation for 3D Bounding Boxes</b>
	</div><div>
	  
	    <i>Journal of Graphics Tools</i>, 
	    vol. 4,
	    
	  
      
	   1999, Republished in: Graphics Tools, pp.23-30, A. K. Peters Ltd., 2005..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">The area covered by a three-dimensional bounding box after projection onto the screen is relevant for view-dependent algorithms in real-time and photorealistic rendering. We describe a fast method to compute the accurate two-dimensional area of a three-dimensional oriented bounding box, and show how it can be computed equally fast or faster than its approximation with a two-dimensional bounding box enclosing the projected three-dimensional bounding box.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_023" style="display:none;">
    <div>
	  Christian Faisstnauer, Dieter Schmalstieg, Zsolt Szalavari:
	</div><div>
	  <b>Device-Independent Navigation and Interaction in Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of the VRST'98 Adjunct Workshop on Computer Graphics</i>,
	  
      
	  November 1998.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_021" style="display:none;">
    <div>
	  Stephan Mantler, Dieter Schmalstieg:
	</div><div>
	  <b>Dynamic Load Balancing in Distributed Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of EUROGRAPHICS'98 Short Papers</i>,
	  
      
	  August 1998.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_020" style="display:none;">
    <div>
	  Gerd Hesina, Dieter Schmalstieg:
	</div><div>
	  <b>A Network Architecture for Remote Rendering</b>
	</div><div>
	  
	    In <i>Proceedings of 2nd International Workshop on Distributed Interactive Simulation and Real Time Applications (DIS-RT'98)</i>,
	  
      
	  July 1998.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_019" style="display:none;">
    <div>
	  Anton Fuhrmann, Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>Strolling through Cyberspace with Your Hands in Your Pockets: Head Directed Navigation in Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of the EUROGRAPHICS Workshop on Virtual Environments (EGVE'98)</i>,
	  
      
	  June 1998.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_017" style="display:none;">
    <div>
	  Zsolt Szalavari, Dieter Schmalstieg, Anton Fuhrmann, Michael
Gervautz:
	</div><div>
	  <b>Studierstube - An Environment for Collaboration in Augmented Reality</b>
	</div><div>
	  
	    <i>Virtual Reality</i>, 
	    vol. 3,
	    
	  
      
	   1998.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We propose an architecture for multi-user augmented reality with applications in visualization, presentation and education, which we call Studierstube. Our system presents three-dimensional stereoscopic graphics simultaneously to group of users wearing light weight see-through head mounted displays. The displays do not affect natural communication and interaction, making working together very effective. Users see the same spatially aligned model, but can independently control their viewpoint and different layers of the data to be displayed. The setup serves computer supported cooperative work and enhances cooperation of visualization experts. This paper presents the client-server software architecture underlying this system and details that must be addressed to create a high-quality augmented reality setup.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_018" style="display:none;">
    <div>
	  Anton Fuhrmann, Helwig Loeffelmann, Dieter Schmalstieg and
Michael Gervautz:
	</div><div>
	  <b>Collaborative Visualization in Augmented Reality</b>
	</div><div>
	  
	    <i>Computer Graphics and Applications</i>, 
	    vol. 18,
	    
	  
      
	   1998.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">-</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_015" style="display:none;">
    <div>
	  Anton Fuhrmann, Helwig Loeffelmann, Dieter Schmalstieg:
	</div><div>
	  <b>Collaborative Augmented Reality: Exploring Dynamical Systems</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Visualization'97</i>,
	  
      
	  October 1997.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">In this paper we present collaborative scientific visualization in STUDIERSTUBE. STUDIERSTUBE is an augmented reality system that has several advantages over conventional desktop and other virtual reality environments, including true stereoscopy, 3D-interaction, individual viewpoints and customized views for multiple users, unhindered natural collaboration and low cost. We demonstrate the application of this concept for the interaction of multiple users and illustrate it with several visualizations of dynamical systemsin DynSys3D, a visualization system running on top of AVS.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
      <div>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/https://www.youtube.com/watch?v=JNedvrPeiqI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="">
        </iframe>
	  </div>
    
  </div>

<div id="Schmalstieg_016" style="display:none;">
    <div>
	  Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>Modeling and Rendering of Outdoor Scenes for Distributed Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of ACM Symposium on Virtual Reality Software and Technology 1997 (VRST'97)</i>,
	  
      
	  September 1997.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_012" style="display:none;">
    <div>
	  Dieter Schmalstieg, Robert F. Tobler:
	</div><div>
	  <b>Exploiting Coherence in 2.5-D Visibility Computation</b>
	</div><div>
	  
	    <i>Computers and Graphics</i>, 
	    vol. 21,
	    
	  
      
	  April 1997.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_013" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gernot Schaufler:
	</div><div>
	  <b>Smooth Levels of Detail</b>
	</div><div>
	  
	    In <i>Proceedings of IEEE Virtual Reality Annual International Symposium (VRAIS'97)</i>,
	  
      
	  March 1997.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_014" style="display:none;">
    <div>
	  Dieter Schmalstieg:
	</div><div>
	  <b>An Octree-Based Level of Detail Generator for VRML</b>
	</div><div>
	  
	    In <i>Proceedings of the ACM SIGGRAPH 2nd Symposium on VRML (VRML'97)</i>,
	  
      
	  February 1997.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_011" style="display:none;">
    <div>
	  Dieter Schmalstieg, Gernot Schaufler:
	</div><div>
	  <b>Incremental Encoding of Polygonal Models</b>
	</div><div>
	  
	    In <i>Proceedings of the 30th Hawaii International Conference on System Sciences (HICSS-30)</i>,
	  
      
	  January 1997.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_004" style="display:none;">
    <div>
	  Dieter Schmalstieg, Anton Fuhrmann, Zsolt Szalavari, Michael Gervautz:
	</div><div>
	  <b>Studierstube - An Environment for Collaboration in Augmented Reality</b>
	</div><div>
	  
	    In <i>Proceedings of Collaborative Virtual Environments (CVE'96)</i>,
	  
      
	  September 1996.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We propose an architecture for multi-user augmented reality, with applications in visualization, presentation, and education.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_008" style="display:none;">
    <div>
	  Gernot Schaufler, Thomasz Mazuryk, Dieter Schmalstieg:
	</div><div>
	  <b>High Fidelity for Immersive Displays</b>
	</div><div>
	  
	    In <i>ACM CHI'96 Conference Companion</i>,
	  
      
	  April 1996.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_006" style="display:none;">
    <div>
	  Dieter Schmalstieg, Christian Faisstnauer, Thomasz Mazuryk:
	</div><div>
	  <b>Constructing a Highly Immersive Virtual Environment: A Case Study</b>
	</div><div>
	  
	    In <i>Proceedings of the 4th International Conference in Central Europe on Computer Graphics and Visualization</i>,
	  
      
	  February 1996.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_007" style="display:none;">
    <div>
	  Dieter Schmalstieg, Michael Gervautz, Peter Stieglecker:
	</div><div>
	  <b>Optimizing Communication in Distributed Virtual Environments by Specialized Protocols</b>
	</div><div>
	  
	    In <i>Virtual Environments and Scientific Visualization'96</i>,
	  
      
	  February 1996.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_005" style="display:none;">
    <div>
	  Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>Implementing Gibsonian Virtual Environments</b>
	</div><div>
	  
	    <i>Cybernetics and Systems</i>, 
	    vol. 27,
	    
	  
      
	   1996, Best paper award at the 13th European Meeting on Cybernetics and Systems Research (Vienna, April 1996)..
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_009" style="display:none;">
    <div>
	  Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>Demand-Driven Geometry Transmission for Distributed Virtual Environments</b>
	</div><div>
	  
	    <i>Computer Graphics Forum</i>, 
	    vol. 15,
	    
	  
      
	   1996.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract">We present a strategy for rendering in distributed virtual environments. A geometry database is maintainedby a server, while users invoke individual clients to interact with the environment. Instead of downloading acomplete copy of the geometry data, the data is distributed on demand, thus gaining significant savings innetwork bandwidth. Our strategy combines several techniques, including levels of detail, progressiverefinement and graceful degradation to deliver the data just in time over the network to the renderingprocess. The method allows operate on a tight resource budget, which important if attempting to use lowcost systems for virtual reality applications.</div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_010" style="display:none;">
    <div>
	  Thomasz Mazuryk, Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>Zoom Rendering: Improving 3-D Rendering Performance With 2-D Operations</b>
	</div><div>
	  
	    <i>The International Journal of Virtual Reality</i>, 
	    vol. 2,
	    
	  
      
	   1996.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_003" style="display:none;">
    <div>
	  Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>Towards a Virtual Environment for Interactive World Building</b>
	</div><div>
	  
	    In <i>Proceedings of the GI 4.1.1 Workshop on Modeling, Virtual Worlds, Distributed Graphics</i>,
	  
      
	  November 1995.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_004a" style="display:none;">
    <div>
	  Michael Gervautz, Dieter Schmalstieg:
	</div><div>
	  <b>Computer Animation and Visualization - Current Status and Trends</b>
	</div><div>
	  
	    In <i>Proceedings of EUROSIM'95</i>,
	  
      
	  July 1995.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_002" style="display:none;">
    <div>
	  Dieter Schmalstieg, Michael Gervautz:
	</div><div>
	  <b>On System Architectures for Virtual Environments</b>
	</div><div>
	  
	    In <i>Proceedings of the 11th Spring Conference on Computer Graphics</i>,
	  
      
	  May 1995.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<div id="Schmalstieg_001" style="display:none;">
    <div>
	  Michael Gervautz, Dieter Schmalstieg:
	</div><div>
	  <b>Integrating a Scripting Language into an Interactive Animation System</b>
	</div><div>
	  
	    In <i>Proceedings of Computer Animation'94</i>,
	  
      
	  May 1994.
    </div><div>
	  &nbsp;
    </div><div>
      <div id="abstract"></div>
      <button onclick="copyToClipboard()">Copy</button>
    </div><div>
	  &nbsp;
	</div>
    
  </div>

<html>
  <body>
    <script>
      const urlParams = new URLSearchParams(window.location.search);
      const myVar = urlParams.get('param'); 
      document.getElementById(myVar).style.display = 'block';
    </script>
	  <script>
        function copyToClipboard() {
          const textToCopy = document.getElementById("abstract").innerText;
          navigator.clipboard.writeText(textToCopy)
          .then(() => { alert("Text copied to clipboard!"); })
          .catch(err => { alert("Failed to copy text: " + err); });
        }
    </script>
  </body>
</html>

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      

      


    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/schmalstieg"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Dieter Schmalstieg. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

