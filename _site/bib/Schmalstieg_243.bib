@INPROCEEDINGS{Schmalstieg_243,
 author={Bernhard Kainz and Stefan Hauswiesner and Raphael Grasset and Markus Steinberger and Lukas Gruber and Jens Grubert and Eduardo Veas and Denis Kalkofen and Hartmut Seichter and Gerhard Reitmayr and Dieter Schmalstieg},
 title={OmniKinect: Real-Time Dense Volumetric Data Acquisition and Applications},
 booktitle={Proc. Virtual Reality Software and Technology (VRST) 2012},
 year= {2012},
 month={Dec},
 address={Toronto, Canada},
 url={http://arbook.icg.tugraz.at/schmalstieg/Schmalstieg_243.pdf},
 selected={1},
 video={https://www.youtube.com/watch?v=CQjisWt1d9w},
 abstract={Real-time three-dimensional acquisition of real-world scenes has many important applications in computer graphics, computer vision and human-computer interaction. Inexpensive depth sensors such as the Microsoft Kinect allow to leverage the development of such applications. However, this technology is still relatively recent, and no detailed studies on its scalability to dense and view-independent acquisition have been reported. This paper addresses the question of what can be done with a larger number of Kinects used simultaneously. We describe an interference-reducing physical setup, a calibration procedure and an extension to the KinectFusion algorithm, which allows to produce high quality volumetric reconstructions from multiple Kinects whilst overcoming systematic errors in the depth measurements. We also report on enhancing image based visual hull rendering by depth measurements, and compare the results to KinectFusion. Our system provides practical insight into achievable spatial and radial range and into bandwidth requirements for depth data acquisition. Finally, we present a number of practical applications of our system.},
}